{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshnxd/solaris2/blob/main/solaris_REINCARNATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUR0zNCpOy7I"
      },
      "source": [
        "# Setup Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtmEfLbPxlu",
        "outputId": "31070f89-4110-4456-ebca-bde4bfb69d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✅ Libraries loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# === STEP 0: Setup Libraries ===\n",
        "# Core\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Technical indicators & TA-Lib alternative\n",
        "!pip install ta --quiet\n",
        "import ta\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "!pip install xgboost --quiet\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "# Deep Learning (TensorFlow/Keras)\n",
        "!pip install tensorflow --quiet\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Flatten, Conv1D, MaxPooling1D,\n",
        "    LSTM, Input, BatchNormalization, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Utilities for reproducibility\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"✅ Libraries loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hev1JrVPjXj"
      },
      "source": [
        "# Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fS3NEtQdxM",
        "outputId": "6b22a3b1-ea4e-46af-8662-374a034fdba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading hourly data...\n",
            "AAPL: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "MSFT: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "AMZN: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "GOOGL: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "TSLA: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "NVDA: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "JPM: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "JNJ: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "XOM: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "CAT: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "BA: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "META: 5075 rows from 2022-10-07 13:30:00 to 2025-09-04 19:30:00\n",
            "\n",
            "Sample aligned close prices:\n",
            "                           AAPL        MSFT        AMZN       GOOGL  \\\n",
            "Datetime                                                              \n",
            "2025-09-04 15:30:00  237.160004  506.000000  233.514999  228.104996   \n",
            "2025-09-04 16:30:00  238.039993  506.750000  234.419998  229.151001   \n",
            "2025-09-04 17:30:00  238.059998  507.070007  235.169998  230.445007   \n",
            "2025-09-04 18:30:00  238.704498  506.614990  234.950104  231.354996   \n",
            "2025-09-04 19:30:00  239.710007  507.980011  235.690002  232.300003   \n",
            "\n",
            "                           TSLA        NVDA         JPM         JNJ  \\\n",
            "Datetime                                                              \n",
            "2025-09-04 15:30:00  333.182587  170.464203  302.790009  177.945007   \n",
            "2025-09-04 16:30:00  335.079987  170.449997  303.279999  177.759995   \n",
            "2025-09-04 17:30:00  335.399109  170.412201  303.914307  177.820007   \n",
            "2025-09-04 18:30:00  336.850006  170.904999  303.785004  178.535004   \n",
            "2025-09-04 19:30:00  338.564514  171.649994  303.839996  178.699997   \n",
            "\n",
            "                            XOM         CAT          BA        META  \n",
            "Datetime                                                             \n",
            "2025-09-04 15:30:00  112.769997  416.347504  231.679993  748.330017  \n",
            "2025-09-04 16:30:00  112.870003  417.320007  231.445007  748.049927  \n",
            "2025-09-04 17:30:00  112.580002  418.239990  230.889999  748.500000  \n",
            "2025-09-04 18:30:00  112.494301  418.964996  231.500000  747.424988  \n",
            "2025-09-04 19:30:00  112.425003  420.230011  230.720001  748.890015  \n",
            "\n",
            "✅ Hourly data downloaded and saved to 'data_raw/'\n"
          ]
        }
      ],
      "source": [
        "# === STEP 1: Data Collection (Hourly) ===\n",
        "!pip install yfinance --quiet\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Target + market context tickers\n",
        "tickers = [\n",
        "    \"AAPL\",  # tech megacap, consumer + innovation driver\n",
        "    \"MSFT\",  # tech/enterprise backbone\n",
        "    \"AMZN\",  # e-commerce + cloud\n",
        "    \"GOOGL\", # search/ads + AI\n",
        "    \"TSLA\",  # EV + growth volatility\n",
        "    \"NVDA\",  # AI + semiconductors\n",
        "    \"JPM\",   # finance, leading bank\n",
        "    \"JNJ\",   # healthcare/pharma stability\n",
        "    \"XOM\",   # energy leader\n",
        "    \"CAT\",   # industrials/infrastructure\n",
        "    \"BA\",    # aerospace/defense\n",
        "    \"META\"   # social + ads volatility\n",
        "]\n",
        "interval = \"60m\"  # 1-hour bars\n",
        "period = \"729d\"   # max allowed for hourly\n",
        "\n",
        "data_dict = {}\n",
        "print(\"Downloading hourly data...\")\n",
        "for t in tickers:\n",
        "    try:\n",
        "        df = yf.download(t, interval=interval, period=period, progress=False)\n",
        "        df.dropna(inplace=True)\n",
        "        df.index = df.index.tz_localize(None)\n",
        "        data_dict[t] = df\n",
        "        print(f\"{t}: {df.shape[0]} rows from {df.index.min()} to {df.index.max()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to get {t}: {e}\")\n",
        "# ✅ Replace old close_df creation with this\n",
        "target_index = data_dict[\"AAPL\"].index\n",
        "aligned_close = pd.DataFrame(index=target_index)\n",
        "\n",
        "for t, df in data_dict.items():\n",
        "    aligned_close[t] = df.reindex(target_index)['Close']\n",
        "\n",
        "print(\"\\nSample aligned close prices:\")\n",
        "print(aligned_close.tail())\n",
        "\n",
        "# Save raw hourly data\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "for t, df in data_dict.items():\n",
        "    df.to_csv(f\"data_raw/{t}_60m.csv\")\n",
        "print(\"\\n✅ Hourly data downloaded and saved to 'data_raw/'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLnkdkzRRvVb"
      },
      "source": [
        "#Feature Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omLPzq5TDwEA"
      },
      "source": [
        "Creating Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFIHXqY5R2fK",
        "outputId": "d5ab3bea-19c7-41a4-a613-d677cda9a864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Created features for 12 tickers\n",
            "Shape: (60504, 35)\n",
            "     ret_1h    ret_3h    ret_6h   ret_12h   ret_24h    vol_6h   vol_12h  \\\n",
            "0  0.010567  0.015609  0.030296  0.020154  0.019625  0.015878  0.011380   \n",
            "1  0.002948  0.008539  0.052511  0.023124  0.021150  0.011376  0.011372   \n",
            "2 -0.015884 -0.002553  0.006797  0.010635 -0.001916  0.010074  0.012419   \n",
            "3 -0.001849 -0.014808  0.000570  0.009166 -0.004856  0.009999  0.012440   \n",
            "4 -0.006624 -0.024210 -0.015878  0.001653 -0.006412  0.008976  0.012625   \n",
            "\n",
            "    vol_24h     rsi_14      macd  ...  JPM_ret_1h  JNJ_ret_1h  XOM_ret_1h  \\\n",
            "0  0.008904  61.414631  0.170813  ...    0.006073   -0.000848    0.001032   \n",
            "1  0.008914  62.828078  0.379671  ...   -0.000274    0.001030    0.000540   \n",
            "2  0.009447  51.786366  0.357898  ...    0.014456   -0.004782   -0.019971   \n",
            "3  0.009451  50.687597  0.316019  ...    0.022592    0.001521    0.006659   \n",
            "4  0.009491  46.858170  0.205427  ...   -0.010980   -0.002429   -0.004178   \n",
            "\n",
            "   CAT_ret_1h  BA_ret_1h  META_ret_1h  hour  day_of_week            datetime  \\\n",
            "0    0.001471   0.004532     0.008750    18            3 2022-10-13 18:30:00   \n",
            "1   -0.001608  -0.004362    -0.002604    19            3 2022-10-13 19:30:00   \n",
            "2   -0.021677  -0.001964    -0.015048    13            4 2022-10-14 13:30:00   \n",
            "3    0.007646   0.010292     0.003274    14            4 2022-10-14 14:30:00   \n",
            "4   -0.007810  -0.005094    -0.003962    15            4 2022-10-14 15:30:00   \n",
            "\n",
            "   ticker  \n",
            "0    AAPL  \n",
            "1    AAPL  \n",
            "2    AAPL  \n",
            "3    AAPL  \n",
            "4    AAPL  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ],
      "source": [
        "all_feat_data = []\n",
        "\n",
        "# Forward-fill aligned_close once globally\n",
        "aligned_ffill = aligned_close.ffill()\n",
        "\n",
        "for ticker in aligned_ffill.columns:\n",
        "    # Skip if all values are NaN\n",
        "    if aligned_ffill[ticker].isna().all():\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_ffill[ticker]\n",
        "    feat_tmp = pd.DataFrame(index=price_series.index)\n",
        "\n",
        "    # Lag returns\n",
        "    for lag in [1, 3, 6, 12, 24]:\n",
        "        feat_tmp[f\"ret_{lag}h\"] = price_series.pct_change(lag)\n",
        "\n",
        "    # Rolling volatility\n",
        "    for window in [6, 12, 24]:\n",
        "        feat_tmp[f\"vol_{window}h\"] = price_series.pct_change().rolling(window).std()\n",
        "\n",
        "    # Technical indicators\n",
        "    try:\n",
        "        feat_tmp[\"rsi_14\"] = ta.momentum.RSIIndicator(price_series, window=14).rsi()\n",
        "    except Exception:\n",
        "        feat_tmp[\"rsi_14\"] = np.nan\n",
        "    try:\n",
        "        macd = ta.trend.MACD(price_series)\n",
        "        feat_tmp[\"macd\"] = macd.macd()\n",
        "        feat_tmp[\"macd_signal\"] = macd.macd_signal()\n",
        "    except Exception:\n",
        "        feat_tmp[\"macd\"] = np.nan\n",
        "        feat_tmp[\"macd_signal\"] = np.nan\n",
        "\n",
        "    # Moving averages\n",
        "    for w in [5, 10, 20]:\n",
        "        feat_tmp[f\"sma_{w}\"] = price_series.rolling(w).mean()\n",
        "        feat_tmp[f\"ema_{w}\"] = price_series.ewm(span=w, adjust=False).mean()\n",
        "\n",
        "    # Volume features\n",
        "    if ticker in data_dict and \"Volume\" in data_dict[ticker].columns:\n",
        "        vol_series = data_dict[ticker].reindex(price_series.index)[\"Volume\"].ffill()\n",
        "        feat_tmp[\"vol_change_1h\"] = vol_series.pct_change()\n",
        "        feat_tmp[\"vol_ma_24h\"] = vol_series.rolling(24).mean()\n",
        "\n",
        "    # Cross-asset returns — from the globally ffilled dataframe\n",
        "    for asset in [\"AAPL\",  # tech megacap, consumer + innovation driver\n",
        "    \"MSFT\",  # tech/enterprise backbone\n",
        "    \"AMZN\",  # e-commerce + cloud\n",
        "    \"GOOGL\", # search/ads + AI\n",
        "    \"TSLA\",  # EV + growth volatility\n",
        "    \"NVDA\",  # AI + semiconductors\n",
        "    \"JPM\",   # finance, leading bank\n",
        "    \"JNJ\",   # healthcare/pharma stability\n",
        "    \"XOM\",   # energy leader\n",
        "    \"CAT\",   # industrials/infrastructure\n",
        "    \"BA\",    # aerospace/defense\n",
        "    \"META\"]:\n",
        "\n",
        "      if asset in aligned_ffill.columns:\n",
        "            feat_tmp[f\"{asset}_ret_1h\"] = aligned_ffill[asset].pct_change()\n",
        "\n",
        "    # Calendar features\n",
        "    feat_tmp[\"hour\"] = feat_tmp.index.hour\n",
        "    feat_tmp[\"day_of_week\"] = feat_tmp.index.dayofweek\n",
        "\n",
        "    # Only drop rows with NaNs in features for THIS ticker\n",
        "    drop_cols = [col for col in feat_tmp.columns if col not in [\"datetime\", \"ticker\"]]\n",
        "    feat_tmp = feat_tmp.dropna(subset=drop_cols)\n",
        "\n",
        "    feat_tmp[\"datetime\"] = feat_tmp.index\n",
        "    feat_tmp[\"ticker\"] = ticker\n",
        "\n",
        "    all_feat_data.append(feat_tmp.reset_index(drop=True))\n",
        "\n",
        "features_df = pd.concat(all_feat_data, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Created features for {features_df['ticker'].nunique()} tickers\")\n",
        "print(\"Shape:\", features_df.shape)\n",
        "print(features_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKZHysWZZsJZ"
      },
      "source": [
        "Label Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "LOfQ6bcfMrzm",
        "outputId": "aaed709c-c22f-42f6-abe3-56594723975a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataset shape: (60888, 4)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"labels_df\",\n  \"rows\": 60888,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-10-07 13:30:00\",\n        \"max\": \"2025-09-04 18:30:00\",\n        \"num_unique_values\": 5074,\n        \"samples\": [\n          \"2023-10-04 14:30:00\",\n          \"2024-04-15 19:30:00\",\n          \"2022-10-13 18:30:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"BA\",\n          \"CAT\",\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122.97277751902838,\n        \"min\": 11.14999008178711,\n        \"max\": 795.52001953125,\n        \"num_unique_values\": 41523,\n        \"samples\": [\n          361.54998779296875,\n          207.80499267578125,\n          202.20489501953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008503611762450779,\n        \"min\": -0.2163199087811757,\n        \"max\": 0.25591833267966835,\n        \"num_unique_values\": 60644,\n        \"samples\": [\n          0.001373305693200258,\n          -0.0009657081162242893,\n          -4.716277247915787e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "labels_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3f5bc4f9-f2ee-41a0-bf5d-6277f4a59ca1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>ticker</th>\n",
              "      <th>price</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-07 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>141.119995</td>\n",
              "      <td>0.000779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-07 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>141.229996</td>\n",
              "      <td>-0.003930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-10-07 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>140.675003</td>\n",
              "      <td>-0.002808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-07 16:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>140.279999</td>\n",
              "      <td>-0.001441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-10-07 17:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>140.077896</td>\n",
              "      <td>-0.002541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-10-07 18:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>139.721893</td>\n",
              "      <td>0.002563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-10-07 19:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>140.080002</td>\n",
              "      <td>-0.000214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-10-10 13:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>140.050003</td>\n",
              "      <td>-0.000214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-10-10 14:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>140.020004</td>\n",
              "      <td>-0.001946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-10-10 15:30:00</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>139.747498</td>\n",
              "      <td>0.001449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f5bc4f9-f2ee-41a0-bf5d-6277f4a59ca1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f5bc4f9-f2ee-41a0-bf5d-6277f4a59ca1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f5bc4f9-f2ee-41a0-bf5d-6277f4a59ca1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6495c127-7dd1-4f8d-a0ff-e3daac292a4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6495c127-7dd1-4f8d-a0ff-e3daac292a4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6495c127-7dd1-4f8d-a0ff-e3daac292a4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             datetime ticker       price    target\n",
              "0 2022-10-07 13:30:00   AAPL  141.119995  0.000779\n",
              "1 2022-10-07 14:30:00   AAPL  141.229996 -0.003930\n",
              "2 2022-10-07 15:30:00   AAPL  140.675003 -0.002808\n",
              "3 2022-10-07 16:30:00   AAPL  140.279999 -0.001441\n",
              "4 2022-10-07 17:30:00   AAPL  140.077896 -0.002541\n",
              "5 2022-10-07 18:30:00   AAPL  139.721893  0.002563\n",
              "6 2022-10-07 19:30:00   AAPL  140.080002 -0.000214\n",
              "7 2022-10-10 13:30:00   AAPL  140.050003 -0.000214\n",
              "8 2022-10-10 14:30:00   AAPL  140.020004 -0.001946\n",
              "9 2022-10-10 15:30:00   AAPL  139.747498  0.001449"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === LABEL CREATION FOR ALL TICKERS (pooled dataset, regression version) ===\n",
        "\n",
        "horizon = 1               # predict 1 hour ahead\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for ticker in aligned_close.columns:\n",
        "    # Skip if ticker is all NaN (e.g., ^VIX alignment issues)\n",
        "    if aligned_close[ticker].dropna().empty:\n",
        "        continue\n",
        "\n",
        "    price_series = aligned_close[ticker]\n",
        "\n",
        "    # Forward return (future percentage change)\n",
        "    future_price = price_series.shift(-horizon)\n",
        "    future_ret = (future_price - price_series) / price_series\n",
        "\n",
        "    # Drop NaNs (where future_ret is nan)\n",
        "    valid_idx = future_ret.dropna().index\n",
        "\n",
        "    # Combine into dataframe\n",
        "    df_tmp = pd.DataFrame({\n",
        "        \"datetime\": valid_idx,\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": price_series.loc[valid_idx],\n",
        "        \"target\": future_ret.loc[valid_idx],  # regression target\n",
        "    })\n",
        "\n",
        "    all_data.append(df_tmp)\n",
        "\n",
        "# Combine all tickers\n",
        "labels_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(\"Combined dataset shape:\", labels_df.shape)\n",
        "labels_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rieWxNf5Mp44"
      },
      "source": [
        "Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H-ATXHjSK6_"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PxZH38IebtG"
      },
      "source": [
        "Normalize Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OERLO3TNed16",
        "outputId": "dd19f849-2b44-47bf-f0d8-6e33cb34367f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (60492, 34)\n",
            "y stats:\n",
            " count    60492.000000\n",
            "mean         0.000206\n",
            "std          0.008491\n",
            "min         -0.216320\n",
            "25%         -0.002552\n",
            "50%          0.000188\n",
            "75%          0.002891\n",
            "max          0.255918\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Merge features with labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Drop NaNs (just in case)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y stats:\\n\", y.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpnDnFsiWa87"
      },
      "source": [
        "Scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oxCtsXaSTrW",
        "outputId": "1a6ec913-4731-4998-cbd5-793e7e15d7a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Train: (42331, 34), Val: (9071, 34), Test: (9072, 34)\n",
            "Target stats in Train:\n",
            " count    42331.000000\n",
            "mean         0.000218\n",
            "std          0.008276\n",
            "min         -0.216320\n",
            "25%         -0.002550\n",
            "50%          0.000202\n",
            "75%          0.002892\n",
            "max          0.255918\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Merge features and labels\n",
        "df = features_df.merge(labels_df, on=[\"datetime\", \"ticker\"], how=\"inner\")\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values([\"datetime\", \"ticker\"]).reset_index(drop=True)\n",
        "\n",
        "# Replace inf values with NaN\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Drop rows with NaNs\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"datetime\", \"ticker\", \"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(len(df) * 0.7)\n",
        "val_size = int(len(df) * 0.15)\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "\n",
        "X_val = X.iloc[train_size:train_size + val_size]\n",
        "y_val = y.iloc[train_size:train_size + val_size]\n",
        "\n",
        "X_test = X.iloc[train_size + val_size:]\n",
        "y_test = y.iloc[train_size + val_size:]\n",
        "\n",
        "# Ensure all values are finite before scaling\n",
        "assert np.isfinite(X_train.values).all(), \"Found non-finite values in X_train!\"\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "print(\"Target stats in Train:\\n\", y_train.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQxLDkaWdBP"
      },
      "source": [
        "Sequence making - For LSTM AND CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn5XIK9DWlAN",
        "outputId": "ff310858-cc33-4311-d149-77311f50444d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train seq: (42203, 128, 34), Val seq: (8943, 128, 34), Test seq: (8944, 128, 34)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, seq_len=24):\n",
        "    \"\"\"\n",
        "    Convert tabular (samples, features) into sequential (samples, seq_len, features)\n",
        "    for CNN/LSTM, keeping labels aligned to the last timestep.\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        X_seq.append(X[i:i+seq_len])\n",
        "        y_seq.append(y[i+seq_len])  # label at next hour\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# === Choose sequence length ===\n",
        "SEQ_LEN = 128\n",
        "\n",
        "# Reshape train/val/test sets\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train.values, SEQ_LEN)\n",
        "X_val_seq,   y_val_seq   = create_sequences(X_val,   y_val.values,   SEQ_LEN)\n",
        "X_test_seq,  y_test_seq  = create_sequences(X_test,  y_test.values,  SEQ_LEN)\n",
        "\n",
        "print(f\"Train seq: {X_train_seq.shape}, Val seq: {X_val_seq.shape}, Test seq: {X_test_seq.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbSWhuL6BzMZ",
        "outputId": "66fa610f-8df8-4c4d-a28c-81d254de27ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train target stats: mean=0.0002, std=0.0083, min=-0.2163, max=0.2559\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# If your y_* are numpy arrays (sequence targets), you don't need to encode them for regression\n",
        "# Just ensure they are np.float32 (or np.float64) and have the right shape for your model\n",
        "\n",
        "# Example: conversion to float and correct shape for Keras (if needed)\n",
        "y_train_seq_float = np.asarray(y_train_seq, dtype=np.float32)\n",
        "y_val_seq_float   = np.asarray(y_val_seq, dtype=np.float32)\n",
        "y_test_seq_float  = np.asarray(y_test_seq, dtype=np.float32)\n",
        "\n",
        "print(\"Train target stats:\",\n",
        "      f\"mean={np.mean(y_train_seq_float):.4f}, std={np.std(y_train_seq_float):.4f}, min={np.min(y_train_seq_float):.4f}, max={np.max(y_train_seq_float):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7cPsJ3SX0Z"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jUYMhA9cSxM"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "2mDqNrx0SddA",
        "outputId": "b725bb47-d647-40a1-afd5-ffa17192ba5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,592</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">229,632</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m34\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m6,592\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m229,632\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,089</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321,089\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">319,809</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m319,809\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import metrics as keras_metrics\n",
        "\n",
        "# Model hyperparameters\n",
        "SEQUENCE_LENGTH = 128  # past 128 hours\n",
        "NUM_FEATURES = 34      # per hour\n",
        "\n",
        "def cnnmodel(seq_len=SEQUENCE_LENGTH, num_features=NUM_FEATURES):\n",
        "    inputs = layers.Input(shape=(seq_len, num_features))  # (128, 51)\n",
        "\n",
        "    # First 1D Conv block\n",
        "    x = layers.Conv1D(filters=64, kernel_size=3, strides=1, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Second 1D Conv block\n",
        "    x = layers.Conv1D(filters=128, kernel_size=5, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Third 1D Conv block\n",
        "    x = layers.Conv1D(filters=256, kernel_size=7, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Global pooling for sequence dimension\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Dense layers for regression\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Output layer (regression: predict next-hour return/price)\n",
        "    outputs = layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile model for regression\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\n",
        "        keras_metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "        keras_metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and print summary\n",
        "cnn_model = cnnmodel()\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p_nIYgVcWrf"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "IYtsddwpfp1i",
        "outputId": "5ca4883a-6e1e-4df0-9ec0-484758fd52c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m34\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m83,456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,905</span> (546.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,905\u001b[0m (546.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,713</span> (545.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,713\u001b[0m (545.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import metrics as keras_metrics\n",
        "\n",
        "# Model hyperparameters\n",
        "SEQUENCE_LENGTH = 128  # past 128 hours\n",
        "NUM_FEATURES = 34      # per hour\n",
        "\n",
        "def lstmmodel(seq_len=SEQUENCE_LENGTH, num_features=NUM_FEATURES):\n",
        "    inputs = layers.Input(shape=(seq_len, num_features))\n",
        "\n",
        "    # LSTM block 1\n",
        "    x = layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inputs)\n",
        "    x = layers.LayerNormalization()(x)   # ✅ LayerNorm stabilizes sequence learning\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # LSTM block 2\n",
        "    x = layers.LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(x)\n",
        "    x = layers.LayerNormalization()(x)   # ✅ use LayerNorm instead of BatchNorm\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense layers for regression\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)   # ✅ BatchNorm is fine here (non-sequence MLP)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Output layer (regression: predict next-hour price/return)\n",
        "    outputs = layers.Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\n",
        "        keras_metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "        keras_metrics.RootMeanSquaredError(name=\"rmse\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build and print summary\n",
        "lstm_model = lstmmodel()\n",
        "lstm_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FalnDi8fxYP"
      },
      "source": [
        "XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjSEPd16f61x"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# ---- y_train, y_val, y_test are already regression targets (floats) ----\n",
        "# If y_train etc are lists, convert to numpy arrays for XGBoost\n",
        "y_train_tab = np.asarray(y_train, dtype=np.float32)\n",
        "y_val_tab = np.asarray(y_val, dtype=np.float32)\n",
        "y_test_tab = np.asarray(y_test, dtype=np.float32)\n",
        "\n",
        "# ---- XGBoost regressor ----\n",
        "xgb_reg = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',   # regression objective\n",
        "    n_estimators=1000,              # set high + use early stopping\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    gamma=1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',             # 'gpu_hist' if you have GPU\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "\n",
        "# Example fit (add early stopping if desired):\n",
        "# xgb_reg.fit(X_train, y_train_tab, eval_set=[(X_val, y_val_tab)], early_stopping_rounds=25, verbose=True)\n",
        "\n",
        "# Example prediction:\n",
        "# y_pred = xgb_reg.predict(X_test)\n",
        "# print(\"Test MSE:\", mean_squared_error(y_test_tab, y_pred))\n",
        "# print(\"Test MAE:\", mean_absolute_error(y_test_tab, y_pred))\n",
        "# print(\"Test R2:\", r2_score(y_test_tab, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKR7NlqVaq34"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOvOaClz5nPe"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gP7w6KfaugQ",
        "outputId": "b3ceceb5-18eb-4f08-cd4d-fe2a943fd675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.00208, saving model to best_cnn.weights.h5\n",
            "660/660 - 170s - 257ms/step - loss: 0.2874 - mae: 0.3417 - rmse: 0.5361 - val_loss: 0.0021 - val_mae: 0.0354 - val_rmse: 0.0457 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 0.00208 to 0.00021, saving model to best_cnn.weights.h5\n",
            "660/660 - 151s - 228ms/step - loss: 0.0098 - mae: 0.0560 - rmse: 0.0991 - val_loss: 2.1492e-04 - val_mae: 0.0108 - val_rmse: 0.0147 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 0.00021 to 0.00008, saving model to best_cnn.weights.h5\n",
            "660/660 - 202s - 307ms/step - loss: 2.3600e-04 - mae: 0.0087 - rmse: 0.0154 - val_loss: 7.9445e-05 - val_mae: 0.0051 - val_rmse: 0.0089 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.00008\n",
            "660/660 - 152s - 231ms/step - loss: 6.9938e-05 - mae: 0.0048 - rmse: 0.0084 - val_loss: 7.9865e-05 - val_mae: 0.0051 - val_rmse: 0.0089 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.00008\n",
            "660/660 - 204s - 309ms/step - loss: 7.0081e-05 - mae: 0.0048 - rmse: 0.0084 - val_loss: 8.1787e-05 - val_mae: 0.0052 - val_rmse: 0.0090 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.00008\n",
            "660/660 - 159s - 242ms/step - loss: 7.0971e-05 - mae: 0.0049 - rmse: 0.0084 - val_loss: 8.2863e-05 - val_mae: 0.0054 - val_rmse: 0.0091 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.00008\n",
            "660/660 - 198s - 299ms/step - loss: 7.2376e-05 - mae: 0.0050 - rmse: 0.0085 - val_loss: 8.9397e-05 - val_mae: 0.0060 - val_rmse: 0.0095 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.00008\n",
            "660/660 - 157s - 237ms/step - loss: 7.3852e-05 - mae: 0.0051 - rmse: 0.0086 - val_loss: 8.7510e-05 - val_mae: 0.0058 - val_rmse: 0.0094 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.00008\n",
            "660/660 - 199s - 301ms/step - loss: 7.2096e-05 - mae: 0.0050 - rmse: 0.0085 - val_loss: 9.2512e-05 - val_mae: 0.0062 - val_rmse: 0.0096 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.00008\n",
            "660/660 - 202s - 307ms/step - loss: 7.3777e-05 - mae: 0.0051 - rmse: 0.0086 - val_loss: 8.5567e-05 - val_mae: 0.0056 - val_rmse: 0.0093 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.00008\n",
            "660/660 - 149s - 226ms/step - loss: 7.5424e-05 - mae: 0.0052 - rmse: 0.0087 - val_loss: 8.5380e-05 - val_mae: 0.0056 - val_rmse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.00008\n",
            "660/660 - 204s - 309ms/step - loss: 7.8317e-05 - mae: 0.0054 - rmse: 0.0088 - val_loss: 1.0044e-04 - val_mae: 0.0067 - val_rmse: 0.0100 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.00008\n",
            "660/660 - 159s - 241ms/step - loss: 8.1172e-05 - mae: 0.0056 - rmse: 0.0090 - val_loss: 1.0313e-04 - val_mae: 0.0070 - val_rmse: 0.0102 - learning_rate: 5.0000e-04\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Final Training Metrics:\n",
            "Loss (MSE): 0.000069 | MAE: 0.004680 | RMSE: 0.008296\n",
            "Final Validation Metrics:\n",
            "Loss (MSE): 0.000079 | MAE: 0.005072 | RMSE: 0.008913\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
        "\n",
        "\n",
        "# ---- Define metrics explicitly (avoid 'rmse' string) ----\n",
        "metrics = [\n",
        "    tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "    tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
        "]\n",
        "\n",
        "# ---- Callbacks ----\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_ckpt = ModelCheckpoint(\n",
        "    filepath=\"best_cnn.weights.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "kill_on_nan = TerminateOnNaN()\n",
        "\n",
        "callbacks = [early_stop, reduce_lr, model_ckpt, kill_on_nan]\n",
        "\n",
        "# ---- Train ----\n",
        "history = cnn_model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    validation_data=(X_val_seq, y_val_seq),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# ---- Load best weights & evaluate ----\n",
        "cnn_model.load_weights(\"best_cnn.weights.h5\")\n",
        "\n",
        "train_eval = cnn_model.evaluate(X_train_seq, y_train_seq, verbose=0)\n",
        "val_eval   = cnn_model.evaluate(X_val_seq,   y_val_seq,   verbose=0)\n",
        "\n",
        "print(\"Final Training Metrics:\")\n",
        "print(f\"Loss (MSE): {train_eval[0]:.6f} | MAE: {train_eval[1]:.6f} | RMSE: {train_eval[2]:.6f}\")\n",
        "\n",
        "print(\"Final Validation Metrics:\")\n",
        "print(f\"Loss (MSE): {val_eval[0]:.6f} | MAE: {val_eval[1]:.6f} | RMSE: {val_eval[2]:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxu1niZ7gq8S"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrRMRsOBgt5h",
        "outputId": "fe2dd8cb-efc5-4415-c2be-9ead7e602e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.00090, saving model to best_lstm.weights.h5\n",
            "660/660 - 347s - 525ms/step - loss: 0.1907 - mae: 0.2929 - rmse: 0.4367 - val_loss: 8.9615e-04 - val_mae: 0.0225 - val_rmse: 0.0299 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 0.00090 to 0.00011, saving model to best_lstm.weights.h5\n",
            "660/660 - 378s - 572ms/step - loss: 0.0064 - mae: 0.0555 - rmse: 0.0799 - val_loss: 1.0769e-04 - val_mae: 0.0069 - val_rmse: 0.0104 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 0.00011 to 0.00008, saving model to best_lstm.weights.h5\n",
            "660/660 - 321s - 487ms/step - loss: 2.5675e-04 - mae: 0.0109 - rmse: 0.0160 - val_loss: 8.0230e-05 - val_mae: 0.0051 - val_rmse: 0.0090 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss improved from 0.00008 to 0.00008, saving model to best_lstm.weights.h5\n",
            "660/660 - 343s - 519ms/step - loss: 7.0686e-05 - mae: 0.0049 - rmse: 0.0084 - val_loss: 7.9666e-05 - val_mae: 0.0051 - val_rmse: 0.0089 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.00008\n",
            "660/660 - 373s - 566ms/step - loss: 6.9358e-05 - mae: 0.0047 - rmse: 0.0083 - val_loss: 8.2770e-05 - val_mae: 0.0053 - val_rmse: 0.0091 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.00008\n",
            "660/660 - 375s - 568ms/step - loss: 6.9846e-05 - mae: 0.0048 - rmse: 0.0084 - val_loss: 8.4426e-05 - val_mae: 0.0055 - val_rmse: 0.0092 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.00008\n",
            "660/660 - 334s - 506ms/step - loss: 7.0326e-05 - mae: 0.0048 - rmse: 0.0084 - val_loss: 8.1082e-05 - val_mae: 0.0052 - val_rmse: 0.0090 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.00008\n",
            "660/660 - 372s - 563ms/step - loss: 6.9899e-05 - mae: 0.0048 - rmse: 0.0084 - val_loss: 8.4339e-05 - val_mae: 0.0055 - val_rmse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.00008\n",
            "660/660 - 399s - 605ms/step - loss: 7.0260e-05 - mae: 0.0048 - rmse: 0.0084 - val_loss: 8.3929e-05 - val_mae: 0.0054 - val_rmse: 0.0092 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.00008\n",
            "660/660 - 336s - 509ms/step - loss: 7.1278e-05 - mae: 0.0049 - rmse: 0.0084 - val_loss: 8.3140e-05 - val_mae: 0.0053 - val_rmse: 0.0091 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.00008\n",
            "660/660 - 380s - 575ms/step - loss: 7.2267e-05 - mae: 0.0050 - rmse: 0.0085 - val_loss: 8.1184e-05 - val_mae: 0.0052 - val_rmse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.00008\n",
            "660/660 - 341s - 516ms/step - loss: 7.2947e-05 - mae: 0.0051 - rmse: 0.0085 - val_loss: 8.0981e-05 - val_mae: 0.0052 - val_rmse: 0.0090 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.00008\n",
            "660/660 - 373s - 566ms/step - loss: 7.0969e-05 - mae: 0.0049 - rmse: 0.0084 - val_loss: 8.1593e-05 - val_mae: 0.0052 - val_rmse: 0.0090 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.00008\n",
            "660/660 - 329s - 498ms/step - loss: 7.1307e-05 - mae: 0.0049 - rmse: 0.0084 - val_loss: 8.1879e-05 - val_mae: 0.0052 - val_rmse: 0.0090 - learning_rate: 2.5000e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Final Training Metrics:\n",
            "Loss (MSE): 0.000069 | MAE: 0.004669 | RMSE: 0.008282\n",
            "Final Validation Metrics:\n",
            "Loss (MSE): 0.000080 | MAE: 0.005059 | RMSE: 0.008926\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
        "\n",
        "# ---- Define metrics explicitly for regression ----\n",
        "metrics = [\n",
        "    tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "    tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
        "]\n",
        "\n",
        "# ---- Callbacks ----\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_ckpt = ModelCheckpoint(\n",
        "    filepath=\"best_lstm.weights.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "kill_on_nan = TerminateOnNaN()\n",
        "\n",
        "callbacks = [early_stop, reduce_lr, model_ckpt, kill_on_nan]\n",
        "\n",
        "# ---- Train ----\n",
        "history = lstm_model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    validation_data=(X_val_seq, y_val_seq),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# ---- Load best weights & evaluate ----\n",
        "lstm_model.load_weights(\"best_lstm.weights.h5\")\n",
        "\n",
        "train_eval = lstm_model.evaluate(X_train_seq, y_train_seq, verbose=0)\n",
        "val_eval   = lstm_model.evaluate(X_val_seq,   y_val_seq,   verbose=0)\n",
        "\n",
        "print(\"Final Training Metrics:\")\n",
        "print(f\"Loss (MSE): {train_eval[0]:.6f} | MAE: {train_eval[1]:.6f} | RMSE: {train_eval[2]:.6f}\")\n",
        "\n",
        "print(\"Final Validation Metrics:\")\n",
        "print(f\"Loss (MSE): {val_eval[0]:.6f} | MAE: {val_eval[1]:.6f} | RMSE: {val_eval[2]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RHWbvELgyIZ"
      },
      "source": [
        "XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lOUy9Yd0g-6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0121534-0dac-4558-a029-d5a2e40209a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:0.00884\n",
            "[1]\tvalidation_0-rmse:0.00884\n",
            "[2]\tvalidation_0-rmse:0.00884\n",
            "[3]\tvalidation_0-rmse:0.00884\n",
            "[4]\tvalidation_0-rmse:0.00884\n",
            "[5]\tvalidation_0-rmse:0.00884\n",
            "[6]\tvalidation_0-rmse:0.00884\n",
            "[7]\tvalidation_0-rmse:0.00884\n",
            "[8]\tvalidation_0-rmse:0.00884\n",
            "[9]\tvalidation_0-rmse:0.00884\n",
            "[10]\tvalidation_0-rmse:0.00884\n",
            "[11]\tvalidation_0-rmse:0.00884\n",
            "[12]\tvalidation_0-rmse:0.00884\n",
            "[13]\tvalidation_0-rmse:0.00884\n",
            "[14]\tvalidation_0-rmse:0.00884\n",
            "[15]\tvalidation_0-rmse:0.00884\n",
            "[16]\tvalidation_0-rmse:0.00884\n",
            "[17]\tvalidation_0-rmse:0.00884\n",
            "[18]\tvalidation_0-rmse:0.00884\n",
            "[19]\tvalidation_0-rmse:0.00884\n",
            "[20]\tvalidation_0-rmse:0.00884\n",
            "[21]\tvalidation_0-rmse:0.00884\n",
            "[22]\tvalidation_0-rmse:0.00884\n",
            "[23]\tvalidation_0-rmse:0.00884\n",
            "[24]\tvalidation_0-rmse:0.00884\n",
            "[25]\tvalidation_0-rmse:0.00884\n",
            "[26]\tvalidation_0-rmse:0.00884\n",
            "[27]\tvalidation_0-rmse:0.00884\n",
            "[28]\tvalidation_0-rmse:0.00884\n",
            "[29]\tvalidation_0-rmse:0.00884\n",
            "[30]\tvalidation_0-rmse:0.00884\n",
            "[31]\tvalidation_0-rmse:0.00884\n",
            "[32]\tvalidation_0-rmse:0.00884\n",
            "[33]\tvalidation_0-rmse:0.00884\n",
            "[34]\tvalidation_0-rmse:0.00884\n",
            "[35]\tvalidation_0-rmse:0.00884\n",
            "[36]\tvalidation_0-rmse:0.00884\n",
            "[37]\tvalidation_0-rmse:0.00884\n",
            "[38]\tvalidation_0-rmse:0.00884\n",
            "[39]\tvalidation_0-rmse:0.00884\n",
            "[40]\tvalidation_0-rmse:0.00884\n",
            "[41]\tvalidation_0-rmse:0.00884\n",
            "[42]\tvalidation_0-rmse:0.00884\n",
            "[43]\tvalidation_0-rmse:0.00884\n",
            "[44]\tvalidation_0-rmse:0.00884\n",
            "[45]\tvalidation_0-rmse:0.00884\n",
            "[46]\tvalidation_0-rmse:0.00884\n",
            "[47]\tvalidation_0-rmse:0.00884\n",
            "[48]\tvalidation_0-rmse:0.00884\n",
            "[49]\tvalidation_0-rmse:0.00884\n",
            "[50]\tvalidation_0-rmse:0.00884\n",
            "[51]\tvalidation_0-rmse:0.00884\n",
            "[52]\tvalidation_0-rmse:0.00884\n",
            "[53]\tvalidation_0-rmse:0.00884\n",
            "[54]\tvalidation_0-rmse:0.00884\n",
            "[55]\tvalidation_0-rmse:0.00884\n",
            "[56]\tvalidation_0-rmse:0.00884\n",
            "[57]\tvalidation_0-rmse:0.00884\n",
            "[58]\tvalidation_0-rmse:0.00884\n",
            "[59]\tvalidation_0-rmse:0.00884\n",
            "[60]\tvalidation_0-rmse:0.00884\n",
            "[61]\tvalidation_0-rmse:0.00884\n",
            "[62]\tvalidation_0-rmse:0.00884\n",
            "[63]\tvalidation_0-rmse:0.00884\n",
            "[64]\tvalidation_0-rmse:0.00884\n",
            "[65]\tvalidation_0-rmse:0.00884\n",
            "[66]\tvalidation_0-rmse:0.00884\n",
            "[67]\tvalidation_0-rmse:0.00884\n",
            "[68]\tvalidation_0-rmse:0.00884\n",
            "[69]\tvalidation_0-rmse:0.00884\n",
            "[70]\tvalidation_0-rmse:0.00884\n",
            "[71]\tvalidation_0-rmse:0.00884\n",
            "[72]\tvalidation_0-rmse:0.00884\n",
            "[73]\tvalidation_0-rmse:0.00884\n",
            "[74]\tvalidation_0-rmse:0.00884\n",
            "[75]\tvalidation_0-rmse:0.00884\n",
            "[76]\tvalidation_0-rmse:0.00884\n",
            "[77]\tvalidation_0-rmse:0.00884\n",
            "[78]\tvalidation_0-rmse:0.00884\n",
            "[79]\tvalidation_0-rmse:0.00884\n",
            "[80]\tvalidation_0-rmse:0.00884\n",
            "[81]\tvalidation_0-rmse:0.00884\n",
            "[82]\tvalidation_0-rmse:0.00884\n",
            "[83]\tvalidation_0-rmse:0.00884\n",
            "[84]\tvalidation_0-rmse:0.00884\n",
            "[85]\tvalidation_0-rmse:0.00884\n",
            "[86]\tvalidation_0-rmse:0.00884\n",
            "[87]\tvalidation_0-rmse:0.00884\n",
            "[88]\tvalidation_0-rmse:0.00884\n",
            "[89]\tvalidation_0-rmse:0.00884\n",
            "[90]\tvalidation_0-rmse:0.00884\n",
            "[91]\tvalidation_0-rmse:0.00884\n",
            "[92]\tvalidation_0-rmse:0.00884\n",
            "[93]\tvalidation_0-rmse:0.00884\n",
            "[94]\tvalidation_0-rmse:0.00884\n",
            "[95]\tvalidation_0-rmse:0.00884\n",
            "[96]\tvalidation_0-rmse:0.00884\n",
            "[97]\tvalidation_0-rmse:0.00884\n",
            "[98]\tvalidation_0-rmse:0.00884\n",
            "[99]\tvalidation_0-rmse:0.00884\n",
            "[100]\tvalidation_0-rmse:0.00884\n",
            "[101]\tvalidation_0-rmse:0.00884\n",
            "[102]\tvalidation_0-rmse:0.00884\n",
            "[103]\tvalidation_0-rmse:0.00884\n",
            "[104]\tvalidation_0-rmse:0.00884\n",
            "[105]\tvalidation_0-rmse:0.00884\n",
            "[106]\tvalidation_0-rmse:0.00884\n",
            "[107]\tvalidation_0-rmse:0.00884\n",
            "[108]\tvalidation_0-rmse:0.00884\n",
            "[109]\tvalidation_0-rmse:0.00884\n",
            "[110]\tvalidation_0-rmse:0.00884\n",
            "[111]\tvalidation_0-rmse:0.00884\n",
            "[112]\tvalidation_0-rmse:0.00884\n",
            "[113]\tvalidation_0-rmse:0.00884\n",
            "[114]\tvalidation_0-rmse:0.00884\n",
            "[115]\tvalidation_0-rmse:0.00884\n",
            "[116]\tvalidation_0-rmse:0.00884\n",
            "[117]\tvalidation_0-rmse:0.00884\n",
            "[118]\tvalidation_0-rmse:0.00884\n",
            "[119]\tvalidation_0-rmse:0.00884\n",
            "[120]\tvalidation_0-rmse:0.00884\n",
            "[121]\tvalidation_0-rmse:0.00884\n",
            "[122]\tvalidation_0-rmse:0.00884\n",
            "[123]\tvalidation_0-rmse:0.00884\n",
            "[124]\tvalidation_0-rmse:0.00884\n",
            "[125]\tvalidation_0-rmse:0.00884\n",
            "[126]\tvalidation_0-rmse:0.00884\n",
            "[127]\tvalidation_0-rmse:0.00884\n",
            "[128]\tvalidation_0-rmse:0.00884\n",
            "[129]\tvalidation_0-rmse:0.00884\n",
            "[130]\tvalidation_0-rmse:0.00884\n",
            "[131]\tvalidation_0-rmse:0.00884\n",
            "[132]\tvalidation_0-rmse:0.00884\n",
            "[133]\tvalidation_0-rmse:0.00884\n",
            "[134]\tvalidation_0-rmse:0.00884\n",
            "[135]\tvalidation_0-rmse:0.00884\n",
            "[136]\tvalidation_0-rmse:0.00884\n",
            "[137]\tvalidation_0-rmse:0.00884\n",
            "[138]\tvalidation_0-rmse:0.00884\n",
            "[139]\tvalidation_0-rmse:0.00884\n",
            "[140]\tvalidation_0-rmse:0.00884\n",
            "[141]\tvalidation_0-rmse:0.00884\n",
            "[142]\tvalidation_0-rmse:0.00884\n",
            "[143]\tvalidation_0-rmse:0.00884\n",
            "[144]\tvalidation_0-rmse:0.00884\n",
            "[145]\tvalidation_0-rmse:0.00884\n",
            "[146]\tvalidation_0-rmse:0.00884\n",
            "[147]\tvalidation_0-rmse:0.00884\n",
            "[148]\tvalidation_0-rmse:0.00884\n",
            "[149]\tvalidation_0-rmse:0.00884\n",
            "[150]\tvalidation_0-rmse:0.00884\n",
            "[151]\tvalidation_0-rmse:0.00884\n",
            "[152]\tvalidation_0-rmse:0.00884\n",
            "[153]\tvalidation_0-rmse:0.00884\n",
            "[154]\tvalidation_0-rmse:0.00884\n",
            "[155]\tvalidation_0-rmse:0.00884\n",
            "[156]\tvalidation_0-rmse:0.00884\n",
            "[157]\tvalidation_0-rmse:0.00884\n",
            "[158]\tvalidation_0-rmse:0.00884\n",
            "[159]\tvalidation_0-rmse:0.00884\n",
            "[160]\tvalidation_0-rmse:0.00884\n",
            "[161]\tvalidation_0-rmse:0.00884\n",
            "[162]\tvalidation_0-rmse:0.00884\n",
            "[163]\tvalidation_0-rmse:0.00884\n",
            "[164]\tvalidation_0-rmse:0.00884\n",
            "[165]\tvalidation_0-rmse:0.00884\n",
            "[166]\tvalidation_0-rmse:0.00884\n",
            "[167]\tvalidation_0-rmse:0.00884\n",
            "[168]\tvalidation_0-rmse:0.00884\n",
            "[169]\tvalidation_0-rmse:0.00884\n",
            "[170]\tvalidation_0-rmse:0.00884\n",
            "[171]\tvalidation_0-rmse:0.00884\n",
            "[172]\tvalidation_0-rmse:0.00884\n",
            "[173]\tvalidation_0-rmse:0.00884\n",
            "[174]\tvalidation_0-rmse:0.00884\n",
            "[175]\tvalidation_0-rmse:0.00884\n",
            "[176]\tvalidation_0-rmse:0.00884\n",
            "[177]\tvalidation_0-rmse:0.00884\n",
            "[178]\tvalidation_0-rmse:0.00884\n",
            "[179]\tvalidation_0-rmse:0.00884\n",
            "[180]\tvalidation_0-rmse:0.00884\n",
            "[181]\tvalidation_0-rmse:0.00884\n",
            "[182]\tvalidation_0-rmse:0.00884\n",
            "[183]\tvalidation_0-rmse:0.00884\n",
            "[184]\tvalidation_0-rmse:0.00884\n",
            "[185]\tvalidation_0-rmse:0.00884\n",
            "[186]\tvalidation_0-rmse:0.00884\n",
            "[187]\tvalidation_0-rmse:0.00884\n",
            "[188]\tvalidation_0-rmse:0.00884\n",
            "[189]\tvalidation_0-rmse:0.00884\n",
            "[190]\tvalidation_0-rmse:0.00884\n",
            "[191]\tvalidation_0-rmse:0.00884\n",
            "[192]\tvalidation_0-rmse:0.00884\n",
            "[193]\tvalidation_0-rmse:0.00884\n",
            "[194]\tvalidation_0-rmse:0.00884\n",
            "[195]\tvalidation_0-rmse:0.00884\n",
            "[196]\tvalidation_0-rmse:0.00884\n",
            "[197]\tvalidation_0-rmse:0.00884\n",
            "[198]\tvalidation_0-rmse:0.00884\n",
            "[199]\tvalidation_0-rmse:0.00884\n",
            "[200]\tvalidation_0-rmse:0.00884\n",
            "[201]\tvalidation_0-rmse:0.00884\n",
            "[202]\tvalidation_0-rmse:0.00884\n",
            "[203]\tvalidation_0-rmse:0.00884\n",
            "[204]\tvalidation_0-rmse:0.00884\n",
            "[205]\tvalidation_0-rmse:0.00884\n",
            "[206]\tvalidation_0-rmse:0.00884\n",
            "[207]\tvalidation_0-rmse:0.00884\n",
            "[208]\tvalidation_0-rmse:0.00884\n",
            "[209]\tvalidation_0-rmse:0.00884\n",
            "[210]\tvalidation_0-rmse:0.00884\n",
            "[211]\tvalidation_0-rmse:0.00884\n",
            "[212]\tvalidation_0-rmse:0.00884\n",
            "[213]\tvalidation_0-rmse:0.00884\n",
            "[214]\tvalidation_0-rmse:0.00884\n",
            "[215]\tvalidation_0-rmse:0.00884\n",
            "[216]\tvalidation_0-rmse:0.00884\n",
            "[217]\tvalidation_0-rmse:0.00884\n",
            "[218]\tvalidation_0-rmse:0.00884\n",
            "[219]\tvalidation_0-rmse:0.00884\n",
            "[220]\tvalidation_0-rmse:0.00884\n",
            "[221]\tvalidation_0-rmse:0.00884\n",
            "[222]\tvalidation_0-rmse:0.00884\n",
            "[223]\tvalidation_0-rmse:0.00884\n",
            "[224]\tvalidation_0-rmse:0.00884\n",
            "[225]\tvalidation_0-rmse:0.00884\n",
            "[226]\tvalidation_0-rmse:0.00884\n",
            "[227]\tvalidation_0-rmse:0.00884\n",
            "[228]\tvalidation_0-rmse:0.00884\n",
            "[229]\tvalidation_0-rmse:0.00884\n",
            "[230]\tvalidation_0-rmse:0.00884\n",
            "[231]\tvalidation_0-rmse:0.00884\n",
            "[232]\tvalidation_0-rmse:0.00884\n",
            "[233]\tvalidation_0-rmse:0.00884\n",
            "[234]\tvalidation_0-rmse:0.00884\n",
            "[235]\tvalidation_0-rmse:0.00884\n",
            "[236]\tvalidation_0-rmse:0.00884\n",
            "[237]\tvalidation_0-rmse:0.00884\n",
            "[238]\tvalidation_0-rmse:0.00884\n",
            "[239]\tvalidation_0-rmse:0.00884\n",
            "[240]\tvalidation_0-rmse:0.00884\n",
            "[241]\tvalidation_0-rmse:0.00884\n",
            "[242]\tvalidation_0-rmse:0.00884\n",
            "[243]\tvalidation_0-rmse:0.00884\n",
            "[244]\tvalidation_0-rmse:0.00884\n",
            "[245]\tvalidation_0-rmse:0.00884\n",
            "[246]\tvalidation_0-rmse:0.00884\n",
            "[247]\tvalidation_0-rmse:0.00884\n",
            "[248]\tvalidation_0-rmse:0.00884\n",
            "[249]\tvalidation_0-rmse:0.00884\n",
            "[250]\tvalidation_0-rmse:0.00884\n",
            "[251]\tvalidation_0-rmse:0.00884\n",
            "[252]\tvalidation_0-rmse:0.00884\n",
            "[253]\tvalidation_0-rmse:0.00884\n",
            "[254]\tvalidation_0-rmse:0.00884\n",
            "[255]\tvalidation_0-rmse:0.00884\n",
            "[256]\tvalidation_0-rmse:0.00884\n",
            "[257]\tvalidation_0-rmse:0.00884\n",
            "[258]\tvalidation_0-rmse:0.00884\n",
            "[259]\tvalidation_0-rmse:0.00884\n",
            "[260]\tvalidation_0-rmse:0.00884\n",
            "[261]\tvalidation_0-rmse:0.00884\n",
            "[262]\tvalidation_0-rmse:0.00884\n",
            "[263]\tvalidation_0-rmse:0.00884\n",
            "[264]\tvalidation_0-rmse:0.00884\n",
            "[265]\tvalidation_0-rmse:0.00884\n",
            "[266]\tvalidation_0-rmse:0.00884\n",
            "[267]\tvalidation_0-rmse:0.00884\n",
            "[268]\tvalidation_0-rmse:0.00884\n",
            "[269]\tvalidation_0-rmse:0.00884\n",
            "[270]\tvalidation_0-rmse:0.00884\n",
            "[271]\tvalidation_0-rmse:0.00884\n",
            "[272]\tvalidation_0-rmse:0.00884\n",
            "[273]\tvalidation_0-rmse:0.00884\n",
            "[274]\tvalidation_0-rmse:0.00884\n",
            "[275]\tvalidation_0-rmse:0.00884\n",
            "[276]\tvalidation_0-rmse:0.00884\n",
            "[277]\tvalidation_0-rmse:0.00884\n",
            "[278]\tvalidation_0-rmse:0.00884\n",
            "[279]\tvalidation_0-rmse:0.00884\n",
            "[280]\tvalidation_0-rmse:0.00884\n",
            "[281]\tvalidation_0-rmse:0.00884\n",
            "[282]\tvalidation_0-rmse:0.00884\n",
            "[283]\tvalidation_0-rmse:0.00884\n",
            "[284]\tvalidation_0-rmse:0.00884\n",
            "[285]\tvalidation_0-rmse:0.00884\n",
            "[286]\tvalidation_0-rmse:0.00884\n",
            "[287]\tvalidation_0-rmse:0.00884\n",
            "[288]\tvalidation_0-rmse:0.00884\n",
            "[289]\tvalidation_0-rmse:0.00884\n",
            "[290]\tvalidation_0-rmse:0.00884\n",
            "[291]\tvalidation_0-rmse:0.00884\n",
            "[292]\tvalidation_0-rmse:0.00884\n",
            "[293]\tvalidation_0-rmse:0.00884\n",
            "[294]\tvalidation_0-rmse:0.00884\n",
            "[295]\tvalidation_0-rmse:0.00884\n",
            "[296]\tvalidation_0-rmse:0.00884\n",
            "[297]\tvalidation_0-rmse:0.00884\n",
            "[298]\tvalidation_0-rmse:0.00884\n",
            "[299]\tvalidation_0-rmse:0.00884\n",
            "[300]\tvalidation_0-rmse:0.00884\n",
            "[301]\tvalidation_0-rmse:0.00884\n",
            "[302]\tvalidation_0-rmse:0.00884\n",
            "[303]\tvalidation_0-rmse:0.00884\n",
            "[304]\tvalidation_0-rmse:0.00884\n",
            "[305]\tvalidation_0-rmse:0.00884\n",
            "[306]\tvalidation_0-rmse:0.00884\n",
            "[307]\tvalidation_0-rmse:0.00884\n",
            "[308]\tvalidation_0-rmse:0.00884\n",
            "[309]\tvalidation_0-rmse:0.00884\n",
            "[310]\tvalidation_0-rmse:0.00884\n",
            "[311]\tvalidation_0-rmse:0.00884\n",
            "[312]\tvalidation_0-rmse:0.00884\n",
            "[313]\tvalidation_0-rmse:0.00884\n",
            "[314]\tvalidation_0-rmse:0.00884\n",
            "[315]\tvalidation_0-rmse:0.00884\n",
            "[316]\tvalidation_0-rmse:0.00884\n",
            "[317]\tvalidation_0-rmse:0.00884\n",
            "[318]\tvalidation_0-rmse:0.00884\n",
            "[319]\tvalidation_0-rmse:0.00884\n",
            "[320]\tvalidation_0-rmse:0.00884\n",
            "[321]\tvalidation_0-rmse:0.00884\n",
            "[322]\tvalidation_0-rmse:0.00884\n",
            "[323]\tvalidation_0-rmse:0.00884\n",
            "[324]\tvalidation_0-rmse:0.00884\n",
            "[325]\tvalidation_0-rmse:0.00884\n",
            "[326]\tvalidation_0-rmse:0.00884\n",
            "[327]\tvalidation_0-rmse:0.00884\n",
            "[328]\tvalidation_0-rmse:0.00884\n",
            "[329]\tvalidation_0-rmse:0.00884\n",
            "[330]\tvalidation_0-rmse:0.00884\n",
            "[331]\tvalidation_0-rmse:0.00884\n",
            "[332]\tvalidation_0-rmse:0.00884\n",
            "[333]\tvalidation_0-rmse:0.00884\n",
            "[334]\tvalidation_0-rmse:0.00884\n",
            "[335]\tvalidation_0-rmse:0.00884\n",
            "[336]\tvalidation_0-rmse:0.00884\n",
            "[337]\tvalidation_0-rmse:0.00884\n",
            "[338]\tvalidation_0-rmse:0.00884\n",
            "[339]\tvalidation_0-rmse:0.00884\n",
            "[340]\tvalidation_0-rmse:0.00884\n",
            "[341]\tvalidation_0-rmse:0.00884\n",
            "[342]\tvalidation_0-rmse:0.00884\n",
            "[343]\tvalidation_0-rmse:0.00884\n",
            "[344]\tvalidation_0-rmse:0.00884\n",
            "[345]\tvalidation_0-rmse:0.00884\n",
            "[346]\tvalidation_0-rmse:0.00884\n",
            "[347]\tvalidation_0-rmse:0.00884\n",
            "[348]\tvalidation_0-rmse:0.00884\n",
            "[349]\tvalidation_0-rmse:0.00884\n",
            "[350]\tvalidation_0-rmse:0.00884\n",
            "[351]\tvalidation_0-rmse:0.00884\n",
            "[352]\tvalidation_0-rmse:0.00884\n",
            "[353]\tvalidation_0-rmse:0.00884\n",
            "[354]\tvalidation_0-rmse:0.00884\n",
            "[355]\tvalidation_0-rmse:0.00884\n",
            "[356]\tvalidation_0-rmse:0.00884\n",
            "[357]\tvalidation_0-rmse:0.00884\n",
            "[358]\tvalidation_0-rmse:0.00884\n",
            "[359]\tvalidation_0-rmse:0.00884\n",
            "[360]\tvalidation_0-rmse:0.00884\n",
            "[361]\tvalidation_0-rmse:0.00884\n",
            "[362]\tvalidation_0-rmse:0.00884\n",
            "[363]\tvalidation_0-rmse:0.00884\n",
            "[364]\tvalidation_0-rmse:0.00884\n",
            "[365]\tvalidation_0-rmse:0.00884\n",
            "[366]\tvalidation_0-rmse:0.00884\n",
            "[367]\tvalidation_0-rmse:0.00884\n",
            "[368]\tvalidation_0-rmse:0.00884\n",
            "[369]\tvalidation_0-rmse:0.00884\n",
            "[370]\tvalidation_0-rmse:0.00884\n",
            "[371]\tvalidation_0-rmse:0.00884\n",
            "[372]\tvalidation_0-rmse:0.00884\n",
            "[373]\tvalidation_0-rmse:0.00884\n",
            "[374]\tvalidation_0-rmse:0.00884\n",
            "[375]\tvalidation_0-rmse:0.00884\n",
            "[376]\tvalidation_0-rmse:0.00884\n",
            "[377]\tvalidation_0-rmse:0.00884\n",
            "[378]\tvalidation_0-rmse:0.00884\n",
            "[379]\tvalidation_0-rmse:0.00884\n",
            "[380]\tvalidation_0-rmse:0.00884\n",
            "[381]\tvalidation_0-rmse:0.00884\n",
            "[382]\tvalidation_0-rmse:0.00884\n",
            "[383]\tvalidation_0-rmse:0.00884\n",
            "[384]\tvalidation_0-rmse:0.00884\n",
            "[385]\tvalidation_0-rmse:0.00884\n",
            "[386]\tvalidation_0-rmse:0.00884\n",
            "[387]\tvalidation_0-rmse:0.00884\n",
            "[388]\tvalidation_0-rmse:0.00884\n",
            "[389]\tvalidation_0-rmse:0.00884\n",
            "[390]\tvalidation_0-rmse:0.00884\n",
            "[391]\tvalidation_0-rmse:0.00884\n",
            "[392]\tvalidation_0-rmse:0.00884\n",
            "[393]\tvalidation_0-rmse:0.00884\n",
            "[394]\tvalidation_0-rmse:0.00884\n",
            "[395]\tvalidation_0-rmse:0.00884\n",
            "[396]\tvalidation_0-rmse:0.00884\n",
            "[397]\tvalidation_0-rmse:0.00884\n",
            "[398]\tvalidation_0-rmse:0.00884\n",
            "[399]\tvalidation_0-rmse:0.00884\n",
            "[400]\tvalidation_0-rmse:0.00884\n",
            "[401]\tvalidation_0-rmse:0.00884\n",
            "[402]\tvalidation_0-rmse:0.00884\n",
            "[403]\tvalidation_0-rmse:0.00884\n",
            "[404]\tvalidation_0-rmse:0.00884\n",
            "[405]\tvalidation_0-rmse:0.00884\n",
            "[406]\tvalidation_0-rmse:0.00884\n",
            "[407]\tvalidation_0-rmse:0.00884\n",
            "[408]\tvalidation_0-rmse:0.00884\n",
            "[409]\tvalidation_0-rmse:0.00884\n",
            "[410]\tvalidation_0-rmse:0.00884\n",
            "[411]\tvalidation_0-rmse:0.00884\n",
            "[412]\tvalidation_0-rmse:0.00884\n",
            "[413]\tvalidation_0-rmse:0.00884\n",
            "[414]\tvalidation_0-rmse:0.00884\n",
            "[415]\tvalidation_0-rmse:0.00884\n",
            "[416]\tvalidation_0-rmse:0.00884\n",
            "[417]\tvalidation_0-rmse:0.00884\n",
            "[418]\tvalidation_0-rmse:0.00884\n",
            "[419]\tvalidation_0-rmse:0.00884\n",
            "[420]\tvalidation_0-rmse:0.00884\n",
            "[421]\tvalidation_0-rmse:0.00884\n",
            "[422]\tvalidation_0-rmse:0.00884\n",
            "[423]\tvalidation_0-rmse:0.00884\n",
            "[424]\tvalidation_0-rmse:0.00884\n",
            "[425]\tvalidation_0-rmse:0.00884\n",
            "[426]\tvalidation_0-rmse:0.00884\n",
            "[427]\tvalidation_0-rmse:0.00884\n",
            "[428]\tvalidation_0-rmse:0.00884\n",
            "[429]\tvalidation_0-rmse:0.00884\n",
            "[430]\tvalidation_0-rmse:0.00884\n",
            "[431]\tvalidation_0-rmse:0.00884\n",
            "[432]\tvalidation_0-rmse:0.00884\n",
            "[433]\tvalidation_0-rmse:0.00884\n",
            "[434]\tvalidation_0-rmse:0.00884\n",
            "[435]\tvalidation_0-rmse:0.00884\n",
            "[436]\tvalidation_0-rmse:0.00884\n",
            "[437]\tvalidation_0-rmse:0.00884\n",
            "[438]\tvalidation_0-rmse:0.00884\n",
            "[439]\tvalidation_0-rmse:0.00884\n",
            "[440]\tvalidation_0-rmse:0.00884\n",
            "[441]\tvalidation_0-rmse:0.00884\n",
            "[442]\tvalidation_0-rmse:0.00884\n",
            "[443]\tvalidation_0-rmse:0.00884\n",
            "[444]\tvalidation_0-rmse:0.00884\n",
            "[445]\tvalidation_0-rmse:0.00884\n",
            "[446]\tvalidation_0-rmse:0.00884\n",
            "[447]\tvalidation_0-rmse:0.00884\n",
            "[448]\tvalidation_0-rmse:0.00884\n",
            "[449]\tvalidation_0-rmse:0.00884\n",
            "[450]\tvalidation_0-rmse:0.00884\n",
            "[451]\tvalidation_0-rmse:0.00884\n",
            "[452]\tvalidation_0-rmse:0.00884\n",
            "[453]\tvalidation_0-rmse:0.00884\n",
            "[454]\tvalidation_0-rmse:0.00884\n",
            "[455]\tvalidation_0-rmse:0.00884\n",
            "[456]\tvalidation_0-rmse:0.00884\n",
            "[457]\tvalidation_0-rmse:0.00884\n",
            "[458]\tvalidation_0-rmse:0.00884\n",
            "[459]\tvalidation_0-rmse:0.00884\n",
            "[460]\tvalidation_0-rmse:0.00884\n",
            "[461]\tvalidation_0-rmse:0.00884\n",
            "[462]\tvalidation_0-rmse:0.00884\n",
            "[463]\tvalidation_0-rmse:0.00884\n",
            "[464]\tvalidation_0-rmse:0.00884\n",
            "[465]\tvalidation_0-rmse:0.00884\n",
            "[466]\tvalidation_0-rmse:0.00884\n",
            "[467]\tvalidation_0-rmse:0.00884\n",
            "[468]\tvalidation_0-rmse:0.00884\n",
            "[469]\tvalidation_0-rmse:0.00884\n",
            "[470]\tvalidation_0-rmse:0.00884\n",
            "[471]\tvalidation_0-rmse:0.00884\n",
            "[472]\tvalidation_0-rmse:0.00884\n",
            "[473]\tvalidation_0-rmse:0.00884\n",
            "[474]\tvalidation_0-rmse:0.00884\n",
            "[475]\tvalidation_0-rmse:0.00884\n",
            "[476]\tvalidation_0-rmse:0.00884\n",
            "[477]\tvalidation_0-rmse:0.00884\n",
            "[478]\tvalidation_0-rmse:0.00884\n",
            "[479]\tvalidation_0-rmse:0.00884\n",
            "[480]\tvalidation_0-rmse:0.00884\n",
            "[481]\tvalidation_0-rmse:0.00884\n",
            "[482]\tvalidation_0-rmse:0.00884\n",
            "[483]\tvalidation_0-rmse:0.00884\n",
            "[484]\tvalidation_0-rmse:0.00884\n",
            "[485]\tvalidation_0-rmse:0.00884\n",
            "[486]\tvalidation_0-rmse:0.00884\n",
            "[487]\tvalidation_0-rmse:0.00884\n",
            "[488]\tvalidation_0-rmse:0.00884\n",
            "[489]\tvalidation_0-rmse:0.00884\n",
            "[490]\tvalidation_0-rmse:0.00884\n",
            "[491]\tvalidation_0-rmse:0.00884\n",
            "[492]\tvalidation_0-rmse:0.00884\n",
            "[493]\tvalidation_0-rmse:0.00884\n",
            "[494]\tvalidation_0-rmse:0.00884\n",
            "[495]\tvalidation_0-rmse:0.00884\n",
            "[496]\tvalidation_0-rmse:0.00884\n",
            "[497]\tvalidation_0-rmse:0.00884\n",
            "[498]\tvalidation_0-rmse:0.00884\n",
            "[499]\tvalidation_0-rmse:0.00884\n",
            "[500]\tvalidation_0-rmse:0.00884\n",
            "[501]\tvalidation_0-rmse:0.00884\n",
            "[502]\tvalidation_0-rmse:0.00884\n",
            "[503]\tvalidation_0-rmse:0.00884\n",
            "[504]\tvalidation_0-rmse:0.00884\n",
            "[505]\tvalidation_0-rmse:0.00884\n",
            "[506]\tvalidation_0-rmse:0.00884\n",
            "[507]\tvalidation_0-rmse:0.00884\n",
            "[508]\tvalidation_0-rmse:0.00884\n",
            "[509]\tvalidation_0-rmse:0.00884\n",
            "[510]\tvalidation_0-rmse:0.00884\n",
            "[511]\tvalidation_0-rmse:0.00884\n",
            "[512]\tvalidation_0-rmse:0.00884\n",
            "[513]\tvalidation_0-rmse:0.00884\n",
            "[514]\tvalidation_0-rmse:0.00884\n",
            "[515]\tvalidation_0-rmse:0.00884\n",
            "[516]\tvalidation_0-rmse:0.00884\n",
            "[517]\tvalidation_0-rmse:0.00884\n",
            "[518]\tvalidation_0-rmse:0.00884\n",
            "[519]\tvalidation_0-rmse:0.00884\n",
            "[520]\tvalidation_0-rmse:0.00884\n",
            "[521]\tvalidation_0-rmse:0.00884\n",
            "[522]\tvalidation_0-rmse:0.00884\n",
            "[523]\tvalidation_0-rmse:0.00884\n",
            "[524]\tvalidation_0-rmse:0.00884\n",
            "[525]\tvalidation_0-rmse:0.00884\n",
            "[526]\tvalidation_0-rmse:0.00884\n",
            "[527]\tvalidation_0-rmse:0.00884\n",
            "[528]\tvalidation_0-rmse:0.00884\n",
            "[529]\tvalidation_0-rmse:0.00884\n",
            "[530]\tvalidation_0-rmse:0.00884\n",
            "[531]\tvalidation_0-rmse:0.00884\n",
            "[532]\tvalidation_0-rmse:0.00884\n",
            "[533]\tvalidation_0-rmse:0.00884\n",
            "[534]\tvalidation_0-rmse:0.00884\n",
            "[535]\tvalidation_0-rmse:0.00884\n",
            "[536]\tvalidation_0-rmse:0.00884\n",
            "[537]\tvalidation_0-rmse:0.00884\n",
            "[538]\tvalidation_0-rmse:0.00884\n",
            "[539]\tvalidation_0-rmse:0.00884\n",
            "[540]\tvalidation_0-rmse:0.00884\n",
            "[541]\tvalidation_0-rmse:0.00884\n",
            "[542]\tvalidation_0-rmse:0.00884\n",
            "[543]\tvalidation_0-rmse:0.00884\n",
            "[544]\tvalidation_0-rmse:0.00884\n",
            "[545]\tvalidation_0-rmse:0.00884\n",
            "[546]\tvalidation_0-rmse:0.00884\n",
            "[547]\tvalidation_0-rmse:0.00884\n",
            "[548]\tvalidation_0-rmse:0.00884\n",
            "[549]\tvalidation_0-rmse:0.00884\n",
            "[550]\tvalidation_0-rmse:0.00884\n",
            "[551]\tvalidation_0-rmse:0.00884\n",
            "[552]\tvalidation_0-rmse:0.00884\n",
            "[553]\tvalidation_0-rmse:0.00884\n",
            "[554]\tvalidation_0-rmse:0.00884\n",
            "[555]\tvalidation_0-rmse:0.00884\n",
            "[556]\tvalidation_0-rmse:0.00884\n",
            "[557]\tvalidation_0-rmse:0.00884\n",
            "[558]\tvalidation_0-rmse:0.00884\n",
            "[559]\tvalidation_0-rmse:0.00884\n",
            "[560]\tvalidation_0-rmse:0.00884\n",
            "[561]\tvalidation_0-rmse:0.00884\n",
            "[562]\tvalidation_0-rmse:0.00884\n",
            "[563]\tvalidation_0-rmse:0.00884\n",
            "[564]\tvalidation_0-rmse:0.00884\n",
            "[565]\tvalidation_0-rmse:0.00884\n",
            "[566]\tvalidation_0-rmse:0.00884\n",
            "[567]\tvalidation_0-rmse:0.00884\n",
            "[568]\tvalidation_0-rmse:0.00884\n",
            "[569]\tvalidation_0-rmse:0.00884\n",
            "[570]\tvalidation_0-rmse:0.00884\n",
            "[571]\tvalidation_0-rmse:0.00884\n",
            "[572]\tvalidation_0-rmse:0.00884\n",
            "[573]\tvalidation_0-rmse:0.00884\n",
            "[574]\tvalidation_0-rmse:0.00884\n",
            "[575]\tvalidation_0-rmse:0.00884\n",
            "[576]\tvalidation_0-rmse:0.00884\n",
            "[577]\tvalidation_0-rmse:0.00884\n",
            "[578]\tvalidation_0-rmse:0.00884\n",
            "[579]\tvalidation_0-rmse:0.00884\n",
            "[580]\tvalidation_0-rmse:0.00884\n",
            "[581]\tvalidation_0-rmse:0.00884\n",
            "[582]\tvalidation_0-rmse:0.00884\n",
            "[583]\tvalidation_0-rmse:0.00884\n",
            "[584]\tvalidation_0-rmse:0.00884\n",
            "[585]\tvalidation_0-rmse:0.00884\n",
            "[586]\tvalidation_0-rmse:0.00884\n",
            "[587]\tvalidation_0-rmse:0.00884\n",
            "[588]\tvalidation_0-rmse:0.00884\n",
            "[589]\tvalidation_0-rmse:0.00884\n",
            "[590]\tvalidation_0-rmse:0.00884\n",
            "[591]\tvalidation_0-rmse:0.00884\n",
            "[592]\tvalidation_0-rmse:0.00884\n",
            "[593]\tvalidation_0-rmse:0.00884\n",
            "[594]\tvalidation_0-rmse:0.00884\n",
            "[595]\tvalidation_0-rmse:0.00884\n",
            "[596]\tvalidation_0-rmse:0.00884\n",
            "[597]\tvalidation_0-rmse:0.00884\n",
            "[598]\tvalidation_0-rmse:0.00884\n",
            "[599]\tvalidation_0-rmse:0.00884\n",
            "[600]\tvalidation_0-rmse:0.00884\n",
            "[601]\tvalidation_0-rmse:0.00884\n",
            "[602]\tvalidation_0-rmse:0.00884\n",
            "[603]\tvalidation_0-rmse:0.00884\n",
            "[604]\tvalidation_0-rmse:0.00884\n",
            "[605]\tvalidation_0-rmse:0.00884\n",
            "[606]\tvalidation_0-rmse:0.00884\n",
            "[607]\tvalidation_0-rmse:0.00884\n",
            "[608]\tvalidation_0-rmse:0.00884\n",
            "[609]\tvalidation_0-rmse:0.00884\n",
            "[610]\tvalidation_0-rmse:0.00884\n",
            "[611]\tvalidation_0-rmse:0.00884\n",
            "[612]\tvalidation_0-rmse:0.00884\n",
            "[613]\tvalidation_0-rmse:0.00884\n",
            "[614]\tvalidation_0-rmse:0.00884\n",
            "[615]\tvalidation_0-rmse:0.00884\n",
            "[616]\tvalidation_0-rmse:0.00884\n",
            "[617]\tvalidation_0-rmse:0.00884\n",
            "[618]\tvalidation_0-rmse:0.00884\n",
            "[619]\tvalidation_0-rmse:0.00884\n",
            "[620]\tvalidation_0-rmse:0.00884\n",
            "[621]\tvalidation_0-rmse:0.00884\n",
            "[622]\tvalidation_0-rmse:0.00884\n",
            "[623]\tvalidation_0-rmse:0.00884\n",
            "[624]\tvalidation_0-rmse:0.00884\n",
            "[625]\tvalidation_0-rmse:0.00884\n",
            "[626]\tvalidation_0-rmse:0.00884\n",
            "[627]\tvalidation_0-rmse:0.00884\n",
            "[628]\tvalidation_0-rmse:0.00884\n",
            "[629]\tvalidation_0-rmse:0.00884\n",
            "[630]\tvalidation_0-rmse:0.00884\n",
            "[631]\tvalidation_0-rmse:0.00884\n",
            "[632]\tvalidation_0-rmse:0.00884\n",
            "[633]\tvalidation_0-rmse:0.00884\n",
            "[634]\tvalidation_0-rmse:0.00884\n",
            "[635]\tvalidation_0-rmse:0.00884\n",
            "[636]\tvalidation_0-rmse:0.00884\n",
            "[637]\tvalidation_0-rmse:0.00884\n",
            "[638]\tvalidation_0-rmse:0.00884\n",
            "[639]\tvalidation_0-rmse:0.00884\n",
            "[640]\tvalidation_0-rmse:0.00884\n",
            "[641]\tvalidation_0-rmse:0.00884\n",
            "[642]\tvalidation_0-rmse:0.00884\n",
            "[643]\tvalidation_0-rmse:0.00884\n",
            "[644]\tvalidation_0-rmse:0.00884\n",
            "[645]\tvalidation_0-rmse:0.00884\n",
            "[646]\tvalidation_0-rmse:0.00884\n",
            "[647]\tvalidation_0-rmse:0.00884\n",
            "[648]\tvalidation_0-rmse:0.00884\n",
            "[649]\tvalidation_0-rmse:0.00884\n",
            "[650]\tvalidation_0-rmse:0.00884\n",
            "[651]\tvalidation_0-rmse:0.00884\n",
            "[652]\tvalidation_0-rmse:0.00884\n",
            "[653]\tvalidation_0-rmse:0.00884\n",
            "[654]\tvalidation_0-rmse:0.00884\n",
            "[655]\tvalidation_0-rmse:0.00884\n",
            "[656]\tvalidation_0-rmse:0.00884\n",
            "[657]\tvalidation_0-rmse:0.00884\n",
            "[658]\tvalidation_0-rmse:0.00884\n",
            "[659]\tvalidation_0-rmse:0.00884\n",
            "[660]\tvalidation_0-rmse:0.00884\n",
            "[661]\tvalidation_0-rmse:0.00884\n",
            "[662]\tvalidation_0-rmse:0.00884\n",
            "[663]\tvalidation_0-rmse:0.00884\n",
            "[664]\tvalidation_0-rmse:0.00884\n",
            "[665]\tvalidation_0-rmse:0.00884\n",
            "[666]\tvalidation_0-rmse:0.00884\n",
            "[667]\tvalidation_0-rmse:0.00884\n",
            "[668]\tvalidation_0-rmse:0.00884\n",
            "[669]\tvalidation_0-rmse:0.00884\n",
            "[670]\tvalidation_0-rmse:0.00884\n",
            "[671]\tvalidation_0-rmse:0.00884\n",
            "[672]\tvalidation_0-rmse:0.00884\n",
            "[673]\tvalidation_0-rmse:0.00884\n",
            "[674]\tvalidation_0-rmse:0.00884\n",
            "[675]\tvalidation_0-rmse:0.00884\n",
            "[676]\tvalidation_0-rmse:0.00884\n",
            "[677]\tvalidation_0-rmse:0.00884\n",
            "[678]\tvalidation_0-rmse:0.00884\n",
            "[679]\tvalidation_0-rmse:0.00884\n",
            "[680]\tvalidation_0-rmse:0.00884\n",
            "[681]\tvalidation_0-rmse:0.00884\n",
            "[682]\tvalidation_0-rmse:0.00884\n",
            "[683]\tvalidation_0-rmse:0.00884\n",
            "[684]\tvalidation_0-rmse:0.00884\n",
            "[685]\tvalidation_0-rmse:0.00884\n",
            "[686]\tvalidation_0-rmse:0.00884\n",
            "[687]\tvalidation_0-rmse:0.00884\n",
            "[688]\tvalidation_0-rmse:0.00884\n",
            "[689]\tvalidation_0-rmse:0.00884\n",
            "[690]\tvalidation_0-rmse:0.00884\n",
            "[691]\tvalidation_0-rmse:0.00884\n",
            "[692]\tvalidation_0-rmse:0.00884\n",
            "[693]\tvalidation_0-rmse:0.00884\n",
            "[694]\tvalidation_0-rmse:0.00884\n",
            "[695]\tvalidation_0-rmse:0.00884\n",
            "[696]\tvalidation_0-rmse:0.00884\n",
            "[697]\tvalidation_0-rmse:0.00884\n",
            "[698]\tvalidation_0-rmse:0.00884\n",
            "[699]\tvalidation_0-rmse:0.00884\n",
            "[700]\tvalidation_0-rmse:0.00884\n",
            "[701]\tvalidation_0-rmse:0.00884\n",
            "[702]\tvalidation_0-rmse:0.00884\n",
            "[703]\tvalidation_0-rmse:0.00884\n",
            "[704]\tvalidation_0-rmse:0.00884\n",
            "[705]\tvalidation_0-rmse:0.00884\n",
            "[706]\tvalidation_0-rmse:0.00884\n",
            "[707]\tvalidation_0-rmse:0.00884\n",
            "[708]\tvalidation_0-rmse:0.00884\n",
            "[709]\tvalidation_0-rmse:0.00884\n",
            "[710]\tvalidation_0-rmse:0.00884\n",
            "[711]\tvalidation_0-rmse:0.00884\n",
            "[712]\tvalidation_0-rmse:0.00884\n",
            "[713]\tvalidation_0-rmse:0.00884\n",
            "[714]\tvalidation_0-rmse:0.00884\n",
            "[715]\tvalidation_0-rmse:0.00884\n",
            "[716]\tvalidation_0-rmse:0.00884\n",
            "[717]\tvalidation_0-rmse:0.00884\n",
            "[718]\tvalidation_0-rmse:0.00884\n",
            "[719]\tvalidation_0-rmse:0.00884\n",
            "[720]\tvalidation_0-rmse:0.00884\n",
            "[721]\tvalidation_0-rmse:0.00884\n",
            "[722]\tvalidation_0-rmse:0.00884\n",
            "[723]\tvalidation_0-rmse:0.00884\n",
            "[724]\tvalidation_0-rmse:0.00884\n",
            "[725]\tvalidation_0-rmse:0.00884\n",
            "[726]\tvalidation_0-rmse:0.00884\n",
            "[727]\tvalidation_0-rmse:0.00884\n",
            "[728]\tvalidation_0-rmse:0.00884\n",
            "[729]\tvalidation_0-rmse:0.00884\n",
            "[730]\tvalidation_0-rmse:0.00884\n",
            "[731]\tvalidation_0-rmse:0.00884\n",
            "[732]\tvalidation_0-rmse:0.00884\n",
            "[733]\tvalidation_0-rmse:0.00884\n",
            "[734]\tvalidation_0-rmse:0.00884\n",
            "[735]\tvalidation_0-rmse:0.00884\n",
            "[736]\tvalidation_0-rmse:0.00884\n",
            "[737]\tvalidation_0-rmse:0.00884\n",
            "[738]\tvalidation_0-rmse:0.00884\n",
            "[739]\tvalidation_0-rmse:0.00884\n",
            "[740]\tvalidation_0-rmse:0.00884\n",
            "[741]\tvalidation_0-rmse:0.00884\n",
            "[742]\tvalidation_0-rmse:0.00884\n",
            "[743]\tvalidation_0-rmse:0.00884\n",
            "[744]\tvalidation_0-rmse:0.00884\n",
            "[745]\tvalidation_0-rmse:0.00884\n",
            "[746]\tvalidation_0-rmse:0.00884\n",
            "[747]\tvalidation_0-rmse:0.00884\n",
            "[748]\tvalidation_0-rmse:0.00884\n",
            "[749]\tvalidation_0-rmse:0.00884\n",
            "[750]\tvalidation_0-rmse:0.00884\n",
            "[751]\tvalidation_0-rmse:0.00884\n",
            "[752]\tvalidation_0-rmse:0.00884\n",
            "[753]\tvalidation_0-rmse:0.00884\n",
            "[754]\tvalidation_0-rmse:0.00884\n",
            "[755]\tvalidation_0-rmse:0.00884\n",
            "[756]\tvalidation_0-rmse:0.00884\n",
            "[757]\tvalidation_0-rmse:0.00884\n",
            "[758]\tvalidation_0-rmse:0.00884\n",
            "[759]\tvalidation_0-rmse:0.00884\n",
            "[760]\tvalidation_0-rmse:0.00884\n",
            "[761]\tvalidation_0-rmse:0.00884\n",
            "[762]\tvalidation_0-rmse:0.00884\n",
            "[763]\tvalidation_0-rmse:0.00884\n",
            "[764]\tvalidation_0-rmse:0.00884\n",
            "[765]\tvalidation_0-rmse:0.00884\n",
            "[766]\tvalidation_0-rmse:0.00884\n",
            "[767]\tvalidation_0-rmse:0.00884\n",
            "[768]\tvalidation_0-rmse:0.00884\n",
            "[769]\tvalidation_0-rmse:0.00884\n",
            "[770]\tvalidation_0-rmse:0.00884\n",
            "[771]\tvalidation_0-rmse:0.00884\n",
            "[772]\tvalidation_0-rmse:0.00884\n",
            "[773]\tvalidation_0-rmse:0.00884\n",
            "[774]\tvalidation_0-rmse:0.00884\n",
            "[775]\tvalidation_0-rmse:0.00884\n",
            "[776]\tvalidation_0-rmse:0.00884\n",
            "[777]\tvalidation_0-rmse:0.00884\n",
            "[778]\tvalidation_0-rmse:0.00884\n",
            "[779]\tvalidation_0-rmse:0.00884\n",
            "[780]\tvalidation_0-rmse:0.00884\n",
            "[781]\tvalidation_0-rmse:0.00884\n",
            "[782]\tvalidation_0-rmse:0.00884\n",
            "[783]\tvalidation_0-rmse:0.00884\n",
            "[784]\tvalidation_0-rmse:0.00884\n",
            "[785]\tvalidation_0-rmse:0.00884\n",
            "[786]\tvalidation_0-rmse:0.00884\n",
            "[787]\tvalidation_0-rmse:0.00884\n",
            "[788]\tvalidation_0-rmse:0.00884\n",
            "[789]\tvalidation_0-rmse:0.00884\n",
            "[790]\tvalidation_0-rmse:0.00884\n",
            "[791]\tvalidation_0-rmse:0.00884\n",
            "[792]\tvalidation_0-rmse:0.00884\n",
            "[793]\tvalidation_0-rmse:0.00884\n",
            "[794]\tvalidation_0-rmse:0.00884\n",
            "[795]\tvalidation_0-rmse:0.00884\n",
            "[796]\tvalidation_0-rmse:0.00884\n",
            "[797]\tvalidation_0-rmse:0.00884\n",
            "[798]\tvalidation_0-rmse:0.00884\n",
            "[799]\tvalidation_0-rmse:0.00884\n",
            "[800]\tvalidation_0-rmse:0.00884\n",
            "[801]\tvalidation_0-rmse:0.00884\n",
            "[802]\tvalidation_0-rmse:0.00884\n",
            "[803]\tvalidation_0-rmse:0.00884\n",
            "[804]\tvalidation_0-rmse:0.00884\n",
            "[805]\tvalidation_0-rmse:0.00884\n",
            "[806]\tvalidation_0-rmse:0.00884\n",
            "[807]\tvalidation_0-rmse:0.00884\n",
            "[808]\tvalidation_0-rmse:0.00884\n",
            "[809]\tvalidation_0-rmse:0.00884\n",
            "[810]\tvalidation_0-rmse:0.00884\n",
            "[811]\tvalidation_0-rmse:0.00884\n",
            "[812]\tvalidation_0-rmse:0.00884\n",
            "[813]\tvalidation_0-rmse:0.00884\n",
            "[814]\tvalidation_0-rmse:0.00884\n",
            "[815]\tvalidation_0-rmse:0.00884\n",
            "[816]\tvalidation_0-rmse:0.00884\n",
            "[817]\tvalidation_0-rmse:0.00884\n",
            "[818]\tvalidation_0-rmse:0.00884\n",
            "[819]\tvalidation_0-rmse:0.00884\n",
            "[820]\tvalidation_0-rmse:0.00884\n",
            "[821]\tvalidation_0-rmse:0.00884\n",
            "[822]\tvalidation_0-rmse:0.00884\n",
            "[823]\tvalidation_0-rmse:0.00884\n",
            "[824]\tvalidation_0-rmse:0.00884\n",
            "[825]\tvalidation_0-rmse:0.00884\n",
            "[826]\tvalidation_0-rmse:0.00884\n",
            "[827]\tvalidation_0-rmse:0.00884\n",
            "[828]\tvalidation_0-rmse:0.00884\n",
            "[829]\tvalidation_0-rmse:0.00884\n",
            "[830]\tvalidation_0-rmse:0.00884\n",
            "[831]\tvalidation_0-rmse:0.00884\n",
            "[832]\tvalidation_0-rmse:0.00884\n",
            "[833]\tvalidation_0-rmse:0.00884\n",
            "[834]\tvalidation_0-rmse:0.00884\n",
            "[835]\tvalidation_0-rmse:0.00884\n",
            "[836]\tvalidation_0-rmse:0.00884\n",
            "[837]\tvalidation_0-rmse:0.00884\n",
            "[838]\tvalidation_0-rmse:0.00884\n",
            "[839]\tvalidation_0-rmse:0.00884\n",
            "[840]\tvalidation_0-rmse:0.00884\n",
            "[841]\tvalidation_0-rmse:0.00884\n",
            "[842]\tvalidation_0-rmse:0.00884\n",
            "[843]\tvalidation_0-rmse:0.00884\n",
            "[844]\tvalidation_0-rmse:0.00884\n",
            "[845]\tvalidation_0-rmse:0.00884\n",
            "[846]\tvalidation_0-rmse:0.00884\n",
            "[847]\tvalidation_0-rmse:0.00884\n",
            "[848]\tvalidation_0-rmse:0.00884\n",
            "[849]\tvalidation_0-rmse:0.00884\n",
            "[850]\tvalidation_0-rmse:0.00884\n",
            "[851]\tvalidation_0-rmse:0.00884\n",
            "[852]\tvalidation_0-rmse:0.00884\n",
            "[853]\tvalidation_0-rmse:0.00884\n",
            "[854]\tvalidation_0-rmse:0.00884\n",
            "[855]\tvalidation_0-rmse:0.00884\n",
            "[856]\tvalidation_0-rmse:0.00884\n",
            "[857]\tvalidation_0-rmse:0.00884\n",
            "[858]\tvalidation_0-rmse:0.00884\n",
            "[859]\tvalidation_0-rmse:0.00884\n",
            "[860]\tvalidation_0-rmse:0.00884\n",
            "[861]\tvalidation_0-rmse:0.00884\n",
            "[862]\tvalidation_0-rmse:0.00884\n",
            "[863]\tvalidation_0-rmse:0.00884\n",
            "[864]\tvalidation_0-rmse:0.00884\n",
            "[865]\tvalidation_0-rmse:0.00884\n",
            "[866]\tvalidation_0-rmse:0.00884\n",
            "[867]\tvalidation_0-rmse:0.00884\n",
            "[868]\tvalidation_0-rmse:0.00884\n",
            "[869]\tvalidation_0-rmse:0.00884\n",
            "[870]\tvalidation_0-rmse:0.00884\n",
            "[871]\tvalidation_0-rmse:0.00884\n",
            "[872]\tvalidation_0-rmse:0.00884\n",
            "[873]\tvalidation_0-rmse:0.00884\n",
            "[874]\tvalidation_0-rmse:0.00884\n",
            "[875]\tvalidation_0-rmse:0.00884\n",
            "[876]\tvalidation_0-rmse:0.00884\n",
            "[877]\tvalidation_0-rmse:0.00884\n",
            "[878]\tvalidation_0-rmse:0.00884\n",
            "[879]\tvalidation_0-rmse:0.00884\n",
            "[880]\tvalidation_0-rmse:0.00884\n",
            "[881]\tvalidation_0-rmse:0.00884\n",
            "[882]\tvalidation_0-rmse:0.00884\n",
            "[883]\tvalidation_0-rmse:0.00884\n",
            "[884]\tvalidation_0-rmse:0.00884\n",
            "[885]\tvalidation_0-rmse:0.00884\n",
            "[886]\tvalidation_0-rmse:0.00884\n",
            "[887]\tvalidation_0-rmse:0.00884\n",
            "[888]\tvalidation_0-rmse:0.00884\n",
            "[889]\tvalidation_0-rmse:0.00884\n",
            "[890]\tvalidation_0-rmse:0.00884\n",
            "[891]\tvalidation_0-rmse:0.00884\n",
            "[892]\tvalidation_0-rmse:0.00884\n",
            "[893]\tvalidation_0-rmse:0.00884\n",
            "[894]\tvalidation_0-rmse:0.00884\n",
            "[895]\tvalidation_0-rmse:0.00884\n",
            "[896]\tvalidation_0-rmse:0.00884\n",
            "[897]\tvalidation_0-rmse:0.00884\n",
            "[898]\tvalidation_0-rmse:0.00884\n",
            "[899]\tvalidation_0-rmse:0.00884\n",
            "[900]\tvalidation_0-rmse:0.00884\n",
            "[901]\tvalidation_0-rmse:0.00884\n",
            "[902]\tvalidation_0-rmse:0.00884\n",
            "[903]\tvalidation_0-rmse:0.00884\n",
            "[904]\tvalidation_0-rmse:0.00884\n",
            "[905]\tvalidation_0-rmse:0.00884\n",
            "[906]\tvalidation_0-rmse:0.00884\n",
            "[907]\tvalidation_0-rmse:0.00884\n",
            "[908]\tvalidation_0-rmse:0.00884\n",
            "[909]\tvalidation_0-rmse:0.00884\n",
            "[910]\tvalidation_0-rmse:0.00884\n",
            "[911]\tvalidation_0-rmse:0.00884\n",
            "[912]\tvalidation_0-rmse:0.00884\n",
            "[913]\tvalidation_0-rmse:0.00884\n",
            "[914]\tvalidation_0-rmse:0.00884\n",
            "[915]\tvalidation_0-rmse:0.00884\n",
            "[916]\tvalidation_0-rmse:0.00884\n",
            "[917]\tvalidation_0-rmse:0.00884\n",
            "[918]\tvalidation_0-rmse:0.00884\n",
            "[919]\tvalidation_0-rmse:0.00884\n",
            "[920]\tvalidation_0-rmse:0.00884\n",
            "[921]\tvalidation_0-rmse:0.00884\n",
            "[922]\tvalidation_0-rmse:0.00884\n",
            "[923]\tvalidation_0-rmse:0.00884\n",
            "[924]\tvalidation_0-rmse:0.00884\n",
            "[925]\tvalidation_0-rmse:0.00884\n",
            "[926]\tvalidation_0-rmse:0.00884\n",
            "[927]\tvalidation_0-rmse:0.00884\n",
            "[928]\tvalidation_0-rmse:0.00884\n",
            "[929]\tvalidation_0-rmse:0.00884\n",
            "[930]\tvalidation_0-rmse:0.00884\n",
            "[931]\tvalidation_0-rmse:0.00884\n",
            "[932]\tvalidation_0-rmse:0.00884\n",
            "[933]\tvalidation_0-rmse:0.00884\n",
            "[934]\tvalidation_0-rmse:0.00884\n",
            "[935]\tvalidation_0-rmse:0.00884\n",
            "[936]\tvalidation_0-rmse:0.00884\n",
            "[937]\tvalidation_0-rmse:0.00884\n",
            "[938]\tvalidation_0-rmse:0.00884\n",
            "[939]\tvalidation_0-rmse:0.00884\n",
            "[940]\tvalidation_0-rmse:0.00884\n",
            "[941]\tvalidation_0-rmse:0.00884\n",
            "[942]\tvalidation_0-rmse:0.00884\n",
            "[943]\tvalidation_0-rmse:0.00884\n",
            "[944]\tvalidation_0-rmse:0.00884\n",
            "[945]\tvalidation_0-rmse:0.00884\n",
            "[946]\tvalidation_0-rmse:0.00884\n",
            "[947]\tvalidation_0-rmse:0.00884\n",
            "[948]\tvalidation_0-rmse:0.00884\n",
            "[949]\tvalidation_0-rmse:0.00884\n",
            "[950]\tvalidation_0-rmse:0.00884\n",
            "[951]\tvalidation_0-rmse:0.00884\n",
            "[952]\tvalidation_0-rmse:0.00884\n",
            "[953]\tvalidation_0-rmse:0.00884\n",
            "[954]\tvalidation_0-rmse:0.00884\n",
            "[955]\tvalidation_0-rmse:0.00884\n",
            "[956]\tvalidation_0-rmse:0.00884\n",
            "[957]\tvalidation_0-rmse:0.00884\n",
            "[958]\tvalidation_0-rmse:0.00884\n",
            "[959]\tvalidation_0-rmse:0.00884\n",
            "[960]\tvalidation_0-rmse:0.00884\n",
            "[961]\tvalidation_0-rmse:0.00884\n",
            "[962]\tvalidation_0-rmse:0.00884\n",
            "[963]\tvalidation_0-rmse:0.00884\n",
            "[964]\tvalidation_0-rmse:0.00884\n",
            "[965]\tvalidation_0-rmse:0.00884\n",
            "[966]\tvalidation_0-rmse:0.00884\n",
            "[967]\tvalidation_0-rmse:0.00884\n",
            "[968]\tvalidation_0-rmse:0.00884\n",
            "[969]\tvalidation_0-rmse:0.00884\n",
            "[970]\tvalidation_0-rmse:0.00884\n",
            "[971]\tvalidation_0-rmse:0.00884\n",
            "[972]\tvalidation_0-rmse:0.00884\n",
            "[973]\tvalidation_0-rmse:0.00884\n",
            "[974]\tvalidation_0-rmse:0.00884\n",
            "[975]\tvalidation_0-rmse:0.00884\n",
            "[976]\tvalidation_0-rmse:0.00884\n",
            "[977]\tvalidation_0-rmse:0.00884\n",
            "[978]\tvalidation_0-rmse:0.00884\n",
            "[979]\tvalidation_0-rmse:0.00884\n",
            "[980]\tvalidation_0-rmse:0.00884\n",
            "[981]\tvalidation_0-rmse:0.00884\n",
            "[982]\tvalidation_0-rmse:0.00884\n",
            "[983]\tvalidation_0-rmse:0.00884\n",
            "[984]\tvalidation_0-rmse:0.00884\n",
            "[985]\tvalidation_0-rmse:0.00884\n",
            "[986]\tvalidation_0-rmse:0.00884\n",
            "[987]\tvalidation_0-rmse:0.00884\n",
            "[988]\tvalidation_0-rmse:0.00884\n",
            "[989]\tvalidation_0-rmse:0.00884\n",
            "[990]\tvalidation_0-rmse:0.00884\n",
            "[991]\tvalidation_0-rmse:0.00884\n",
            "[992]\tvalidation_0-rmse:0.00884\n",
            "[993]\tvalidation_0-rmse:0.00884\n",
            "[994]\tvalidation_0-rmse:0.00884\n",
            "[995]\tvalidation_0-rmse:0.00884\n",
            "[996]\tvalidation_0-rmse:0.00884\n",
            "[997]\tvalidation_0-rmse:0.00884\n",
            "[998]\tvalidation_0-rmse:0.00884\n",
            "[999]\tvalidation_0-rmse:0.00884\n",
            "\n",
            "Evaluation on Train:\n",
            "MSE: 6.848771590739489e-05\n",
            "MAE: 0.004621519707143307\n",
            "R2: -1.1920928955078125e-07\n",
            "\n",
            "Evaluation on Validation:\n",
            "MSE: 7.818187441444024e-05\n",
            "MAE: 0.004979636054486036\n",
            "R2: -0.0006011724472045898\n",
            "\n",
            "Evaluation on Test:\n",
            "MSE: 8.302374044433236e-05\n",
            "MAE: 0.004884067922830582\n",
            "R2: -0.0002225637435913086\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# ---- y_train, y_val, y_test are already regression targets (floats) ----\n",
        "y_train_tab = np.asarray(y_train, dtype=np.float32)\n",
        "y_val_tab = np.asarray(y_val, dtype=np.float32)\n",
        "y_test_tab = np.asarray(y_test, dtype=np.float32)\n",
        "\n",
        "# ---- XGBoost regressor ----\n",
        "xgb_reg = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=1000,              # high value; use early stopping\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    gamma=1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',             # 'gpu_hist' if you have GPU\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "\n",
        "# ---- Train with early stopping ----\n",
        "xgb_reg.fit(\n",
        "    X_train, y_train_tab,\n",
        "    eval_set=[(X_val, y_val_tab)],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# ---- Evaluate on train/validation/test ----\n",
        "print(\"\\nEvaluation on Train:\")\n",
        "y_pred_train = xgb_reg.predict(X_train)\n",
        "print(\"MSE:\", mean_squared_error(y_train_tab, y_pred_train))\n",
        "print(\"MAE:\", mean_absolute_error(y_train_tab, y_pred_train))\n",
        "print(\"R2:\", r2_score(y_train_tab, y_pred_train))\n",
        "\n",
        "print(\"\\nEvaluation on Validation:\")\n",
        "y_pred_val = xgb_reg.predict(X_val)\n",
        "print(\"MSE:\", mean_squared_error(y_val_tab, y_pred_val))\n",
        "print(\"MAE:\", mean_absolute_error(y_val_tab, y_pred_val))\n",
        "print(\"R2:\", r2_score(y_val_tab, y_pred_val))\n",
        "\n",
        "print(\"\\nEvaluation on Test:\")\n",
        "y_pred_test = xgb_reg.predict(X_test)\n",
        "print(\"MSE:\", mean_squared_error(y_test_tab, y_pred_test))\n",
        "print(\"MAE:\", mean_absolute_error(y_test_tab, y_pred_test))\n",
        "print(\"R2:\", r2_score(y_test_tab, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di2jwJEwhUtH"
      },
      "source": [
        "# O-O-F Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "P1VNAxG9xLC2"
      },
      "outputs": [],
      "source": [
        "# Use correct aligned length (should match X_train_seq or X_tab_aligned)\n",
        "n_samples = X_train_seq.shape[0]  # or X_tab_aligned.shape[0], should be 17607\n",
        "oof_cnn = np.zeros((n_samples, 3))\n",
        "oof_lstm = np.zeros((n_samples, 3))\n",
        "oof_xgb = np.zeros((n_samples, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BstRtL0ehVta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5044b1b4-9110-45dd-d637-95f31088be66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned lengths: tab=(42203, 34), seq=(42203, 128, 34), y=(42203,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# ==== Combine your split data back into one dataset ====\n",
        "X_tab = np.vstack([X_train, X_val, X_test])\n",
        "y_tab = np.concatenate([y_train, y_val, y_test])\n",
        "\n",
        "# ==== Time series split config ====\n",
        "n_splits = 3\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# ==== Align all arrays to the same length ====\n",
        "min_len = min(len(X_tab), len(X_train_seq), len(y_tab))\n",
        "\n",
        "X_tab_aligned = X_tab[:min_len]\n",
        "X_train_seq_aligned = X_train_seq[:min_len]\n",
        "y_tab_aligned = y_tab[:min_len]  # shape (min_len,)\n",
        "# If you need shape (min_len, 1) for DL models:\n",
        "# y_tab_aligned = y_tab_aligned.reshape(-1, 1)\n",
        "\n",
        "print(f\"Aligned lengths: tab={X_tab_aligned.shape}, seq={X_train_seq_aligned.shape}, y={y_tab_aligned.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3NN2CkhDvJ",
        "outputId": "d4dada9d-2b5a-483a-8707-1e9ff9c80ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating CNN OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Generating CNN OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq_aligned[train_idx], X_train_seq_aligned[val_idx]\n",
        "    y_seq_tr, y_seq_va = y_tab_aligned[train_idx], y_tab_aligned[val_idx]  # use continuous targets\n",
        "\n",
        "    # Build + compile\n",
        "    cnn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # use regression loss\n",
        "\n",
        "    # Train\n",
        "    cnn_model.fit(X_seq_tr, y_seq_tr, validation_data=(X_seq_va, y_seq_va),\n",
        "                  epochs=5, batch_size=64, verbose=0)\n",
        "    # Predict\n",
        "    oof_cnn[val_idx] = cnn_model.predict(X_seq_va, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjUIXAYdhGJ4",
        "outputId": "e95b57de-d6f1-4989-afaf-45b602fdbc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating LSTM OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Generating LSTM OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "    # Sequences\n",
        "    X_seq_tr, X_seq_va = X_train_seq_aligned[train_idx], X_train_seq_aligned[val_idx]\n",
        "    y_seq_tr, y_seq_va = y_tab_aligned[train_idx], y_tab_aligned[val_idx]\n",
        "    # Build + compile (make sure output units=1 for regression)\n",
        "    lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    # Train\n",
        "    lstm_model.fit(X_seq_tr, y_seq_tr, validation_data=(X_seq_va, y_seq_va),\n",
        "                   epochs=5, batch_size=64, verbose=0)\n",
        "    # Predict\n",
        "    oof_lstm[val_idx] = lstm_model.predict(X_seq_va, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlbAkv81hL4f",
        "outputId": "e4affa5c-75e9-4b35-82a5-9b99915c7cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Generating XGB OOF predictions ===\n",
            "\n",
            "--- Fold 1/3 ---\n",
            "\n",
            "--- Fold 2/3 ---\n",
            "\n",
            "--- Fold 3/3 ---\n",
            "oof_idx_xgb shape: (31650,)\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize OOF array (1D, for regression)\n",
        "oof_xgb = np.zeros(X_tab_aligned.shape[0])  # shape (N,)\n",
        "\n",
        "xgb_reg = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=1000,              # high value; use early stopping\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    min_child_weight=3,\n",
        "    gamma=1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist',             # 'gpu_hist' if you have GPU\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "\n",
        "print(\"=== Generating XGB OOF predictions ===\")\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_tab_aligned), 1):\n",
        "    print(f\"\\n--- Fold {fold}/{n_splits} ---\")\n",
        "    # Tabular split\n",
        "    X_tr_tab, X_va_tab = X_tab_aligned[train_idx], X_tab_aligned[val_idx]\n",
        "    y_tr_tab, y_va_tab = y_tab_aligned[train_idx], y_tab_aligned[val_idx]\n",
        "    # Train\n",
        "    xgb_reg.fit(X_tr_tab, y_tr_tab,\n",
        "                eval_set=[(X_va_tab, y_va_tab)],\n",
        "                verbose=False)\n",
        "    # Predict (continuous output)\n",
        "    oof_xgb[val_idx] = xgb_reg.predict(X_va_tab)\n",
        "\n",
        "# After all OOF prediction cells (CNN, LSTM, XGB)\n",
        "oof_idx_xgb = np.concatenate([val_idx for _, val_idx in tscv.split(X_tab_aligned)])\n",
        "print(\"oof_idx_xgb shape:\", oof_idx_xgb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tHDwGqD9_vv",
        "outputId": "4bc5e351-e17e-4c92-de3a-5cb41ec7aaa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 OOF predictions saved to oof_preds.pkl\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(\n",
        "    {\n",
        "        \"oof_cnn\": oof_cnn,\n",
        "        \"oof_lstm\": oof_lstm,\n",
        "        \"oof_xgb\": oof_xgb,\n",
        "        \"y\": y_tab_aligned  # continuous targets for regression\n",
        "    },\n",
        "    \"oof_preds.pkl\"\n",
        ")\n",
        "print(\"💾 OOF predictions saved to oof_preds.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhJxvxu9C6I8",
        "outputId": "43d09544-262c-4187-805f-1274a79f3aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned shapes: (31650, 3) (31650, 3) (31650,)\n"
          ]
        }
      ],
      "source": [
        "idx = np.asarray(oof_idx_xgb)  # shape (17607,)\n",
        "oof_cnn_aligned = np.asarray(oof_cnn)[idx]\n",
        "oof_lstm_aligned = np.asarray(oof_lstm)[idx]\n",
        "oof_xgb_aligned = np.asarray(oof_xgb)[idx]\n",
        "print(\"Aligned shapes:\", oof_cnn_aligned.shape, oof_lstm_aligned.shape, oof_xgb_aligned.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhKOAKMNxrMP"
      },
      "source": [
        "# META LEARNER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UY6W_zKg-fS",
        "outputId": "51c733c6-84d5-4122-b3e1-df0824c00fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta_X_train shape: (31650, 7)\n",
            "meta_y_train shape: (31650,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Ensure the XGB index mapping exists\n",
        "if 'oof_idx_xgb' not in globals():\n",
        "    raise RuntimeError(\"oof_idx_xgb not found. Re-run XGB OOF generation to set oof_idx_xgb.\")\n",
        "\n",
        "idx = np.asarray(oof_idx_xgb)\n",
        "\n",
        "# 2) Select aligned rows from CNN/LSTM/XGB using that mapping\n",
        "aligned_cnn = np.asarray(oof_cnn)[idx]   # shape (N_aligned,)\n",
        "aligned_lstm = np.asarray(oof_lstm)[idx] # shape (N_aligned,)\n",
        "aligned_xgb = np.asarray(oof_xgb)[idx]   # shape (N_aligned,)\n",
        "\n",
        "# 3) Sanity checks\n",
        "assert aligned_cnn.shape[0] == aligned_lstm.shape[0] == aligned_xgb.shape[0], \\\n",
        "       f\"Aligned shapes mismatch: cnn {aligned_cnn.shape} lstm {aligned_lstm.shape} xgb {aligned_xgb.shape}\"\n",
        "\n",
        "# 4) Build meta matrices (stacked predictions)\n",
        "meta_X_train = np.column_stack([aligned_cnn, aligned_lstm, aligned_xgb])  # shape: (N_aligned, 3)\n",
        "\n",
        "# Use the y that matches the aligned samples\n",
        "if 'y_tab_aligned' in globals():\n",
        "    meta_y_train = np.asarray(y_tab_aligned)[idx]\n",
        "elif 'y_tab' in globals():\n",
        "    meta_y_train = np.asarray(y_tab)[idx]\n",
        "else:\n",
        "    raise RuntimeError(\"No continuous target found for regression meta learner.\")\n",
        "\n",
        "print(\"meta_X_train shape:\", meta_X_train.shape)\n",
        "print(\"meta_y_train shape:\", meta_y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F859Av3p0qf",
        "outputId": "11dfd55f-6173-470b-cdd3-d01e3ebb58c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta X shape: (42203, 11)\n",
            "Feature names: ['cnn_pred', 'lstm_pred', 'xgb_pred', 'mean_pred', 'std_pred', 'max_pred', 'min_pred']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Stack base model predictions as features (shape: n_samples, 3)\n",
        "meta_preds = np.column_stack([oof_cnn, oof_lstm, oof_xgb])  # shape (n, 3)\n",
        "\n",
        "# Compute engineered meta-features derived from base model predictions:\n",
        "# - per-sample mean, std, max, min across base model predictions\n",
        "def meta_stats_from_preds(preds_block):\n",
        "    # preds_block shape (n_samples, n_models)\n",
        "    mean_pred = preds_block.mean(axis=1)\n",
        "    std_pred = preds_block.std(axis=1)\n",
        "    max_pred = preds_block.max(axis=1)\n",
        "    min_pred = preds_block.min(axis=1)\n",
        "    stats = np.vstack([mean_pred, std_pred, max_pred, min_pred]).T\n",
        "    stats_cols = [\"mean_pred\", \"std_pred\", \"max_pred\", \"min_pred\"]\n",
        "    return stats, stats_cols\n",
        "\n",
        "stats, stats_cols = meta_stats_from_preds(meta_preds)\n",
        "\n",
        "# Optionally add simple original features if available (e.g. last-hour vol, last return).\n",
        "# If you saved a features/labels DataFrame earlier, load and align here:\n",
        "# features_df = pd.read_parquet(\"features_aligned.parquet\")  # or load whatever you have\n",
        "# extra_feats = features_df.loc[:n-1, [\"vol_24h\", \"ret_1h\"]].to_numpy()\n",
        "\n",
        "# Build final meta_X from predictions + stats\n",
        "meta_X = np.hstack([meta_preds, stats])\n",
        "meta_feature_names = (\n",
        "    [f\"cnn_pred\", \"lstm_pred\", \"xgb_pred\"] +\n",
        "    stats_cols\n",
        ")\n",
        "\n",
        "print(\"Meta X shape:\", meta_X.shape)\n",
        "print(\"Feature names:\", meta_feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJul1btp2JA",
        "outputId": "93365c52-f047-43d7-fe4e-544503bbb10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes before fit: X_meta: (31650, 7) y_meta: (31650,)\n",
            "Final meta_learner model trained and saved to meta_learner.pkl\n",
            "Train RMSE: 0.007535525139827724\n",
            "Train MAE: 0.004260377820287832\n",
            "Train R2 Score: 0.027402236164692173\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Use aligned meta arrays produced earlier\n",
        "if 'meta_X_train' in globals() and 'meta_y_train' in globals():\n",
        "    X_meta = np.asarray(meta_X_train)\n",
        "    y_meta = np.asarray(meta_y_train)\n",
        "else:\n",
        "    raise RuntimeError(\"Aligned meta arrays not found. Make sure meta_X_train and meta_y_train exist.\")\n",
        "\n",
        "print(\"Shapes before fit: X_meta:\", X_meta.shape, \"y_meta:\", y_meta.shape)\n",
        "\n",
        "# sanity\n",
        "if X_meta.shape[0] != y_meta.shape[0]:\n",
        "    raise ValueError(f\"Shape mismatch: X_meta rows {X_meta.shape[0]} != y_meta {y_meta.shape[0]}\")\n",
        "\n",
        "# build final model with the best hyperparameters found earlier (best_cfg)\n",
        "try:\n",
        "    best_cfg  # noqa: F821\n",
        "except NameError:\n",
        "    # fallback: use the best config you printed: {'max_iter':200,'learning_rate':0.1,'max_depth':4}\n",
        "    best_cfg = {'max_iter': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
        "\n",
        "final_model = HistGradientBoostingRegressor(**best_cfg, early_stopping=True, random_state=42)\n",
        "final_model.fit(X_meta, y_meta)\n",
        "\n",
        "# Save the trained meta model\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n",
        "print(\"Final meta_learner model trained and saved to meta_learner.pkl\")\n",
        "\n",
        "# Quick train-set diagnostics (regression metrics)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "pred_train = final_model.predict(X_meta)\n",
        "print(\"Train RMSE:\", np.sqrt(mean_squared_error(y_meta, pred_train)))\n",
        "print(\"Train MAE:\", mean_absolute_error(y_meta, pred_train))\n",
        "print(\"Train R2 Score:\", r2_score(y_meta, pred_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LoSvckCSp8Mr"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from typing import Optional\n",
        "\n",
        "def load_and_predict_regression(\n",
        "    model_path: str,\n",
        "    meta_X: np.ndarray,\n",
        "    y: Optional[np.ndarray] = None,\n",
        "    verbose: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a saved regression meta model,\n",
        "    restricts meta_X to the first 7 features if needed,\n",
        "    predicts continuous values, and returns (preds).\n",
        "    \"\"\"\n",
        "    assert isinstance(meta_X, np.ndarray), \"meta_X must be a numpy array\"\n",
        "\n",
        "    # --- force only relevant features, e.g., 7 (3 base + 4 stats) ---\n",
        "    if meta_X.shape[1] > 7:\n",
        "        if verbose:\n",
        "            print(f\"[INFO] meta_X has {meta_X.shape[1]} features, truncating to first 7.\")\n",
        "        meta_X = meta_X[:, :7]\n",
        "    elif meta_X.shape[1] < 3:\n",
        "        raise ValueError(f\"meta_X has {meta_X.shape[1]} features, but at least 3 (base models) are required.\")\n",
        "\n",
        "    # Accept both 'meta_learner.pkl' and 'meta_model.pkl'\n",
        "    try:\n",
        "        obj = joblib.load(model_path)\n",
        "    except FileNotFoundError as e:\n",
        "        if model_path == \"meta_model.pkl\":\n",
        "            print(\"[WARN] meta_model.pkl not found, trying meta_learner.pkl instead.\")\n",
        "            obj = joblib.load(\"meta_learner.pkl\")\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    # Expect a fitted regressor\n",
        "    if isinstance(obj, dict):\n",
        "        if verbose:\n",
        "            print(\"Loaded dict artifact with keys:\", list(obj.keys()))\n",
        "        meta_model = obj.get(\"meta_model\") or obj.get(\"model\") or obj.get(\"estimator\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"Loaded estimator directly from\", model_path)\n",
        "        meta_model = obj\n",
        "\n",
        "    if meta_model is None:\n",
        "        raise RuntimeError(\"No 'meta_model' found in artifact and artifact is not a direct estimator.\")\n",
        "\n",
        "    # Get predictions\n",
        "    preds = meta_model.predict(meta_X)\n",
        "\n",
        "    # Diagnostics\n",
        "    if y is not None:\n",
        "        if len(y) != len(preds):\n",
        "            raise ValueError(f\"Length mismatch: y ({len(y)}) vs preds ({len(preds)})\")\n",
        "        rmse = np.sqrt(mean_squared_error(y, preds))\n",
        "        mae = mean_absolute_error(y, preds)\n",
        "        r2 = r2_score(y, preds)\n",
        "        if verbose:\n",
        "            print(f\"RMSE: {rmse:.4f}   MAE: {mae:.4f}   R2: {r2:.4f}\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"No ground-truth y provided; returning predictions only.\")\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1nvP47MjnKA"
      },
      "source": [
        "# save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nGTwsv4qpi6",
        "outputId": "a2ee3f97-5afb-4a63-e1fc-b04f3c5e739e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['meta_learner.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TdtsuwkPaxcH",
        "outputId": "9e77ca2a-448f-4f4a-e496-95b0fa9bdc67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf207e5a-374d-4e08-bb2e-ce1f6d08b730\", \"meta_learner.pkl\", 58616)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"meta_learner.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SF20g9Ys68Nb",
        "outputId": "1cbbd3d2-b8e8-427c-dd11-89d94c12adf5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed11164f-d0a6-4f39-8f24-165e8dbfc47c\", \"cnn_model.pkl\", 3939519)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_13d309b9-657c-4bef-a4ae-157c22fa7208\", \"lstm_model.pkl\", 1755876)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d53a336-a41e-4eca-ba06-9f025fdc547e\", \"xgb_model.pkl\", 706024)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save the three base models\n",
        "joblib.dump(cnn_model, \"cnn_model.pkl\")\n",
        "joblib.dump(lstm_model, \"lstm_model.pkl\")\n",
        "joblib.dump(xgb_reg, \"xgb_model.pkl\")  # change to your actual XGB var name\n",
        "\n",
        "# Download them\n",
        "files.download(\"cnn_model.pkl\")\n",
        "files.download(\"lstm_model.pkl\")\n",
        "files.download(\"xgb_model.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "layD2Oi7Tymv",
        "outputId": "6dd252d8-5099-4e46-b354-d4affc4983b8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab97ec82-221a-417d-a536-3b709a43c390\", \"scaler.pkl\", 2055)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "files.download(\"scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zOhIC-hbgPvo",
        "outputId": "05abb84b-f379-4a95-cb95-e42de546f923"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9dbe1abb-c917-484f-895b-0d51978a4c8b\", \"meta_learner.pkl\", 58616)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cfd6d8e3-62f1-4785-a7d0-7b72f49bb678\", \"cnn_model.pkl\", 3939519)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c5aeabb8-7d5f-4dc4-85ab-6e53364cb3d9\", \"lstm_model.pkl\", 1755876)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24a42fd5-0766-48c2-959f-f67637a455a7\", \"xgb_model.pkl\", 706024)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_500c6bad-2d60-4c04-a5c0-1d066da58e2c\", \"scaler.pkl\", 2055)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import joblib\n",
        "from google.colab import files\n",
        "\n",
        "# Save meta-learner\n",
        "joblib.dump(final_model, \"meta_learner.pkl\")\n",
        "files.download(\"meta_learner.pkl\")\n",
        "\n",
        "# Save three base models\n",
        "joblib.dump(cnn_model, \"cnn_model.pkl\")\n",
        "files.download(\"cnn_model.pkl\")\n",
        "\n",
        "joblib.dump(lstm_model, \"lstm_model.pkl\")\n",
        "files.download(\"lstm_model.pkl\")\n",
        "\n",
        "joblib.dump(xgb_reg, \"xgb_model.pkl\")  # Use your XGBRegressor variable name!\n",
        "files.download(\"xgb_model.pkl\")\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "files.download(\"scaler.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "START_CAPITAL = 10000\n",
        "model_col = 'pred_meta'  # or 'pred_cnn', etc.\n",
        "\n",
        "# Make sure to generate predictions for each test sequence and save to bt_df\n",
        "results = []\n",
        "for i in range(len(X_test_seq)):\n",
        "    seq_input = X_test_seq[i].reshape(1, *X_test_seq.shape[1:])  # shape (1, SEQ_LEN, n_features)\n",
        "    tab_input = X_test[i + SEQ_LEN - 1].reshape(1, -1)           # align tab input with sequence\n",
        "    y_true = y_test.iloc[i + SEQ_LEN - 1]\n",
        "\n",
        "    pred_cnn = cnn_model.predict(seq_input, verbose=0)[0][0]\n",
        "    pred_lstm = lstm_model.predict(seq_input, verbose=0)[0][0]\n",
        "    pred_xgb = xgb_reg.predict(tab_input)[0]\n",
        "\n",
        "    meta_X = np.array([[pred_cnn, pred_lstm, pred_xgb,\n",
        "                        np.mean([pred_cnn, pred_lstm, pred_xgb]),\n",
        "                        np.std([pred_cnn, pred_lstm, pred_xgb]),\n",
        "                        np.max([pred_cnn, pred_lstm, pred_xgb]),\n",
        "                        np.min([pred_cnn, pred_lstm, pred_xgb])]])\n",
        "    pred_meta = final_model.predict(meta_X)[0]\n",
        "\n",
        "    results.append({\n",
        "        'y_true': y_true,\n",
        "        'pred_cnn': pred_cnn,\n",
        "        'pred_lstm': pred_lstm,\n",
        "        'pred_xgb': pred_xgb,\n",
        "        'pred_meta': pred_meta\n",
        "    })\n",
        "\n",
        "bt_df = pd.DataFrame(results)\n",
        "\n",
        "# Trading simulation as before\n",
        "capital = START_CAPITAL\n",
        "pnl = []\n",
        "positions = []\n",
        "for idx, row in bt_df.iterrows():\n",
        "    pred = row[model_col]\n",
        "    realized = row['y_true']\n",
        "    # LONG if pred>0, SHORT if pred<0\n",
        "    if pred > 0:\n",
        "        pos = 1\n",
        "    elif pred < 0:\n",
        "        pos = -1\n",
        "    else:\n",
        "        pos = 0\n",
        "    positions.append(pos)\n",
        "    pnl.append(pos * realized * capital)\n",
        "\n",
        "equity_curve = np.cumsum(pnl) + START_CAPITAL\n",
        "final_capital = equity_curve[-1]\n",
        "total_pnl = final_capital - START_CAPITAL\n",
        "total_return_pct = (final_capital / START_CAPITAL - 1) * 100\n",
        "n_trades = np.count_nonzero(np.array(positions))\n",
        "\n",
        "print(f\"Backtest summary using '{model_col}':\")\n",
        "print(f\"Start capital:    ${START_CAPITAL:,.2f}\")\n",
        "print(f\"Final capital:    ${final_capital:,.2f}\")\n",
        "print(f\"Total PnL:        ${total_pnl:,.2f} ({total_return_pct:.2f}%)\")\n",
        "print(f\"Total trades:     {n_trades} (out of {len(bt_df)} hours)\")\n",
        "print(f\"Avg hourly PnL:   ${np.mean(pnl):.4f} ± ${np.std(pnl):.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(equity_curve, label=f'Equity Curve ({model_col})')\n",
        "plt.title('Trading Backtest - Equity Curve')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Portfolio Value ($)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "3KfL2I_766mk",
        "outputId": "f41605bf-9856-437f-a6d8-137a06eeaf78"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtest summary using 'pred_meta':\n",
            "Start capital:    $10,000.00\n",
            "Final capital:    $33,997.15\n",
            "Total PnL:        $23,997.15 (239.97%)\n",
            "Total trades:     8944 (out of 8944 hours)\n",
            "Avg hourly PnL:   $2.6830 ± $91.1666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA5PBJREFUeJzs3XdcE/cbB/BPEsLeGwQBxQEKbhH3BJVarVqtWlertVZrrdU6atXW2aGtv9Y6Wlfdo9a6ERXcE8UNKjJc7L0y7/dHkiNHEoZseN6vFy+Tu2/uvokZd8893+fLYxiGASGEEEIIIYQQQgghVYhf3R0ghBBCCCGEEEIIIfUPBaUIIYQQQgghhBBCSJWjoBQhhBBCCCGEEEIIqXIUlCKEEEIIIYQQQgghVY6CUoQQQgghhBBCCCGkylFQihBCCCGEEEIIIYRUOQpKEUIIIYQQQgghhJAqR0EpQgghhBBCCCGEEFLlKChFCCGEEEIIIYQQQqocBaUIIYQQUiF69uyJnj17svdjY2PB4/Gwbdu2autTdejZsydatmxZ3d2o0+rre4sQQgipaygoRQghhNQRPB6vVH9hYWHV3dVKFxYWpvG8ra2t0alTJ+zatau6uwcAWLFiBQ4fPlyp+7hy5QqWLFmCjIyMCt/2kiVLin2fJSQkVPg+i3PixAksWbKkUrYtk8mwdetW9OzZE9bW1jAwMIC7uzsmTpyIW7duVco+CSGEkPpAr7o7QAghhJCKsWPHDs79v//+GyEhIRrLvby8qqQ/bm5uyM/Ph1AorJL9aTNjxgx06NABAJCamop9+/bhww8/REZGBqZNm1Zt/QIUQanhw4djyJAhlbaPK1eu4LvvvsOECRNgaWlZKftYv349TE1NNZZX1v4A7e+tEydOYN26dRUemMrPz8fQoUNx6tQpdO/eHQsWLIC1tTViY2Oxf/9+bN++HfHx8XBxcanQ/RJCCCH1AQWlCCGEkDriww8/5Ny/du0aQkJCNJYXlZeXB2Nj4wrvD4/Hg6GhYYVvtyy6deuG4cOHs/enTp2KRo0aYffu3dUelKorhg8fDltb2yrdZ1W+t+bMmYNTp07hl19+wcyZMznrFi9ejF9++aVC9iOXyyEWi6v9M0MIIYRUJRq+RwghhNQjqnpH4eHh6N69O4yNjbFgwQIAwH///YegoCA4OzvDwMAAjRs3xtKlSyGTyTS2s2nTJjRu3BhGRkbo2LEjLl68qNFGW92fCRMmwNTUFK9evcKQIUNgamoKOzs7zJ49W2M/qampGDt2LMzNzWFpaYnx48fj7t275aolpK+vDysrK+jpca/Lbd26Fb1794a9vT0MDAzg7e2N9evXa93GyZMn0aNHD5iZmcHc3BwdOnTA7t27i93v6dOnYWxsjFGjRkEqlYLH4yE3Nxfbt29nh7tNmDCBbf/q1St89NFHcHBwgIGBAVq0aIEtW7ZobPe3335DixYtYGxsDCsrK7Rv357ty5IlSzBnzhwAgIeHB7uf2NjYMrxiFePly5cYMmQITExMYG9vjy+//BLBwcEaw0nd3d05r4NKSfXKJkyYgHXr1gHgDmNlGAbu7u4YPHiwxjYLCgpgYWGBKVOmFNvvjRs3ol+/fhoBKQAQCASYPXs2myU1YcIEuLu7a7RTDXVUx+PxMH36dOzatQstWrSAgYEBjh49Cmtra0ycOFFjG1lZWTA0NMTs2bPZZSKRCIsXL4anpycMDAzg6uqKr7/+GiKRSOdzIoQQQmoSypQihBBC6pnU1FQMGDAAH3zwAT788EM4ODgAALZt2wZTU1PMmjULpqamOHfuHBYtWoSsrCz89NNP7OM3b96MKVOmoHPnzpg5cyaeP3+Od999F9bW1nB1dS1x/zKZDIGBgfDz88PPP/+MM2fOYPXq1WjcuDGmTp0KQJE1MmjQINy4cQNTp05F8+bN8d9//2H8+PFleq7Z2dlISUkBAKSlpWH37t148OABNm/ezGm3fv16tGjRAu+++y709PRw9OhRfPbZZ5DL5ZyMqm3btuGjjz5CixYtMH/+fFhaWuLOnTs4deoURo8erbUPx44dw/DhwzFy5Ehs2bIFAoEAO3bswKRJk9CxY0d88sknAIDGjRsDABITE9GpUyc2aGFnZ4eTJ0/i448/RlZWFhsc+fPPPzFjxgwMHz4cX3zxBQoKCnDv3j1cv34do0ePxtChQ/HkyRPs2bMHv/zyC5vNZGdnV6bXsCRpaWkay/T09Njhe/n5+ejTpw/i4+MxY8YMODs7Y8eOHTh37lyF9WHKlCl4/fq1xnBVHo+HDz/8ED/++CPS0tJgbW3Nrjt69CiysrKKzSQ8efIkpFIpxo4dW2F9VXfu3Dns378f06dPh62tLZo0aYL33nsPhw4dwsaNG6Gvr8+2PXz4MEQiET744AMAis/Iu+++i0uXLuGTTz6Bl5cX7t+/j19++QVPnjyp9HplhBBCSIVgCCGEEFInTZs2jSn6U9+jRw8GALNhwwaN9nl5eRrLpkyZwhgbGzMFBQUMwzCMWCxm7O3tmdatWzMikYhtt2nTJgYA06NHD3ZZTEwMA4DZunUru2z8+PEMAOb777/n7KdNmzZMu3bt2Pv//PMPA4D59ddf2WUymYzp3bu3xja1CQ0NZQBo/PH5fGb58uWleu6BgYFMo0aN2PsZGRmMmZkZ4+fnx+Tn53PayuVy9naPHj2YFi1asM9DKBQykydPZmQyGecxJiYmzPjx4zX2+/HHHzNOTk5MSkoKZ/kHH3zAWFhYsH0dPHgwux9dfvrpJwYAExMTU2y7t7F48WKtrzEAplmzZmy7X3/9lQHA7N+/n12Wm5vLeHp6MgCY0NBQdrmbm5vW16RHjx4lvre0vd8ZhmGioqIYAMz69es5y999913G3d2d839X1JdffskAYO7cuaP7hVAzfvx4xs3NTWO56rVSp3o/Pnz4kLM8ODiYAcAcPXqUs3zgwIGc9+OOHTsYPp/PXLx4kdNuw4YNDADm8uXLpeozIYQQUp1o+B4hhBBSzxgYGGgdHmRkZMTeVmUYdevWDXl5eYiMjAQA3Lp1C0lJSfj00085WRwTJkyAhYVFqfvw6aefcu5369YNz58/Z++fOnUKQqEQkydPZpfx+fwy14FatGgRQkJCEBISgn379mHUqFH45ptvsHbtWk479eeemZmJlJQU9OjRA8+fP0dmZiYAICQkBNnZ2Zg3b55G3Z+iQ7MAYM+ePRg5ciSmTJmCjRs3gs8v+bCLYRj8888/GDRoEBiGQUpKCvsXGBiIzMxM3L59G4CikPjLly9x8+bNMr0mFe2ff/5hX2PV39atW9n1J06cgJOTE6e2l7GxMZshVtmaNm0KPz8/zqyLaWlpOHnyJMaMGaP1/04lKysLAGBmZlYpfevRowe8vb05y3r37g1bW1vs27ePXZaeno6QkBCMHDmSXXbgwAF4eXmhefPmnPdJ7969AQChoaGV0mdCCCGkItHwPUIIIaSeadCgASegpPLw4UMsXLgQ586dY0/GVVSBmbi4OABAkyZNOOuFQiEaNWpUqv0bGhpqDCGzsrJCeno6ez8uLg5OTk4aBdg9PT1LtQ8VHx8f9O3bl70/YsQIZGZmYt68eRg9ejTbj8uXL2Px4sW4evUq8vLyONvIzMyEhYUFoqOjAQAtW7Yscb8xMTH48MMP8f777+O3334rdX+Tk5ORkZGBTZs2YdOmTVrbJCUlAQDmzp2LM2fOoGPHjvD09ERAQABGjx6NLl26lHp/6nJycpCTk8PeFwgEpRrq171792ILncfFxcHT01Mj+NOsWbO36ufbGDduHKZPn464uDi4ubnhwIEDkEgkJQ7LMzc3B6AI0lYGDw8PjWV6enoYNmwYdu/eDZFIBAMDAxw6dAgSiYQTlHr69CkeP36s8/9I9T4hhBBCajLKlCKEEELqGfWsIJWMjAz06NEDd+/exffff4+jR48iJCQEP/zwAwBF/ZqKIhAIKmxbb6NPnz4oKCjAjRs3AADR0dHo06cPUlJSsGbNGhw/fhwhISH48ssvAbzdc3dyckLnzp1x4sQJ3Lp1q9SPU+3rww8/1Mg+Uv2pgk5eXl6IiorC3r170bVrV/zzzz/o2rUrFi9eXOb+AsDPP/8MJycn9q9Dhw5vtZ3y0JW1pK3Yfll88MEHEAqFbLbUzp070b59+xIDY82bNwcA3L9/v1T7KWv/tX0WVf3Nzs7GyZMnAQD79+9H8+bN0apVK7aNXC6Hj4+PzvfJZ599Vqo+E0IIIdWJMqUIIYQQgrCwMKSmpuLQoUPo3r07uzwmJobTzs3NDYAiS0M1TAgAJBIJYmJiOCfN5eHm5obQ0FDk5eVxsqWePXtW7m1LpVIAYLOCjh49CpFIhCNHjqBhw4Zsu6LDn1SFyB88eFBixpahoSGOHTuG3r17o3///jh//jxatGjBaaMtgGFnZwczMzPIZDJOhpcuJiYmGDlyJEaOHAmxWIyhQ4di+fLlmD9/PgwNDYsdmlbUuHHj0LVrV/a+roBJWbm5ueHBgwdgGIbTn6ioKI22VlZWyMjI0FgeFxdXYiZecc/V2toaQUFB2LVrF8aMGYPLly/j119/LbHvAwYMgEAgwM6dO0tV7Ly4/pdF9+7d4eTkhH379qFr1644d+4cvvnmG06bxo0b4+7du+jTp0+Z/p8JIYSQmoQypQghhBDCZi8xDMMuE4vF+OOPPzjt2rdvDzs7O2zYsAFisZhdvm3bNq0n428rMDAQEokEf/75J7tMLpdj3bp15d72sWPHAIANoGl77pmZmZy6SAAQEBAAMzMzrFy5EgUFBZx16o9VsbCwQHBwMOzt7dGvXz92+J+KiYmJxmsmEAgwbNgw/PPPP3jw4IHGNpOTk9nbqampnHX6+vrw9vYGwzCQSCTsPgCU6v+mUaNG6Nu3L/v3tsMAixo4cCBev36NgwcPssvy8vK0Dk9s3Lgxrl27xnlvHTt2DC9evChxPyU917Fjx+LRo0eYM2cOBAIBO4tdcVxdXTF58mScPn1a6zBMuVyO1atX4+XLl2z/MzMzce/ePbbNmzdv8O+//5a4L3V8Ph/Dhw/H0aNHsWPHDkilUs7QPUAxFPXVq1ecz4hKfn4+cnNzy7RPQgghpDpQphQhhBBC0LlzZ1hZWWH8+PGYMWMGeDweduzYoRFsEQqFWLZsGaZMmYLevXtj5MiRiImJwdatW0tdU6o0hgwZgo4dO+Krr77Cs2fP0Lx5cxw5cgRpaWkAis+KUXfx4kU2gJSWloYjR47g/Pnz+OCDD9ihWQEBAdDX18egQYMwZcoU5OTk4M8//4S9vT3evHnDbsvc3By//PILJk2ahA4dOmD06NGwsrLC3bt3kZeXh+3bt2vs39bWFiEhIejatSv69u2LS5cuoUGDBgCAdu3a4cyZM1izZg2cnZ3h4eEBPz8/rFq1CqGhofDz88PkyZPh7e2NtLQ03L59G2fOnGFfg4CAADg6OqJLly5wcHDA48eP8fvvvyMoKIgtzN2uXTsAwDfffMMOYRs0aBAbwKkIBw8ehKmpqcbyfv36wcHBAZMnT8bvv/+OcePGITw8HE5OTtixY4dGvTAAmDRpEg4ePIj+/ftjxIgRiI6Oxs6dO9ksteKonuuMGTMQGBioEXgKCgqCjY0NDhw4gAEDBsDe3r5Uz2/16tWIjo7GjBkzcOjQIbzzzjuwsrJCfHw8Dhw4gMjISHY/H3zwAebOnYv33nsPM2bMQF5eHtavX4+mTZuyBepLa+TIkfjtt9+wePFi+Pj4wMvLi7N+7Nix2L9/Pz799FOEhoaiS5cukMlkiIyMxP79+xEcHIz27duXaZ+EEEJIlau+if8IIYQQUpmmTZumMQ19jx49mBYtWmhtf/nyZaZTp06MkZER4+zszHz99dfs9PShoaGctn/88Qfj4eHBGBgYMO3bt2cuXLjA9OjRg+nRowfbJiYmhgHAbN26lV02fvx4xsTERGPfixcv1uhrcnIyM3r0aMbMzIyxsLBgJkyYwFy+fJkBwOzdu7fY5x4aGsoA4Pzp6+szzZs3Z5YvX86IxWJO+yNHjjC+vr6MoaEh4+7uzvzwww/Mli1bGABMTEyMRtvOnTszRkZGjLm5OdOxY0dmz5497Hptr/GzZ88YJycnxsvLi0lOTmYYhmEiIyOZ7t27M0ZGRgwAZvz48Wz7xMREZtq0aYyrqysjFAoZR0dHpk+fPsymTZvYNhs3bmS6d+/O2NjYMAYGBkzjxo2ZOXPmMJmZmZx9L126lGnQoAHD5/O1Pp+3pfo/0/Wn/p6Ji4tj3n33XcbY2JixtbVlvvjiC+bUqVNa31urV69mGjRowBgYGDBdunRhbt26Var3llQqZT7//HPGzs6O4fF4Gu8nhmGYzz77jAHA7N69u0zPVSqVMn/99RfTrVs3xsLCghEKhYybmxszceJE5s6dO5y2p0+fZlq2bMno6+szzZo1Y3bu3Kn1/Q2AmTZtms59yuVyxtXVlQHALFu2TGsbsVjM/PDDD0yLFi0YAwMDxsrKimnXrh3z3XffabwPCCGEkJqIxzBa8s0JIYQQQmqgw4cP47333sOlS5cqbHgZqR5hYWHo1asXQkND0bNnzyrZ55dffonNmzcjISFBa6YWIYQQQqoW1ZQihBBCSI2Un5/PuS+TyfDbb7/B3Nwcbdu2raZekdqqoKAAO3fuxLBhwyggRQghhNQQVFOKEEIIITXS559/jvz8fPj7+0MkEuHQoUO4cuUKVqxYUWEzw5G6LykpCWfOnMHBgweRmpqKL774orq7RAghhBAlCkoRQgghpEbq3bs3Vq9ejWPHjqGgoACenp747bffMH369OruGqlFHj16hDFjxsDe3h7/+9//0Lp16+ruEiGEEEKUqKYUIYQQQgghhBBCCKlyVFOKEEIIIYQQQgghhFQ5CkoRQgghhBBCCCGEkCpHNaUqiFwux+vXr2FmZgYej1fd3SGEEEIIIYQQQgipFgzDIDs7G87OzuDzdedDUVCqgrx+/Rqurq7V3Q1CCCGEEEIIIYSQGuHFixdwcXHRuZ6CUhXEzMwMgOIFNzc3r+bevD2JRILTp08jICAAQqGwurtDSL1Bnz1Cqgd99gipHvTZI6R60GePVJWsrCy4urqysRJdKChVQVRD9szNzWt9UMrY2Bjm5ub0JUVIFaLPHiHVgz57hFQP+uwRUj3os0eqWknljajQOSGEEEIIIYQQQgipchSUIoQQQgghhBBCCCFVjoJShBBCCCGEEEIIIaTKUU0pQgghhBBCCCG1hlwuh1gsru5u1EoSiQR6enooKCiATCar7u6QWkwoFEIgEJR7OxSUIoQQQgghhBBSK4jFYsTExEAul1d3V2olhmHg6OiIFy9elFiAmpCSWFpawtHRsVzvJQpKEUIIIYQQQgip8RiGwZs3byAQCODq6go+n6rRlJVcLkdOTg5MTU3p9SNvjWEY5OXlISkpCQDg5OT01tuioBQhhBBCCCGEkBpPKpUiLy8Pzs7OMDY2ru7u1EqqoY+GhoYUlCLlYmRkBABISkqCvb39Ww/lo3chIYQQQgghhJAaT1UDSV9fv5p7QggBwAaHJRLJW2+DglKEEEIIIYQQQmoNqoVESM1QEZ9FCkoRQgghhBBCCCGEkCpHQSlCCCGEEEIIIaSW27ZtGywtLau7GzXK2bNn4eXlxQ79rGoTJkzAkCFDqmXf5TVv3jx8/vnnlb4fCkoRQgghhBBCCCGVZMKECeDxeBp//fv3r9D9jBw5Ek+ePGHvL1myBK1bt66QbTMMg02bNsHPzw+mpqawtLRE+/bt8euvvyIvL69C9lEZvv76ayxcuPCti3DXBT179sTMmTPL/LjZs2dj+/bteP78ecV3Sg0FpQghhBBCCCGEkErUv39/vHnzhvO3Z8+eCt2HkZER7O3tK3SbKmPHjsXMmTMxePBghIaGIiIiAt9++y3+++8/nD59+q23KxaLK7CXXJcuXUJ0dDSGDRtWru1UZh9rMltbWwQGBmL9+vWVuh8KShFCCCGEEEIIIZXIwMAAjo6OnD8rKyt2/dOnT9G9e3cYGhrC29sbISEh4PF4OHz4MAAgLCwMPB4PGRkZ7GMiIiLA4/EQGxsLgDt8b9u2bfjuu+9w9+5dNjNr27Zt+PjjjzFy5EhO3yQSCezt7bF582atfd+/fz927dqFPXv2YMGCBejQoQPc3d0xePBgnDt3Dr169QKgPSNnyJAhmDBhAnvf3d0dS5cuxbhx42Bubo5PPvkEnTt3xty5czmPS05OhlAoxIULFwAAIpEIs2fPRoMGDWBiYgI/Pz+EhYUV+5rv3bsX/fr1g6GhIbtMlT22ceNGuLq6wtjYGCNGjEBmZibbRjXkbvny5XB2dkazZs0AAC9evMCIESNgaWkJa2trDB48mH3tAcXskLNmzYKlpSVsbGzw9ddfg2GYYvuormfPnvj8888xc+ZMWFlZwcHBAX/++Sdyc3MxceJEmJmZwdPTEydPnuQ87sGDBxgwYABMTU3h4OCAsWPHIiUlhX0u58+fx9q1a9n3QWxsLGQyGT7++GN4eHjAyMgIzZo1w9q1azX6NGjQIOzdu7fUz+FtUFCKEEJIrZSYVYCHrzNLbkgIIYSQOolhGOSJpdXyV5ZgQ0nkcjmGDh0KfX19XL9+HRs2bNAI0pTVyJEj8dVXX6FFixZsZtbIkSPx8ccf4+zZs3jz5g3b9tixY8jLy9MIVqns2rULzZo1w+DBgzXW8Xg8WFhYlKlvP//8M1q1aoU7d+7g22+/xZgxY7B3717Oa7pv3z44OzujW7duAIDp06fj6tWr2Lt3L+7du4f3338f/fv3x9OnT3Xu5+LFi2jfvr3G8mfPnmH//v04evQoTp06hTt37uCzzz7jtDl79iyioqIQEhKCY8eOQSKRIDAwEGZmZrh48SIuX74MU1NT9O/fn82kWr16NbZt24YtW7bg0qVLSEtLw7///lum12b79u2wtbXFjRs38Pnnn2Pq1Kl4//330blzZ9y+fRsBAQEYO3YsO2QyIyMDvXv3Rps2bXDr1i2cOnUKiYmJGDFiBABg7dq18Pf3x+TJk9n3gaurK+RyOVxcXHDgwAE8evQIixYtwoIFC7B//35Ofzp27IiXL19ygm8VTa/StkwIIYRUkoWH72PntXgAwMWve8HV2riae0QIIYSQqpYvkcF7UXC17PvR94Ew1i/96fSxY8dgamrKWbZgwQIsWLAAZ86cQWRkJIKDg+Hs7AwAWLFiBQYMGPDW/TMyMoKpqSn09PTg6OjILu/cuTOaNGmCnTt3soGvrVu34v3339fon8rTp0/ZbKGK0Lt3b3z11Vfs/REjRmDmzJm4dOkSG4TavXs3Ro0aBR6Ph/j4eGzduhXx8fHs6zN79mycOnUKW7duxYoVK7TuJy4ujm2vrqCgAH///TcaNGgAAPjtt98QFBSE1atXs6+ViYkJ/vrrL+jr6wMAdu7cCblcjr/++gs8Hg+A4nWztLREWFgYAgIC8Ouvv2L+/PkYOnQoAGDDhg0IDi7b+7NVq1ZYuHAhAGD+/PlYtWoVbG1tMXnyZADAokWLsH79ety7dw+dOnXC77//jjZt2nBegy1btsDV1RVPnjxB06ZNoa+vD2NjY877QCAQ4LvvvmPve3h44OrVq9i/fz8b0ALAvn5xcXFwd3cv03MpLQpKEUIIqRQiqQxSGQMTg4r7qfkj7Bl+Do6CXO3iZHRyDgWlCCGEEFKj9erVS6M2j7W1NQDg8ePHcHV15QRQ/P39K60vY8eOxbZt2zB37lwkJibi5MmTOHfunM72FZkVBkAje8nOzg4BAQHYtWsXunXrhpiYGFy9ehUbN24EANy/fx8ymQxNmzblPE4kEsHGxkbnfvLz8zlD91QaNmzIBqQAxWstl8sRFRXFBm58fHzYgBQA3L17F8+ePYOZmRlnWwUFBYiOjkZmZibevHkDPz8/dp2enh7at29fptfP19eXvS0QCGBjYwMfHx92mYODAwAgKSmJ7VdoaKjWgGJ0dLTGa6Zu3bp12LJlC+Lj45Gfnw+xWKxRGN/IyAgAKrWYPQWlCCGEVDixVI6+a84jVyTDxa97lTkwlZBZgAO3XmBMJzdYmygOCNaFPsNPwVEabdNya17xyZiUXGy+9Bxz+zeHmaGwurtDCCGE1ElGQgEefR9YbfsuCxMTE3h6er71/vh8ReUd9QCHRCJ5q2198MEH+O6773D16lVcuXIFHh4ebIaSNk2bNkVkZGSp+lg0AKOtjyYmJhrLxowZgxkzZuC3337D7t274ePjwwZjcnJyIBAIEB4erjGLnq7sLkBRqDs9Pb3EfmtTtI85OTlo164ddu3apdHWzs7urfahjVDIPW7k8XicZaosLblczvZr0KBB+OGHHzS25eTkpHM/e/fuxezZs7F69Wr4+/vDzMwMP/30E65fv85pl5aWBqBin2NRFJQihBBS4eLTcvEiLR8AEJWYjbYNFYU8rz9PxW/nnmHj2HZsoCo1R4QF/95H/5aOeK+NCwBg4eEHOPM4EWceJ+Kv8R3QYfkZzvYbWBqhlasFTtxPQHxa+a/cyOUMGAACPq/c25LK5Oj1cxgAYOe1eESvGFgh2yWEEEIIF4/HK9MQuprKy8sLL168wJs3b9hAwrVr1zhtVEGBN2/esAXSIyIiit2uvr4+ZDKZxnJVke6tW7fi6tWrmDhxYrHbGT16ND744AP8999/GnWlGIZBVlYWLCwsYGdnx6lVJZPJ8ODBA7YQenEGDx6MTz75BKdOncLu3bsxbtw4dl2bNm0gk8mQlJRUbPCsqDZt2uDRo0cay+Pj4/H69Ws2M+3atWvg8/nFDlFs27Yt9u3bB3t7e5ibm2tt4+TkhOvXr6N79+4AAKlUivDwcLRt27bUfS6rtm3b4p9//oG7uzv09LR/FrS9Dy5fvozOnTtzamlFR0drPPbBgwcQCoVo0aJFxXZcDRU6J4QQUuE+2FR4IBWTnAsAKJDIMHLTNVx6loK/r8ax6/++Gofgh4n4ct9dZOYprqadeZwIALj7MhMLD9/nbPvbd7wRMqs7mtgr0qd/PfMUydmit+6rVCZHowUn0HjBCRRINA/cyiohq4Bzv/2ykApPeyeEEEJI7SISiZCQkMD5U82Q1rdvXzRt2hTjx4/H3bt3cfHiRXzzzTecx3t6esLV1RVLlizB06dPcfz4caxevbrYfbq7uyMmJgYRERFISUmBSFR4vPTxxx9j+/btePz4McaPH1/sdkaMGIGRI0di1KhRWLFiBW7duoW4uDgcO3YMffv2RWhoKABFrajjx4/j+PHjiIyMxNSpUzmzBRbHxMQEQ4YMwbfffovHjx9j1KhR7LqmTZtizJgxGDduHA4dOoSYmBjcuHEDK1euxPHjx3VuMzAwEJcuXdJYbmhoyHmtZ8yYgREjRnBqLhU1ZswY2NraYvDgwbh48SJiYmIQFhaGGTNm4OXLlwCAL774AqtWrcLhw4cRGRmJzz77rNTP/21NmzYNaWlpGDVqFG7evIno6GgEBwdj4sSJbCDK3d0d169fR2xsLFJSUiCXy9GkSRPcunULwcHBePLkCb799lvcvHlTY/sXL15Et27d2GF8lYGCUoQQQirU7fh0pOQUDqk7eu81AOD3c8/YZVsuxwAAniRmY+3ZwllTRv/FvSoIAMEPE9nbOz/2w8ddPWCsrwc+rzD76PyT5Lfq66PXWfD8pnBa3V9CnuBg+Eu4zzuOSds1f5hLo+hwwvQ8CQ5HvHqrbRFCCCGkbjh16hScnJw4f127dgWgGPb277//Ij8/Hx07dsSkSZOwfPlyzuOFQiH27NmDyMhI+Pr64ocffsCyZcuK3eewYcPQv39/9OrVC3Z2dtizZw+7rm/fvnByckJgYKDWYuDqeDwedu/ejTVr1uDw4cPo0aMHfH19sWTJEgwePBiBgYohlB999BHGjx+PcePGoUePHmjUqFGpsqRUxowZg7t376Jbt25o2LAhZ93WrVsxbtw4fPXVV2jWrBmGDBmCmzdvarQrur2HDx8iKopb/sHT0xNDhw7FwIEDERAQAF9fX/zxxx/F9s3Y2BgXLlxAw4YNMXToUHh5eeHjjz9GQUEBmzn11VdfYezYsRg/fjw7JO69994r9fN/G87Ozrh8+TJkMhkCAgLg4+ODmTNnwtLSkh3yOXv2bAgEAnh7e8POzg7x8fGYMmUKhg4dipEjR8LPzw+pqakaMxACimF+qiLrlYXH0OXbCqFKWczMzNSZzlcbSCQSnDhxAgMHDtQYz0oIqTx15bN3JToFo/+8rrHc3cYYsancYXb/TPXHihORCI/jjvWPXRUE93ncq17mhnq4syiAMwwuM1+CVt+dBgD8ONwXI9q7au3Ts6Rs9F1zAb4uFjg0tTP0BHw8ep2Fgf+7WOLzub6gDxzMNQtkFicsKgkTtt6El5M5nCwMcS4yCb2a2WHrxI5l2g6pGnXls0dIbUOfPfI2CgoKEBMTAw8PD60FrOsaHo+Hf//9F0OGDKmwbcrlcmRlZYHP58PV1RVbt25lZ4uri+bMmYOsrCy2aPqSJUtw+PDhEoc+EuDkyZP46quvcO/ePZ1DA4v7TJY2RkKZUoQQQiqMtoAUAI2AFAD8F/EaYqlcY3meWAoTfW4RS097U426TBZGQgT5Kuou5ImkAACJTI7zT5LZ7eaKpOi75gIA4N7LTHh+cxLu846XKiAFAH4rzpaqnTpVppSNiT6+ClDMeHI9Jg0SmeZzJYQQQgipSnK5HMnJyVi2bBksLS3x7rvvVneXKtU333wDNzc3tjA4Kb3c3Fxs3bpVZ0CqolBQihBCSKX436g26NTIWuf6v6/G4f6rTADAn+MKpwb2XhSMXLEMZmoz9g1vpz0Lylg5803EiwwAwG/nnmH8lhvouOIMGIZBj59Cy/s0yiwlR1GvwcZUH16O5jA31EOeWIbHb7KqvC+EEEIIIeri4+PRtGlT7NmzB1u2bKn0gEN1s7S0xIIFC9ihbNUlPj4epqamOv/i4+OrtX/aDB8+HH5+fpW+n7r9DiSEEFJt3m3ljLYNLdH1h1CM83fDR108IJXL2cwldX297OFsYYjXmYVFwn1cLPDnuPZIzRGjoY2x1n3EKTOwDke8xuA2DfA/ZX2qjDwJvjv6iFPbSpc/xrTFzdg0bL0cq3U9wzDYfCkG9uaGeLdV8TUXACAxSxGUcjQ3BJ/PQ1s3K4RFJeNWbDp8XSxLfDwhhBBCCIBKmSjF3d0d6enpMDc3r/ZATXVYsmQJlixZUuX7dXZ2LnbIYEl1veoyCkoRQgipMLamBkjJEeHkF4rpel2sjBG7KojTZnZAU/x8+gl7f+uEDuDxeDg3uyeaf3uKXe5hawITAz2YGOj+qerRzA43YtMAABO3cguTb7sSy7m/+v1WaOpghvf+uIzZgc3Qwtkc3Zoopldu7WoJGxN9GAoF6OJpi4+33WQDZHdfZmLZ8ccAgBl77uDGgj6wL6bO1FZlEXdVm/bKoNT3xx5htF9DyOQMRv91HYZ6fOz9pBN4PJ7ObRFCCCGEkNpPT08Pnp6e1d2NGomCUoQQQsrl9MMErAt9hlXDfNmhayb6un9eTNWCTANaOqJXc3sAgKFQAD0+D1K54qqgm47sKHXTennip2DujCoTu7hzsp4OfOqPfLEM3ZrYgsfj4dmKgRrbcbY0wvTeTdj7uyd3Qs+fw2BqoIekrAJO2y/3R2DXpE4l9s1YWRfL27mwsGPzb09hjF9D3FUON8zKl8LCmAr8EkIIIYSQ+qn+5esRQgipMCKpDJ/sCMfdl5kYsLaweLi9uYHOxxipFTEf1taFs04VkAKACZ09StWHGwv6sLc/69kY3wZ5o72bFSyNhfh1ZGt0cLdG96Z2ZcpIMjVUBM5yRFKNIYCXn6XqfBzDMFA9ha6etgAUAS91u64X1gzIKpCUuk+EEEIIUaAJ5AmpGSris0iZUoQQQt7K31djsei/h1rXGQoFWpcD4AR5uje109rGycIQ+nqlu25ib26I2FVBSM0RwcpYH3w+DwendgbDMG89NE49m+veywzOulauljofl55XGGRyUA7fa+5ojp+G+2LOwXsa7TPzJdBewp0QQgghRQkEiuMLsVgMIyOjEloTQipbXp6ivqtQ+PaZ/xSUIoQQUmYMw+gMSJWkq6ctfgqO0hp42jqxA3ZcjcOqoT5l3q6NKTc7qzy1mgz0+NAX8CGWyRH8MAEAMLRNAxy684odeqdNcrZi+KKVsZDz3N5v74r327siNCoJ4bHp2H/rBZKyRZQpRQghhJSBnp4ejI2NkZycDKFQWC8LdZeXXC6HWCxGQUEBvX7krTEMg7y8PCQlJcHS0pINGL8NCkoRQggps2yRlHO/WxNbXHyaAgBo5mBW7GNbuVri2Odd4WKleYWzVzN79GpmX3EdfUs8Hg9CAQ9iWWH2U6dGNjh05xUA4L+IV/BvZKNR8Dw1VxGUKhogU1E9vyvRKYqgVL5UaztCCCGEaOLxeHByckJMTAzi4uKquzu1EsMwyM/Ph5GREU22QsrN0tISjo6O5doGBaUIIYSUWUR8BnvbUMjH7IBmbFBqtF/DEh/fsoFFZXWtwuSKZZz7BsLCq4lf7I0AAI2ZBdNzFQEsa2P9YrdtbqRIcaZMKUIIIaRs9PX10aRJE4jF4pIbEw0SiQQXLlxA9+7dyzXkihChUFiuDCkVCkoRQggptSeJ2Qj45QJn2eW5vWFtog8nC0O8ySxAtya21dS7imWgx4dIKgcAmBnooXdzzQyuzDwJZ/a89DzFAbKVSfEHeeaGyqBUPgWlCCGEkLLi8/kwNDQsuSHRIBAIIJVKYWhoSEEpUiNU6yDS9evXw9fXF+bm5jA3N4e/vz9OnjzJru/Zsyd4PB7n79NPP+VsIz4+HkFBQTA2Noa9vT3mzJkDqZQ7HCIsLAxt27aFgYEBPD09sW3bNo2+rFu3Du7u7jA0NISfnx9u3LhRKc+ZEEJqK7FUrhGQGtbWBTamBuDxeLjwdS88/C4QjexMq6mHFStyaX/4uigyuv4c3x5mhkL4eVhz2oQ8TuTcT89VBqVKyJQyUNabulNMfSpCCCGEEELqumoNSrm4uGDVqlUIDw/HrVu30Lt3bwwePBgPHxYWz508eTLevHnD/v3444/sOplMhqCgIIjFYly5cgXbt2/Htm3bsGjRIrZNTEwMgoKC0KtXL0RERGDmzJmYNGkSgoOD2Tb79u3DrFmzsHjxYty+fRutWrVCYGAgkpKSquaFIISQWqD/Wm5Aqndze6we0Yq9LxTwYWJQdxJweTwejkzvithVQejUyAYAcD0mjdPm4tNkzv00NlOq+KDUyQeK4unH772pqO4SQgghhBBS61RrUGrQoEEYOHAgmjRpgqZNm2L58uUwNTXFtWvX2DbGxsZwdHRk/8zNzdl1p0+fxqNHj7Bz5060bt0aAwYMwNKlS7Fu3Tp2jPGGDRvg4eGB1atXw8vLC9OnT8fw4cPxyy+/sNtZs2YNJk+ejIkTJ8Lb2xsbNmyAsbExtmzZUnUvBiGE1GC5IimeJ+ey9yOX9seWCR2qsUc1w38RrzFlxy1IZYphfqrZ92xKCEqN7OBa6X0jhBBCCCGkpqsxc0DKZDLs3bsXubm58Pf3Z5fv2rULtra2aNmyJebPn4+8vDx23dWrV+Hj4wMHBwd2WWBgILKysthsq6tXr6Jv376cfQUGBuLq1asAALFYjPDwcE4bPp+Pvn37sm0IIaS+S80pLCa64cO2MBSWv6hhbfS/UW0gFPCw9oPW7LLgh4nYdiUWABCtDNy525gUu50+Xor6VE3s68ZQR0IIIYQQQt5GtY+zuH//Pvz9/VFQUABTU1P8+++/8Pb2BgCMHj0abm5ucHZ2xr179zB37lxERUXh0KFDAICEhAROQAoAez8hIaHYNllZWcjPz0d6ejpkMpnWNpGRkTr7LRKJIBKJ2PtZWVkAFLMZSCS1t3Ctqu+1+TkQUhvV9M9eToHi+87UQA99mtnW2H5WtgHeduizsA/09fhIHtgMy05EAQAO33mFDzu64HlyDgDA3caw2NfIWE8xBXNmfu3+zagLavpnj5C6ij57hFQP+uyRqlLa91i1B6WaNWuGiIgIZGZm4uDBgxg/fjzOnz8Pb29vfPLJJ2w7Hx8fODk5oU+fPoiOjkbjxo2rsdfAypUr8d1332ksP336NIyNjauhRxUrJCSkurtASL1UUz97L3IAQA96jAQnTpyo7u7UCHYAvm0DLL2jhwevs/DN1lMQSQXQ4zG4fzUMD3m6H5taAAB6SM8tqLDXMy4HCHvNx1APOcxoMp0yq6mfPULqOvrsEVI96LNHKpv6KLfiVHtQSl9fH56engCAdu3a4ebNm1i7di02btyo0dbPzw8A8OzZMzRu3BiOjo4as+QlJipmQnJ0dGT/VS1Tb2Nubg4jIyMIBAIIBAKtbVTb0Gb+/PmYNWsWez8rKwuurq4ICAjg1L2qbSQSCUJCQtCvXz+aIpSQKlTTP3u34zOA+zdgYWqCgQO7Vnd3apQI2T0cvZeAf2IVQxo9HczxTpB/sY/JzJfg+zuhkMh56BPQn52N7239GPwEf96PBQBY2jpg44dtyrW9+qSmf/YIqavos0dI9aDPHqkqqtFkJan2oFRRcrmcMyxOXUREBADAyckJAODv74/ly5cjKSkJ9vaK+hwhISEwNzdnhwD6+/trXIUOCQlh61bp6+ujXbt2OHv2LIYMGcL24ezZs5g+fbrOfhoYGMDAwEBjuVAorBMf7rryPAipbWrqZ0/GKNJ+DIWCGtm/6rTsPV+cf5KCrAIpAKCJg1mJr5E5r7Aml4zhl+s1Tc4W4c9Lsez9B6+z6P/oLdTUzx4hdR199gipHvTZI5WttO+vai10Pn/+fFy4cAGxsbG4f/8+5s+fj7CwMIwZMwbR0dFYunQpwsPDERsbiyNHjmDcuHHo3r07fH19AQABAQHw9vbG2LFjcffuXQQHB2PhwoWYNm0aGzD69NNP8fz5c3z99deIjIzEH3/8gf379+PLL79k+zFr1iz8+eef2L59Ox4/foypU6ciNzcXEydOrJbXhRBCahqRVDG7nIGwxsyPUWNYGAkxd0Bz9r6ZYcnXe4QCHgR8RaCvQCor1/7zxFLOfT1+MeMGCSGEEEIIqUGq9ewiKSkJ48aNQ7NmzdCnTx/cvHkTwcHB6NevH/T19XHmzBkEBASgefPm+OqrrzBs2DAcPXqUfbxAIMCxY8cgEAjg7++PDz/8EOPGjcP333/PtvHw8MDx48cREhKCVq1aYfXq1fjrr78QGBjIthk5ciR+/vlnLFq0CK1bt0ZERAROnTqlUfycEELqq5n7IgAArzMKqrcjNdQYPzfYmSkuhvRoaldiex6PB0PlkL18cfmCUgUSOef+68wCtF0aggtPksu1XUIIIYQQQipbtQ7f27x5s851rq6uOH/+fInbcHNzK7FIbM+ePXHnzp1i20yfPr3Y4XqEEFKfZeYrZs9IydE+vJoAxz7virsvMtDPu3QXNAyFAuSKZeXOlCqQKB7vbGEIb2cLnHmciLRcMcZtuYFnyweAx+Ph053hSMoWYe/kTjDSF5SwRUIIIYQQQqoGjcMghBBCKoCDuSECWjiCxyvd8DlDoSI4VDTTqaxUQSlDoQBt3Sw5654k5mDvzXiEPErE3RcZ8Fp0CtkFNAU0IYQQQgipGSgoRQghhFQDQ2HFDN8rrPclwPC2LvC0N2XXXX2eit/OPuO091lyulz7I4QQQgghpKJQUIoQQkipfdWvaXV3oc5gM6V0DN8TS+X4KTgSUQnZxW7nv4jXyu3xYW9uiDOzemCMX0MAwNJjj5CQpVkH7NHr0k3RSwghhBBCSGWioBQhhJBiMQzD3h7ZwbUae1K3qIJSIklhUCq7QII1IU8Qm5KLn4IjsS40GoG/XsC9lxkAALmcQY+fQuE+7zhWnHgMqUyOf26/BACYGxZOuzuolTNnX1/3b4Y/xrRl7x+OeFVZT4sQQgghpM7KEUkxafstrAt9VnLjt3TvZQbeZOZzjsHrsmotdE4IIaTmU695ZGJAPxsVxUgZlPp052183b8Z2ja0wgebrgEA/nf2Kaftu79f1nj8pgvPsenCc+jr8SGWyjG1Z2N2XadGNpy2H3Zyg7mhEEsHt8C3/z3Ezdi0in46hBBCCCF1Wq5IipaLgwEAZx4nYkibBmhgaVTh+5m5LwLPk3Px90cd0b0UszrXdnR2QQghpFi5Yil7WxVIIeVnb2bA3v7xVNRbb0esrCnlaG6odX17Nys2i6pNQysAQHRSzlvvjxBCCCGkPip6Ue/KsxS8375iRxG8TM/D8+RcAEDLBhYVuu2aiobvEUIIKVaeSDG8zFhfAD6/dDPLkZJ91NVD63I3G2P2tn+RjCcAMDPUw7X5fTSWG+lzA4ZrRrRCR3dr/Da6DbuskZ0JACCrQIrMvIqbhY9hGEhl5ZtFkBBCCCGkJnuRlse5fzs+o8L30fWHUABAA0sjWJvoV/j2ayLKlCKE1BhZBRJkF0grJQ2WvD1VppSxPv1kVKSWDSwQs3IgskVS+CpnxHO1NkLY7J6QK0sI8HlAVr4UP5+OQnt3KwzydWYDgxvHtsOUHeHs9gyLZLENbeuCoW1dOMuM9fVgZ2aA5GwR4tJy4WtsWe7nEfwwAVN2hMPOzACnvugGG1ODkh9ECCGEEFLLvMzIBwCYGughRyTF8XuvsXKoT4Vtf+2ZwvINui5e1kWUKUUIqTF6/hSGLqvO4Wp0apkfG5eaC58lwZh/6D7OPErEtN23kZwtqoRe1h/PkrKRkSdGao4YAGBqQEP3KhqPx4O5oRDXF/TBpz0aY9vEjuDxeBDwFX88Hg8WxkIsHdISg1s34GSq9fVy4ARwDYWl+0l3s1ZkYt1/lVnu/h+49YINjCVnizBt9+1yb5MQQgghpCbaeP45AOC9Ng0AKDLP41PzIJOXvyD5s6Rs/HLmCXv/YwpKEUJI1UvLVQQ/Rv15rcyPXR8WjewCKfbciMekv2/h+L03+O7ow4ruYr0R+MsF9F1zAYN+v4TTjxIAAK1dLau3U3WYg7kh5g1ojsZ2pqV+jIDPQyvXwloD+oLS/aR39LAGANyOy9BY9zQxGwduvSjVbC95YinmHLzHWXbteRqikxX1qq5Gp2Lj+Wga1kcIIYSQOqVlA3N0dFccT3X/KRQTt90s10x5qTki9F1zgb1/ZlaPcvexNqGgFCGkWiRlF2DJkYeITMgCgFJfYbgRk4b/tExnnyOSaiy7HkMzjL2NUw8SEJWYDQB4kZaPv6/GAQC6Nqn7s3/UNupDKnm80tX7crdV1JVKyVFkEsrVPnv9frmAOQfvwWP+CSz67wFbRF2bUw8S2NtTejRib99R1lcY89c1rDwZiX23XpSqX4QQQgghNVVSVgF7O8jXGX297dn7F54kY4Myi6q05HIGWy/H4FxkInr+FMYuH9vJDZ72pb9IWRdQUIoQUi323niBbVdi0f/XiwCAfImMsz67QLMIc1aBBCM2XsUXeyPwoMjQo3svNYciNVKefJOyOXJXM+gHAD3qwZS0tc2Ezu4w0ONjtF/DUj/GTlnzKSVHhLVnnqL5olO49zJDo93fV+OwpJhsQ1XwaUr3Rpg/wAvvtnIGAMw+cBdTd4azdbFepueXum+EEEIIIVVBLJWXKZv7cYLigm0jWxOYGuhhnL87Z/25yMQy7f+7ow/x3dFH+GjbLWQrL64Pa+uCpUNalmk7dQEFpQgh1SI8Lp29nSOSIkqZMaUSk5LLuV8gkbHFoAHguXL97fh0nH6YgPi0PPB5wP0lAZjR2xMAYG9uWFndr7MYhmH/bz7v7QkjZfHs/41qAzszKmBd07RsYIE7i/ph6eDSH8DYKoNSydki/HLmCcRSOb4+eA8iqUyj7YFbL7RmS11+loId1xQZdC7KGlWOFoWft5NqWVQGenSoQQghhJDqxTAM7r3MgEQmx5rTUWi68CQ8vzkJ93nHseVSTImPf5mumHnPQ3nR21AowNPlA3BkehcAwM3YdJx9XPrA1KmHCZz7HrYm+Pl931I/vi6hqZQIIdVCfYrTn4OjkFUkM0o1tEjln9svOffPRyUjXyzF3H/us8u8nMxhZihEAytF8ec8LUP6SPEiE7KRmCWCgM/DxC4eGNWxIR6+zkI/b4fq7hrRoayzIlqbKj57SWoTAcSm5uK3s8802kpkDJ4mZaOFswVn+Zi/rrO3G1gqglEfdHDFpguaqeu/nnmKqT0bw0CPCuUTQgghpHpsvRyL7489gpeTOR6/4V4M//7YI0zo7M6ZUKaoJ8pMKdV5BgAIBXy0VDtGWvTfQ/TxKvmY+ezjRCRmcc91Dk3tXOpSDHUNXb4khFSLjDwxe3vblVgcus0dMqYaGqRS9Iv7n9svOQEpAPB1UfwoiJSZHWcjkyqqu/VGWFQyAKC9mxWsTfThbGlEAak6xtpYX2NZgUSO30MLg1KnZnZDOzcrAIUzzagULeTZubEtAKCRnSnOz+mJP8e119h+l1WhAACpTI75h+7Bfd5xjNx4FcuOPcJH224iT0wBZEIIIYRUnu+PPQIAjYCUyhu1mlHaxKYqMqWaFKn3xOfz8NNwRYbTq4x8XIlOKXY7j99k4ePttwAosqP6eTvg+8EtYGWieXxWX1BQihBSLZ4pZ+jS5bdz3KyNuFTFcD3HYobkOVkorlyYlDFzhCgCDQv+vY8fTkUCAMyNhNXcI1JZjPSLz1jq5+2A5o7m6OqpCDZdepbCKYauXv/t4XeBMBQWbs/NRnFwNaClI2ebKTkiZOZJ4PnNSey5oSh8fj0mDX9disG5yCRsCIsu9/MihBBCCFFhGAZ915yH+7zjGrVoAeCT7o0QuyqILWuQla9Zz1ZduvKCuup8Q9377V3ZY5/Rf17XWK9uwNqL7O0FA73w57j2GvWp6hsKShFCqlxiVgFepGkWPzbQ42NUR1eN5QzD4Gp0KgBg5VAfzjpvJ3M0czADAHygfGxnTxvOY0nJHr7Owu7r8ez9Ia0bVGNvSGX7un8zAEAjOxN80r0RZ91c5TrV8rRcMYZvuMKuVw8gGesIcK0b3RZPlw/AiRnd2GWtvj+ttS0A/O+c5tBBQgghhJCyePAqE80WnoTnghOITc3DsyTFRfD3/rgMADAU8hE2uyeuze+D+QOaAyisfVncjMMAkJCpyKRSlUEoysSg8KJ4aQuo02gEBUonIIRUuZuxaQAUAaWRHVzxPDkHbd2s8I6vMx6/ycKeGy/YqxYAEJWYjaRsEQz0+PBvbIMPOrhi701FtsXWiR1gbaIPOcOwNWvUfxREUjknk4Nol13AHT410MdRR0tSF3zW0xOf9VRMCBCbksupBeVprwjymhjoYUBLR5x8kIDb8Rn4/ugjfPuOFyeApKv2AZ/PAx88uNsaa10fvWIgGi84UVFPhxBCCCH1XJ5Yind/v8TO/tvr5zB2nUSmWPhemwZwLzI7t+pQJreYWrS5Iilbi7Po8D0VudqFcBnDaA200MVy7SgoRQipcrdiFbO7dfSwxvjO7px1qmBUep4YcjkDPp+H88o6R108bWEoFGDegObo3tQOgS0cIdBSkFB9+F6OSEpBqRIUSGQY9ec19n7MyoH1ttBifeRua4JGtiZ4npKLJYO8OesWvuPNzqS35XKMxoQEJTHW18PuyX6cVHbV++vJsgEYu/k6rsekoaOHNcLj0nD5WSomdfMoc/F2QgghhNQ/L9Ly0O1HRd3K30e3gbyEmE//lk4ay16mK0Zv/HQ6Cv8qSxcUdf5JMnvbzFBHiQu1fct0dOTvq3Hs7T/GtC2+s/UIHfURQqqcqsBgK1cLjXU2ypRYmZxBRr4E1ib67I9FC2dzAIClsT4G+mj+qKgI+DyY6AuQK5Yhp0DKyboimv69U1hk3kRfQAGpemjdmLa4HZ+OEe25w2cbWHLrJhwML5wFUzVstiSdG9uivZsVbsWlY+0Hrdn3l74eHx919cD1mDTciEnDsPVXAQAO5gYY2aFheZ4OIYQQQuqwZ0k56LvmPGfZ9N13AADvt3MBn8fDvlsvNB7XtqGlzm0+fK29ADoA/BfxSuc6lX7eDjikPKbWFZQ6cvc1pz1RoJpShJAql6Cc3aKBpebQHqGADwtlke3UHEWa7OsMRVBKW2FBXUwNFTH3nGJScYlCvriwcHXonJ7V1xFSbbyczDHGzw1CgeZhwer3W2ksM9Dj4/iMrqXe/o6P/XBrYV8MLlKrLDNPM/Pqh1NReF7CRAiEEELKh4YRkdqsaEBK3dSejfHDcF/ErgrCerVspIOf+mvNcpod0BQA0KmRjcY6leCHiSX3SS3IJNdRUko1RPCzno21HnPVV/RKEEKqVL5YhjjllKpOFtpn0jNV1oTKUwZLXimDUs6Wumfe07UNCkqVTDUEMsjHCfZmpX+NSf0wrJ0LYlcFsdMdA8CGD9tBrwwHU0b6Aq0Zi54OmnUZ0nLF6L1a98EmIYSQ8plz4C485p/A7fj06u4KIWW28Tx3xt5OjazZ2x09rNHIrvDYop+3A9aPaYsb3/RBe3draKOqpZldxhIFRQnURhr8EfaMM3MxAIikMrbw+phObuXaV11DQSlCSJXqvTqMva0rKKWasl419bwqU6roUKLisEGpAgpKlUQ124i+Hv0kEN3eb++K2FVBiF0VhF7N7Stkm21cLStkO4QQUtsxDIPo5Bz4LglG55VnOcN//gl/iYBfzqNAIitmC6V3QDkUe+gfV3Dg1gusOPEYklLOFkZIRTkY/hJdVp2D+7zj2H4lttSP26U2W/ThaV2wa1In9PWyR0NrY+ye5MdpqyfgY0AJF13NlaMrik76o/IiLY+9vXRIS53b4avVud144TkaLTjBZiSGx6Wj2cJTkMoZGOsL4KzjHKi+oppShJAqwzAM3iinU+3WxFZnpoWRsjB5vliGHJEUWcofCaeyBKVo+F6piZUHokIB1ZIiVYvH4yF2VRAKJDLIGQbei4LZddkFEt3FRAkhpA7ZcikG3x97xN7PKpCi189huPB1L0hkcnx14C4AYPaBu/jfB204J7/lNefgPQBAKxdLBPnqrtdJSEVhGAbz/rnPqfm0+MhDhMel43+j2hT72OjkHMQrg0QXv+4FV2tFKZC/xnd46/6ojjWeJeVg8LrL+Gtce9iZGbB9nbkvgm3rX8wQP20Ss0QQSWUYtv4KuyxPLKP6rUXQZXFCSJXJzC9Mi/1zXHud7dQzpR4piw7amhqw2U+lQcP3So8ypUh1MxQKYKyvh6PTC+tU+Sw5TVfuCSH1grYiyvFpeej6wznOBBPH7r3B76HPyr0/befDL9LzNBcSUgmik3O0FiE/cvc13OcdR3RyDkRS7VmBJ+69AQD0bGbHBqTKy8yw8Pzi7osMdFh+BvGpeWAYBn4rziI8TjHMtXdze3jaa5YdKE6nlWfR46cwzrJ5A5qXu891DZ2BEEKqjCot1kCPD0NlNpQ2qkypmJRcXFBOwerfuGxXJkwNFFc9KChVMgmbKUU/CaR6mRtxA89hUck6WhJCSPVTXdQpL4Fa5tOEzu7s7Zfp+Zh/6D6n7ZqQJ+Xen6Ge5jHYqpOR5d4uISVhGAaf7rzN3p8T2AzfD27BadNn9Xl0/zGUE5jKyBNj/qF7WK18/wcVMwt3WakHpVTm/3sPPX8OQ1K2YtKl5o5m2Dxe9wX10jozqwcmdfUo93bqGjoDIYRUGVWASNuXvzpVralHb7Jw/L7iikiXMgelFAdcVFOqZJQpRWoKVytjuFgVDtOd/PctndMqE0JIddp0IRotlwTjRkxaqR+TmFWAC0+SkZEn5ixXTeyyMMgLi97xxv0lARXa16K0fa8K+DyNwsyElEdkQhZ8Fgfjk79v4U58OpKzRfCYf4It9t3K1RLTenlinL87HnwXyHlsYpYId19kIrtAgnn/3MOUHeHYc0ORXWUo5CPA27HC+mlupFkq4PKzVHZiJjMDPZyY0a1UQ+62f9SRfYy6/i0ccfObvvC0Ny3TRDH1BdWUIoRUGdU0qCYlDMMb2tYFe2++wHFlii4ANHM0K9O+TGj4XqmpMqX06UeSVDM+n4dLc3vDfd5xdtmu63EY5+9efZ0ihBAtVpxQZBatPPkY/37WpcT2N2LSMGLjVQBAr2Z2SMuToEtjG8wOaIbIhGwAQDs3K/D5PJgZCnHyi24YsPYiAEVWiOoiHQDI5Uy56krJGM3gk0zO4HlKbpmHJxGiS/9fFe/f048ScfpRosb6mX2asLdNDfQQuyoIg367hPuvMgGA/bwU9duotrAwrriak0IBH/9+1hlyRjGpUqeVZznr7y0JKHUNqO5NbLF/ij8a25mAz+Oh9+owOFkY4X+j2tDF32JQUIoQUmUy8hQ1pUrKlGrT0FJjWROHsgWlDJSp6WKqSVMiMQWlSA1zY0EfdFyhOCjcdS2eglKEkBrLuZSTsPx9NZa9Haocmnz3RQYO3ymsJ6VeO9PLyRyxq4IAKIJQdmYG2KacoezB60ycfZwEV2tjDGrlxB7zlFbRTKnmjmaITMjGy/Q8CkqRKnF3cQAstGQojezgygaltDk8rQtaV8LMvW0aWrG35w1ozg5n/by3Z5mKkvN4PHT0sGbv31lUuVmPdQWdgRBCqszCww8AAMb6xQelhAI+1o1uywZJ5g9oXqYi50DhUDSRhIJSJRFLFQenQrqCQ2oIe/PCqZLfb+9SjT0hhBBNqTki9nZju5KDOAfDX+KYWva3utfKWYkB3bMM8/k8LHm3sO7Ou79fxtqzTzH7wF38eCoKMjkDuZzB4N8v4ZcSak6pD9Gb0qMRDnzqD0dl2YQJW2/i/BOq5Ved/gh7hqk7wyGt5RdVVcXBAWDRO96cdWGze2oNSAHAh53csGCgZiHwZg5m+HGYb6UEpIr6tEdjfNK9EYa2bYCpPRtX+v4IZUoRQqrIzmtxSMhSHHjZK6dZLU6Qr1O5piY2UAZY/rn9Ev/cfglfFwvsmdypxKGD9RFlSpGaaGibBjh05xXkWoaZEEJIdXqdURhIMijFBR1ts+t1cLfCzdh0zrKSLsDxeEDRr8TNl2Kw+VIMe//uy0xM7dlY54Qy6kP3PuvhCQtjIdzUZjEbv+UGm6FFqlZmvgQ/nooCAJyLTEJAi4qrm6RLUlYB/ot4jRHtXStkSFxytgidV52FRKZ4nwW2cMBHXT3wUVcPyOQMp6i/Lp90b4xPujfGlegUrDjxGL+Pagt3W5Ny960sFgz0qtL91Xd0BkIIqRKqLCkAWDakZaXvr+i47XsvM0u8elhfSZSFzilTitQkegLFgavqwJYQQmqK2NRc9nZxxcFFUhm6/nAOF5+mAAAWD/JG7KogxK4Kwo6P/SAUFJ6g/zaqTYn7/WVE61L171lSDhgdAX31oXt85c/+lB7cbJDnyTml2g8pH4Zh8PhNFiQyOZKyCzBu83V2XVYVTdTz2a7bWH7iMb46EFEh21t2/BHnd1u9tmtpAlLqOje2xbHPu1V5QIpUPUoZIIRUiQ86uGLvzRfwcjKHpbF+pe9PWzHBvy7FYHDrBvBxsaj0/dcmhZlSb180lZCKppoV8qfgKIzzd4OZYcUVNSWEkPKITMhib6tnHkUn56DP6vMAgCndG6FHUzu8TM9n16tngBsKBXi6fGCZipar13t6v50Lxvq74d3fL2u0e+e3SwCAiEX9NI651LNPVUECZ0sjPPo+EN6LggEAvZXP4eF3gZRhXok85p/QuS67QFIlfbilHGZ35nFShWzvTJGC5l/2bVoh2yV1G10WJ4RUCVUaeZ/m9lWyP76OooSDfr+E9FwxRFIZTX2spDr5L2uhVEIqk/qJ1Ff771ZjTwghpNCmC9FYFxrN3lcdS8jlDBuQAoCNF55j2u7b7P3eze1hb1ZYL0+lLLPoNXM0Q0d3a/RoaoelQ1rC18US95YE4MmyATgyXXMGwF/PPNVYxsmUUjtWMtbXw7rRbTltD2sZdkg0MQyDJUceYs3pKJ1tZHIG8w/dw18XnwNQZNEV57ujjwAAeWIpPt52E+7zjuNmbFrFdboSyOQMcsWK59XR3RobPmyL9u7WJTyKEApKEUKqSFquGICiiHlViE/LY2+P93fjrGuzNATNFp7ChG03q6QvNZ0qKEVT1ZKaZJza5/aNWiFgQgipDrEpuXCfdxwrTkRylv/v3DO4zzuOo/deazwmXTnrcENrY2yZ0KHcfRAK+Nj/qT+2f9SRvdhnbiiEvh4fvi6WWPtBa0571Wx96uRq9bOLDqcKaOEAZ4vCwFlKtrjcfa4PnqfkYtuVWPzv3DO8TM/T2ubi02TsufECy44/hkgqQ/DDRK3t1LnPOw7vRcE4G6nIYnp/w1Vk5FXs/4mjuWag9G0NXHuRvf3rB63Rv+Xb14Yl9QudgRBCKl1mngRH7ioO1oR6VTNE7B21FPnZgc0QsaifRpsLT5I1pkWuj0RU6JzUQI3sTPHfNMWV/xS1ma4IIaQ6aAvwqJulltFZdEIXvTLW0nlbXk7mGstepHGDJOrDDQVFssqFAj6uzO+Dr/ophly9ytAeYCFc/X+9wN7ecTVOa5sJWwsvhO698QJXo1M12sSsHFhikfl2y84gKbviLtRYqhU3L5AUn72l7ujd14guUnssKjGbvW1jWvmlOkjdQWcghJBKN3LTVfZ2QhVlPDR1MMP1BX3wZNkAmBkKYWmsjzOzusNYnztELTGLMjBEyoMQypQiNY2d8sQuJUdUpcNtd1yNxYgNV5GeS1kChBBFRvHjN4V1pGJWDkRgCwdOG9VFrh0fd8T1BX0468pa4PltOVsasbfbNLQEAHT7MRT9f72AlScfQy5nihQ6194vVR2pfIlc6/r6TiKTY31YNO69zMDN2DROYe+XGfka7fPF3GDP4iMPsedGPADg+8Et4GJlhAOf+oOnDBKemdVdYxuqemQyOYOg/13SWci+rNTfmw9eZZbqMfMP3cPne+6gz+rzbNAzPI47tJBKQpCyoMp1hJBKF5lQeOWkKseWOxRJSfa0N8Oj7/vDf+VZdjjQ64x8zkFcfaQqdF6aaa0JqUq2poqglETGICNfAmuTqrny+u1/DwEAcw7ew1/j21fJPgkhNQ/DMPhw83VcflaY1XJkehfweDxM6+WJ6ORctGtohX23XgAA2rtZoaunLXg8Hub2b44fTimG+u342K9K+mtqoIfgmd0hFPCQmivG+xsUFwUjE7IRmZCNFs4W8PNQHIcVFyhTXaQSl1D3qL55/CYLOSIp1oU+Q1hUstY2x++9waJ3CmBnaoCnSTmQyOSYsfeOzm0Ob+eCcf7unGWe9ma4/W0/tF0aAgDo3tQO//ugDcJj05GQVYDkbBE2nH+OqT0ba9li2eSrZUddeJpS4nG6ahiiSrcfQzXatHezKne/SP1CQSlCSKUqmt0wsKVjNfWk0NHPu6L9sjMAgFcZ+ajvp5xUU4rUVPp6fJgZ6CFbJMXdFxnoVUUTJaiceZxYppmxCCF1y+rTTzgBKXcbY/i6WAIAfF0scWZWDwCAh50JniRmY/kQHzbbZWrPxhUSNCirZo5mAIBGdsDHXT2w+VIMu+5mTBosjRTDtYorX1AYlKJMKZX41DwMUKuZVFQTe1M8TVIMZ/NbcRZDWjvjcIRmnTF1fZrbw1hf++m4tYk+rszrDYlMDjcbEwDA1fm92Rn71p59UjFBKbUsrv+dfYpZyqGbqkwsXpEhnmtCnpS4zaVDWpa7X6R+oTMQQkilUBUEbbSgcLrbM7O6Q68G1C2yNTXA0LYNAACvM2j4HgWlSG2QLZJWy36P3X9TrsdfjU7FrRo+YxIhRLvfQ5+xt/UFfOya3Elru097NMaaEa1hpF+zhix9+443YlcF4YdhPgCAJ4nZGLflRomPU2VOqzKp6zupTI7uP2lmBKkY6PGxf4o/Z5m2gJS+Hh9Lh7REQ2tjHPqsMzaXUPze2dKIDUgBigDR7ABF0EiPX/wxW2xKrkY9MW3yigwtZBgG2QUS9Pw5DCM3XuNcXC6QyPBEOfph2ZCW8NZSw0zRzxJ3SwgHZUoRQiqF+oGciqe9WTX0RLsGyiF75yITq+VKZk1Cw/dITebXyAZnHicit4qCUieKBKH233yB7k1scT0mDf28HMqUNZVVIMGoP68BAJ4uH1Bls48SQspPvejzrkl+6OJpW429KR9Pe1MAiuzw0lBNfEKZUgo/BkdpLFv+XkuM8ePO7rzvk04YuekaZ1krV0t0bmyDmX2bsHWWxnbiPq4sWrsqhsbliKRwn3cc/37WGW0aFg6Xk8kZdFp5FsnZiglCni0foPOCsFzOIDNfwlk2ZN1l3H2pqC0Vl5qH+68y0crVEgAwdWc4csUyOFkYYkR7V3zYyQ3xqXnQE/DQedU5dhuNbE3f+vmR+omCUoSQCieVyRH8MIGzzMHcQEfr6iFXpiXfjE2v5p5UP9WBNxWlJDWRqYHifZlTUPlBqVcZ+fhs123OspuxaRj153U8fpOF7we30Kj9UZzMvMKD/ax8CWxMa9b3ICFEuxyRFC0XB7P3Oze2qcbelJ+LlTEA4GV6KYNSNHyPlZBZgE0XnrP373zbD8YGAq3HTH6NFMGnX888BQD8NqoNBrVyrtD+6Am4F0be++MK9Pg8BLRwQKdGNlikrImo0mH5GdxZFKB1W8GPEjWWqQJSKpeepbBBqVBlHa3Gdqbse6ShjeK99c/UzlgfFo0fh/tS5j0pM3rHEEIq3LYrscgucgIZOrtn9XRGhz5eDiU3qgcYhkGBcnYdQyEFpUjNY2qouH5W2cP3UnPF6KJ2pXdhkBdMDfQgUpt165/wl2XapkitSHDRq9GEkMohURty9rYzlH287SZ7u21DS426OrWNnakBm/2kMsavoc72qqCCqJ4HpRhGkXWkcnhaF1iZ6Bd7EW9m36Z4unwAni0fUOEBKQDooKUQuVTO4MT9BI2AFACk5+n+7cnML/xd3T1ZezH+80+S0evnMHRaUfg6aKsZ1c7NCn+Nb19lE5KQuoUypQghFSo8Lh3Ljj8GoCjyOcjXGcb6Ap2FHKtLY7XUYrFUXm+v6sSmFtYbMBTWz9eA1GymBoqivJWdKRXyKIm97dPAAhM6uyM0KolT5NiqjAfbOSIKShFSVeJT89i6PxZGQswObIZvDz8AAATP7M4WAC+N6zGFdeBWDvWt2I5WAz6fh8b2pmyAvU9zeyx/z0dn+/o2fO9FWh4m/30LYzq5cYbWqc9MZ6wvQGtlxlBJKnOodnGzJqoYCQWcvuvCQBG07dbEFp0b26JNQ0vcic9AXy8HzBvQHH3XnMeNGM2aiB62JhrLCCmPmnWWSAip1RiGwbD1V9j7Y/wasinjNY2xQeFVrjyxFPp69fPKjnqdHjNDYTX2hBDtzJSZUpVRU0p99qnb8YqhvO42xjj6eVcAwNeBzTH42WW2TXxqyUVj1eWp9ZmCUoRUrul7CofeZuZL2IAUAHy4+Tquz+9TbE242/HpOHb3Dfp5F2ZSH/u8a5mCWTVZC2dzNijV17v4bHETA+X3rrh6JpioahvORyMyIRvfHn6AIa2d2eMh9az/wa0rPuvpbfVsZoewqGR09bTFz++3QoFEBgsjIZ6n5CIxqwADWjpi7dmn7DDCrAIJzLUc42Uos6icLAwBAH+Oa48XaXlo09AKUh1F7oN8nSrpWZH6rFovi69fvx6+vr4wNzeHubk5/P39cfLkSXZ9QUEBpk2bBhsbG5iammLYsGFITOSOfY2Pj0dQUBCMjY1hb2+POXPmQCrlfoGGhYWhbdu2MDAwgKenJ7Zt26bRl3Xr1sHd3R2Ghobw8/PDjRslz0xBCOF6k1k4k93Mvk1qbEAKUFzFUmVH5VTTrF41gWp4kZtNzf2/IvWbiXI2q4r+nO64GovGC07g/U3X8SwT+DdCUeD8s16ebJsWzubo3NgG7dwURWTj0/I4Q4NKkporZm9TUIqQynWvSC0cdcnZIhy680pjuUzO4NvDD/BLyBMM/eMKtlyOYScnAAoLhNcFzsoJXgCgR1O7YtuqLgZURS2/muDI3cKZ8pYrs/0BRS1Alc96eqKmWDOiNRa9443/jWoDRwtDuNuawMpEH+3crDDQxwk8Hg/vqAWPpu4M17od1e+SpbHiwqytqQFbNF1XcfQFA70q8qkQAqCag1IuLi5YtWoVwsPDcevWLfTu3RuDBw/Gw4eK8bBffvkljh49igMHDuD8+fN4/fo1hg4dyj5eJpMhKCgIYrEYV65cwfbt27Ft2zYsWrSIbRMTE4OgoCD06tULERERmDlzJiZNmoTg4MLihfv27cOsWbOwePFi3L59G61atUJgYCCSkgpT+QkhJfsjTDHjXpuGlpjZt2k196ZkpsorgUWnw61P2HpSVOSc1FCmqivWFRiUyhNL8a2y9kbEi0z89qgwcbx7k8KTNT0BH7snd8KBKf4w1hdAKmcQn5aHh68z8e3hB8jIE2tsW12ScvYjAMiqJyd3hFQHqUwOVRLU8Rld4WxhCBN9AUK+7I4gH8XJ+Q+nIjVqTIXHpWPHtTisPftU63brUq3Fd3ydIODz0L2pHSdApY0pmykl42SU1jZyOYMnidnF1hZbfTqKkxEV8SKDvf0kMYe97Wpdcy7eWZvo46OuHsXWb1INfQeAy89SIZLK8CItj52BUSoHMpRBKQsj7ZnyPw73RY+mdrg2vw8+7NQQq4b6sLNXE1KRqnX43qBBgzj3ly9fjvXr1+PatWtwcXHB5s2bsXv3bvTu3RsAsHXrVnh5eeHatWvo1KkTTp8+jUePHuHMmTNwcHBA69atsXTpUsydOxdLliyBvr4+NmzYAA8PD6xevRoA4OXlhUuXLuGXX35BYGAgAGDNmjWYPHkyJk6cCADYsGEDjh8/ji1btmDevHlV+IoQUrvtvBYPABjYsnal9mYX1N8MBrEy60OoV7uLuJK6iz05qsCgVJ/V57Uub+dmBUflMAZ1fD4PjexM8OBVFp4l5eD7o4/wKiMfrzPysXlCB537UQ2VAYBEtUxSQkjFep6SCzmjqPvj5WiOi3N7gwfFZ3flMB8cv/8GydkieMw/gVsL+8JWORPmyE1XOduxNtFHmjLDcVJXj6p+GpWqqYMZwmb3LFUhatUEEwDw8HUmfF0sK7FnlafRghMAgA86uGLlUB/0XXMe0cm5AICTX3RDTEoufjv3jPOYZ0k5KJDIYCgUcIaE1jYO5gbwdjLHI+Xv0H93XuPrf+6ptdADoMgQszTWHpQa0d4VI9q7AgCWDdFdg4yQ8qoxVW1lMhn27t2L3Nxc+Pv7Izw8HBKJBH379mXbNG/eHA0bNsTVq4ofkKtXr8LHxwcODoXjogMDA5GVlcVmW129epWzDVUb1TbEYjHCw8M5bfh8Pvr27cu2IaQ+C41MQlxqbrFtGIbB+rBo9n5vL/vK7laFUB14zv3nfjX3pPpIZYqrh5VZlJOQ8lAFpSpqGIlYKucMNVa36B1vnY/ztFMM4zlw6yV7pfnBa93DhQDgoNpsfb+HPiumJakr5LU4q6Q2U32mG1obg8/nQcDnsfWjzA2F7JT2ANB+2RnkiKTIF8tQNIFm58eFM5CNUSt4XVe4Whuz9aKKoz67XK6odmaTq2dH7b35AsEPE9mAFAAMWHsRn+0qDDrtn+IPOzMDSOUMlh57BACozZfreDweTnzRDQN9HAGgSECKy6gOZQSS2qnaC53fv38f/v7+KCgogKmpKf799194e3sjIiIC+vr6sLS05LR3cHBAQkICACAhIYETkFKtV60rrk1WVhby8/ORnp4OmUymtU1kZKTOfotEIohEamn5WYootEQigURSe7MuVH2vzc+BVJzb8RmYqJwW+enSAJ3tLjxNwQ+nCj8vrhb6teo99Cwpp9r7W12fvXyRIjAn4NHnntRMqgv22QUV8/va9NvT7O39n3REQ0t9dPrxEgCgub2xzn2oTnDOPC6sbdncwaxMfaLPWN22/vxzrDmjCD6uHu6Dd1vVrqzhqlaRv3tJmYpJCKxNhFq3t3lsG7RfEcre/zUkir3N5wGnZnSBnAEa2xnh1xG+yJfI4FLLjmUqmm8Dc9x7lYXMvIJa+TpsvRLHuf+pjrpKKm1czNC/hQN2XIvHruvxuBqdivZuVrgRm453fBxr5WsAADalyIzztNX920dIeZT2fVXtQalmzZohIiICmZmZOHjwIMaPH4/z57Wn1dckK1euxHfffaex/PTp0zA2rjljjt9WSEhIdXeB1ABXEnkAFFdPjh8/AZ6OS0aLwwVQXU+yEDKcCQtqsg62fNxM4aONjRwnTpyo7u4AqPrPXniK4v84Mz2txrwGhKhLzAcAPaTn5Jf7PapIYik89Hl2+wreCIG1/or7p07p/u66GlX4PafyJimp2D5Z6guQIVY8Rshj6DNWRaRy4EUu4GYKlGL29AqRKQbWhBe+t746eB96r+5Uzc5ruYr43Tv7QvFbJstK0fk5m9EC+N9Dxf/RX5di2eVORgwe31Cce0RB8Sk3BnDixN1y96s2K8jhA+Dj8vVwiJ7XrgzAFznAz/e1n+bObCnF8ywejsQXZgf92kmKEydOoKUMUP1GPE/JxfMURWaVYc4rnDjxUsvWar6chMJjeQDobC9HT2c5LPWBAzF8CPlAzJ2LiKGvK1IJ8vJKN2txtQel9PX14empmM2gXbt2uHnzJtauXYuRI0dCLBYjIyODky2VmJgIR0dFGqKjo6PGLHmq2fnU2xSdsS8xMRHm5uYwMjKCQCCAQCDQ2ka1DW3mz5+PWbNmsfezsrLg6uqKgIAAmJubl/FVqDkkEglCQkLQr18/CIU0PXx9ZxSVjH3PFb9SnXr21Xm15YurhZkHR2Z0L7GAZk2RcDkWN089gWuDBhg4sHrHylfXZ6/gzivg6UM4Odhh4MB2VbZfQkorMasAKyIuQMzwMWBAAHi6ouOlkJ4nBq6FAQDOftkVDa2NS/3Zs/FKw4dbbgEAgnwccfx+AkwtrOHs0xS+DSy0TjW/5G4oIFZmgzA8dOzeh61lQyrHg1dZeG+DYva0+f2b4qMu7lrbnYtKxsqTUfj+XS/4N7KpsH2q8+rYAx62JuXadl2m67MnlzN4mpQDT3tTCEoZVbzy30Pg5Sv4+TTBwF6NtbZhGAb/W6QZAJvS1xsDO7i+3ZOow45nRuBJZhIaN2+BgX4Nq7s7ZbLrejxwvzCDf2BLB5x4oDjXmzZyIJKyRTjyoyIQ6WJlhKCgbmzbx3qR2HY1nrM9n5YtMbBj7XyPBMoZ/Lu48H2//fP+7Gdv+9Q+dL5HKpVqNFlJqj0oVZRcLodIJEK7du0gFApx9uxZDBs2DAAQFRWF+Ph4+PsrLmn6+/tj+fLlSEpKgr29ooZNSEgIzM3N4e3tzbYpesUkJCSE3Ya+vj7atWuHs2fPYsiQIWwfzp49i+nTp+vsp4GBAQwMNA8shUJhnfhw15XnQcpHX1j4FZFRIIOjpfb3hKow6P4p/nCzqz1BWQPl85MBNeb9Xtxn78CtF7j2PA2zAppW2OwnjLK0oL6eoMa8BoSoszRVnJTK5AxkEJSr9sWrzMKZlBo7WHDWlfS717WpA54sGwB9PT5CI5Nw/H4Cbsdn4P1NN9DRwxr7p/hrPCZfwq3Fkpong5MVfc4q08pTT9jbP51+iik9m2ht91toNGJT8zB+WzhiVgaVa5/LT0ZpXR6w9jJiV5Vv2/VB0c/efxGv8MXeCACK2b9UhZaLk56nqDlnZ25U7Od4bv/mnHIDswOaYqy/R7mC3XWVuZHiQmSelKl1xwd50sLMrvNzesLVyhj3XmXCp4EFBHweHC0Lj29zRFLO81sy2AeL322J6OQc9F1zAQDQ1NGi1r0GKkIAN77pg82XYvChnxvnedD5HqlspX1/VWtl2/nz5+PChQuIjY3F/fv3MX/+fISFhWHMmDGwsLDAxx9/jFmzZiE0NBTh4eGYOHEi/P390alTJwBAQEAAvL29MXbsWNy9exfBwcFYuHAhpk2bxgaMPv30Uzx//hxff/01IiMj8ccff2D//v348ssv2X7MmjULf/75J7Zv347Hjx9j6tSpyM3NZWfjI6S+Up8GOClLpLOdRKqYwc3WtORx6zWJnrK4t1Q5A11N8+BVJpp8cwLXnqciIbMAcw7ewz+3X6LLqnN4npxT8gZKQaKafY8KnZMaylgoYIcOp+To/h4qjUX/PSzX4/X1FJ8TAz3u5+VGTBo7cYKKXM6gQML9btl380W59k9KdiM2jb0tlTNap4JnGAYPXmUpb5d/nx09rNnb1xf0YW+bG9a4a7+1wvWYwv/Drw/ew38RrwAAy48/gs/iYBy+84pdL5LKkJojwulHiiwYa+Pij0PUM74b2Zpgeu8mFJDSQTXJRHYFTTJRlVR9ntjFHW42JuDzeWjtaslm3qln4LV0ttB4PI/Hg6e9GVa/3wpzApvBv3H5simrm72ZIeYP8IKrde0vMUPqpmr9tUxKSsK4cePw5s0bWFhYwNfXF8HBwejXrx8A4JdffgGfz8ewYcMgEokQGBiIP/74g328QCDAsWPHMHXqVPj7+8PExATjx4/H999/z7bx8PDA8ePH8eWXX2Lt2rVwcXHBX3/9hcDAQLbNyJEjkZycjEWLFiEhIQGtW7fGqVOnNIqfE1LfcIJS2dpPBuVyBtnKqdrNjWrX1RahQHFQopqBrqaZuS8CEhmDDzZdw/aPOnLW3YxNQyPlbGDlIVE+dz0KSpEais/nwVRfD9kiKbr9GIpjn3dFywaaJxGl8TQpu0L6ZKAlW6vtUsXwiN9Ht8E7vs4QSTWD3TuuxaF3c3vEpebC2tQALZ3N4WptTEHhCpIr0jx59ph/AuEL+8LaRB88Hg9fH7yL8Lj0Ct2vKrg/qasHHMwNsWxISyw8/ADt3a1LeCRRFxqVhPNRybhd5P/ni70RbOYUoPhtnLkvAtoY6Rf/WTLSL/zsbp3Y4a37Wh+ogqqqmU9fpueh6w+hMBTycWthPzZoVRNlFyiGTZsZ6j4u/aR7Ixy7+xrfD26hs82wdi4V3jdCiKZq/TbZvHlzsesNDQ2xbt06rFu3TmcbNze3EguH9uzZE3fuFF+9bfr06cUO1yOkPlIPSiVk5mttoz48xVi/dk0pK+ArDl4lbzGFd1aBBL5LFLW0fn6/FYZXwoGLelbIXxefc9apim+WV2GmFF0pJjWX+vfModuv0LKBBbIKJGAYwKKYYHhiVgGG/nEFrzK4318bPmxbrv6oZ1uYGeixgXkAmL77Do7dfYNl77Vkl333bgssPqLI0lLNaKouZuVAytZ4C68y8mFvZsAG9SJeZGht127ZGZ3bKO7EWi5nsPVKLHhQZFzo+j9KVGYSO5gbcrYp1hKYJNrdf5mJiVu5n409kzth6q5wZOSVbvYmY30BujexK7ZNXy8H2JoaoJWLBdxsqN5XcVQBnSxlgGf8FkUd3wKJHC0XB2Ocvxv+vhqH4Jnd0czRrNr6qU1qjiJz1cpY9+/DgoFemD+gOX33ElID0KU5QohOUrVgzZvMAq1t8sSFJ4uGerUrKKUKxMjkZT9xOPc4ib09+0DFz9CTI5JyDsQvPk0BANibKYYmbzz/XOvjykr1fyzk088BqbnUv4u2XI7B8Xtv4LvkNFp9dxru847jdYZm0Dw+NQ9+K85qBKQAwMmifDXZ3G1NMKqjKzq6W+Py/N4a6089TEBmvupKvR7GlFAk2GP+Ca1ZPkS33j+Hocuqcxj02yUUKIOWSdmK36kunjbYPdmvVNspLnD0zeEHWHrsEb4/9gjROoZMMwyDI3dfAwAcLBRBKVWQTFxDh4bXNHfiMzDo90sayz3tTXF6ZvdSbWNKj0Z49H3/ErN+jfQFuLWwLzZPoCypklgqAzr/RbxGgUSG6GTuxbC/r8YBAAJ/vYAXaaWbYauqqH4TSqq/SQEpQmqGmpt3SQipdrJSBKXylUEpI6FA6+xTNZmeKlOqDMP31odFc4qkquSKpDCpwFT2LZditC4f2tYFG85HA1DUnHrbYUwqqhMyoV7t+r8j9du03bc59zuvOgcAaOVigf+mdwUAnI1M1HiciotV+ScKWDnUl72tKmZ9LjIRH21TzNDXZ7ViZqfsAin0BHxM69UY60KjdW7v0ZssdKDhXiX6JeQJ1p59yt6PTMhG829P4er83sjKVwT2LIyE6NzYFquG+mDeofsa29AX8NmAkVgmh1Qm1xrM2HOjcAau1BwxPO01+5OQVfjb2MBSEZRS1R6TUFCqRAl5wBd/Fs6k7etigaQsETo3toGd8iKMgR6fHQ4bs3IgNl+KwY2YNKwa5gsLI2GpZ+gjZWOpVp+rzfeasxaqO/0oER939ajsLpWaKnvRURkoJoTUbHRpnBCik/oBtbZMBADIkyhOAmrb0D0A0GNrSpX+xEFbQAoA/nfuqdblb2tNyBOtywNbFNa6i00t/xA+qTJLTI8ypUgNdnR611LNOHn3ZSbC4xRFkm8p69J0a2KLkWqzdw1r6wIbU83ZcytC7+YOaNPQkrPMUKj4bPloCSAvGeTN3lbVQCHFUw9IqVtxIpItNm+uHHY0soMrTn7RDU+XD8DnvT3Ztns+6YTIpf3Z+0VnSQQKhyyp5OjIZFMFwgCgbUMrAIVZuDR8T7f/Il6hybensfJu4cWcvl72+G9aF1xb0AdrRrZml1+e1xsGenwM9HEEj8fDpG6NsGlce1ib6FNAqhKpT+ig/hm58U0fNLbjDn3UNqFAdZHJGSQryx84mlNQipDagM5CCCE6lWX4nlEtDEqxhc5LWVOq6FXvyd082HoFh26/qpKr4o3sTNGzmaJmhvrQyaLkpXxOqiLv+nr0c0BqLh8XC1ye1xths3uyy95r0wAxKwdqZD3FpeZBLmdw8UkyAGBm36b4YbgvLs3tha/6NcWid7xRmQ5N7YzFasGmhUGK2/28HbH6/VZoZGeC/VP8EbsqCBO6eKB7U8XnWVUDhei2/xZ39sIdH3fEiPaKen5RCVmIUwbqVbWdeDwevJzMIRTwEdjCkX2cpbEQBnp8qOIZ+WrfpdHJOVhzOoqtGaiiK8CkCia62RizQ4H0BZQpBQDnnyTji713kJojglQmh/u84+yfeuFylT/Htdc6nMrW1ABRywbgjzHtqqDXRMXaRHMmwxHtXWBvZoizX/XE3cUB7HJDLZM/VIaYlFwcDH/JyeQvKjVHBJmcAZ+HSrsAQQipWDR8jxCik/oBdWa+BCk5IoRFJcNIKECQrxOAwoP52pgpJSjj8L2niYU1RS7M6YWGNsb4vE8T9PgxFMnZIpx5lIgBPk4V2sfl77XEN/8+YO9bGAlhoq/46s5Tu3Ivlclx/P4bdG9ih9vx6fh4+y18M9ALk7s3Knb7qiEsenS1mdQC7rYm7FA5lX+mdsaBWy/w82lFdmFStgiNFhROgNLKRZGh5GKl+LxWNh6Ph4ldPDCxC3coi4DPw7B2LhqzOamKpquyfIhua04XZpA+XzEQfD4PzRzMsP/WSzxJzGFnCXOz0Zz2vGUDC/w4zBdvMgvQWDlzqeq8dsP551gwsDl6rQ7DizTtWcG66kOppp43Myw8pBYqg/x1PVNKLmcgkcthoKOe5Kc7wpEvkSErX4LeXsXPaL10cAuq71PDtGxggc97e2LThefs8En1C1gWRkI0sjPB8+Rc5ImrpiZer5/DAACnHrzBxrHttWbKqYbU2pkZUCYdIbUEXRonhOhUNFgT/DABsw/cxbTdt3FOWa9FNdtRfA0rclkaQn7ZCp1HJmQBANo2tERD5UmPuaGQDUTde5VZ7j4VSGRIyipgh/x0b2LHOdkBCrPS8tTS6WfsvYMv9kZg1J/X8PF2RU2b5Scel7g/VaYUTUlPaisHc0NM792ELSa+6iR3iG1JhY+rmyobQVc2KinU2dMGANDC2ZytYWivNjzntfI1tNKS4QEAIzq44ou+moHJLZdj8MXeCI2AlL6Az9Y1OhLxWus2VSfAtmoZGapMqboclNp7Ix6NFpxAs4WnkKmclINhGLZgf1RCNjvkKzQqGd8efqCxjXWjWmFGCykWDmyGsf7uVdZ3UnpfBTRD1LIB7H0/DxvO+q6etgAKg7NV5czjJJ1DeROU3wM0dI+Q2qNmH6kRQipEeq4YTxOzy/y4orWWfgkpPACYvvsOAEVxS0AxRXBtozpZlZaQKZWRJ8aZR4m4GauoVePlZM5Zb6c8GamImjBz/nmArj+Esq+nnoCHJYNaAAAmKYuIqg761yuLJodGJuHE/QQAiqK/ZaHKhlMNZSSktjI1rJ3J34nKoMa2K7HV25FaQJWt8X6RbLOisxs2sTct87aP33/D3h7VsSHCF/bFk+UD4KQslHw2MgkiqYzNDpbJGWy6EI35ykLqbtaF2VnmRoph3QlZBeyMgHVJZp6EU0D+0jPF7LCz9t9Fi8XBuPg0Gbfj07U+du0HrfHgu0BErxiIAG8HNDYHxvu7VUm/ydu7MKcX1n7QGu/4crPBVRfNKjMolZkn0VrXdLuO78zzyqHbtW3yHULqs9p5BEcIKTW5nEGbpYWzphz7vCu8ncxL9WNdtB5GirJwJKCoZ3QnPh2N7Uxw90UGRnUsfsrzmkhV6FxSQqbUj8FR2H29cBYmv0bcK4Vs5lIxNZ50EUllSMgsgLO5PmRy4NRD7oxhAj4PQ9s2QCtXS7irZWcBQLYyOKU6ACvKrBSzAUooU4rUEa1dLDWW7Z7kV/UdKaNnSTklN6rH0nLFyMqXwN3WhB2ybFzku83dprDo8l/j2sPFSnP4njYX5vRC959COcs+7NQQy4b4sPffb+eCey8VWbDNFp7Sua3h7QqL6bvbGKOVqyXuvsjAJ3+H49DUznXqBDklV8S5v+LEY/B4wL93XgEAFvx7H/MHeGl97LutnNlhevKy/2SSatLQxpjNEFdnpjoeqcCgVGqOCO2WnQEAOFkY6swizcyXwH3ecfh5WGPvJ53Y99Uu5fHa/Zflz14nhFQNOgshpI4rOivcO79dwme7butozaUKWHTUMU353hsv2Daeb3FluroJ+aXLlFIPSAGaV+FV9bQO3X5VYl2F2/HpCH6oyGpKzxWj2cJT6PFTGJp8exovtUymp8fng8fjwdPelM3sGqu8qmxpLATDMNh5LQ4A2KLrKtkiKZtVpYsq8FjThzgRUpLAFo6Y0kNRQ62ZgxmeLR+AzsqhJTXZokGVW3i9NotKyEbbpSHo+XMYwuPSkasM/Kvq6qkMauUMoYAHPw9r9PUuvnaROm0n2d+/25Jzv2gNMG2Wv9cSPi6FsyvyeDx80k3xXox4kaEza6i2KnrB6lVGPue44kVaPp4os7M7N7ZB7Kog7J7sh0tze1HdqDrGVBkgzhFV3Oyhg9ddZm+XZljz9Zg0duiuOtVsmISQmo/OQgipwxiGwR9h0RrLTz1MKNX0vaoDT29n7nC1Wf2aAgBOPnjDDgs0qZWFzpWZUiUEpYoWyrQ30z2by3dHHnHuv8nMZ6eoB4Chf1zBlB3heJaUgwlbb3DarnmgmdmkrYC8av+Z+RKsOhnJzh64c5If3G2M2eEmQOHQoKL/32m5YngvOoUjdxV1Umj4Hqnt+Hwe5g/wQuyqIAR/2b3WBFobKod9GdAMmBq+2HuHvT1s/RXciFF8l5oYcL8XHS0McXV+H2z/qGO59rd0cAuNjCZjfT00sDTS2n5iF3c8+C4QY/w0h58F+Tqhd3N7AIr6N+peZeTDfd5x/Bfxqlz9rS7PkxVXUJwtDNHUQfsFqXORiues+v3s3Ni21BlspPaojOF7L9O1Tzagvs8+ys+Wyu04ReD3iVqpih+H+1ZYnwghlYuG7xFShx299wZiqRyGQj4iFgUgu0CKDssVKdGpuWJOYVZtVMEO/SInS9N7eWL39XgkZBUgS1nDKPcthq5VN1UgpqRC5+42xohOLkxjsjLmFtEVqdXTUg1xlMjkeOd/lxClPED6b1oXNFE7eP/r4nPcLUVqubZpllX1ShgG2HjhObu8hbMFzn3VE3w+D4G/XEBUYjbuvcxE79Xn2TZPlg1AfFou+q65wNlmfi38/yOkLlBlGoikckhkchpKq5SZL9E5tNHGRPO3q6TfM12WDmmJtWeeYuVQH/T1stfa5vK83kjPFeNlej5G/3UNzRzMsHOSn9bvZ3XvtWmAc5FJOPM4EfMGNGeXd1l1DgDwxd4IOFkYoYO7Va3KIFJlRb3OLMDzuQMR8OsF9v+qe1M7XHiSzA55pPdz3VaYKVUxQam41MJjrcndPPAqIx8NrU3wVUBTpOaIsf1qLAa0dERilghnIwuDvVeiUzGolTP+ulh4TNTQmoKghNQW9EtBSB32T/hLAEA7NysYCgWwMzNgs2zeZJScEs0O7eLzMLGLOwDFATyfz0NzJzNOWy9Hs6IPr/FKW+hcFZxTKXolXX14h4DPA8Mw+HRHOBuQAoCxm68jJbtwyve9N1+wt38f3Ubrfps5aH9NizsRUvWtsb2ixsrMfRGc9U0XntQISAGAh62JxjJCSOUzUauPVNJw2/rEb8UZSOUMmjuaYffkwtpg1ib6Gr8/5TG2kxtuLeyLft4OxQaGrEz04eNigftLAnFwaucSA1IA0KOZHfT4PDxLymGHWWfmc4c5jdh4Fd8dfaTt4TWGRCZHqvKCS3qumLOOz+fhyPQuaO1qib5e9uyEHCp6daiWFtGkqimVU0GZUuFxhUNdFwz0wh9j2mHegOYQCvhwtDDE3P7N4etiiX7eDjgzqwc2fNgOALDnRjxepuchIUvxPg3ycapTddwIqesoU4qQOkoslbMFsL99p7BmiZOlEZKyRXiVkc+pgaFN4cxsfMwOaIZPujeCk4ViGINdkavSHna1L6ihOliWyOVgGEbnCUmuSJFFNKGzO2YFNNVYb22ij5/fb4XZB+5CJJVj1v67nCt4AJBVIMXcf+5pPHa8vxve8XWGi4UBVhy8go8C2uLTXREAFEP/Sit4ZnfOfYdSTIX8YaeGeL+dK/6984odZkIIqVpCAR8GenyIpHLkiKSwLJKJWdViUnKRlFWgMaFDVXqWlM3OQDrGryE6N7ZF7KogJGYVQI/PqzXZN+aGQgS2dMTxe2+w8PADFEhksNfy3bztSiyaOJhqHQZYmTaej8bKk5EAgJNfdNOYWRZQzDLYdOFJFDfi31hfD4endQEAZBVIwOOBbW9QiuAdqb1UQ2mzKyigrsqw+7BTwxKzBz3tTeGmVheu6w+FkxZM7dm4QvpDCKkateNXnRBSJnI5g7ZqM+41sS+8qqyatjomRUtV7SKk7MxsPPD5PDYgBQDCIkP6igapagPViU2BRI4Wi4NxWlmAvChV8fKPuniwM98VpaoHky+RsTMQqR6jcvV5qsbjpvb0BAC0cDbHGE85p05CVhmuPDYqEhR0LHLiM6wtt1jv7kl+WDbEB61cLbHk3Ra1pv4OIXVR0SEwj99k6ZxVs7IwDAOGYfDhX9cxctO1ainOnSOS4tMd4Xjnt0vssrH+7uxtB3ND2NSy35pFaheFlh1/jDOPErW2++bfB1XVJQBAeFwaG5ACgAFrL8J93nGIpIqLMFKZHFeepeDrg/d0BqSOfd5VY5m5oRCt1GbCzMqvuALYpOYxVk46kJknwbrQZ4hPzSvX9lSZUu3dtE+wU5SuAHXzWpi9T0h9RmchhNRBf158zp7c9PWy5xTqVhUlffC65HpGEjYopflV0apIllVtDGqovy55Yhl+Co7SaCOXM8hT1lsyKqaYuyoopSrECwCbxrbDokHeuLsoQKM9jwfM7NsEjhaaV81XDVVMR75+TFud+7MxKcymmNWvqcb/UdFMqaFtG+Dn91sBUASkasOsZITUF6ohfLkiKf688BwD1l7E+C034D7vONznHce0XbfhPu94qS4mvI2LT5PR7NtTmLX/Ll5lKDI0h/5xpVQTYlSkcZuv49TDBDZLakkdmJnQwdwQuycVDj9UTS7hqyVT+Wp0Kjs5RUV7lZGPQ7dfQqrMgN54/rnWds0WnsJfF5+jyw/nMPqv6/jn9kuNNu+2csaj7wPRsoH2bOuAFoUzIM7o41kBvSc1lZEyE04sk+On4Ci889vFcm1PVVOq6AQ7xfmsSFbU6vdb1cpjUkLqMxq+R0gdpLr6aWaoh7/Gd+Csa+2qmCI3Ij6jxO2wNaW0/LgPa+uCXdfjIZMz2DKhg8b62qDojHNPlYVaGYbBgn/vY8+NF9j5ceHJRNEZn9QVHaLwfjsXBLRwBABYGAtx8FN/DN9wFQDw03BfDGrlrLMmycgOrgjydWJrNWjzdf9mmPvPfQDAjD5NNNbbm3OzCQz0+BjezgXDSzG9OSGkaqkmkxi2/qrW9cfvvwEA9P/1AqKWDaiw/eaKpNDX42PsZsVMoOpZngCw58YLjPZrWGH7K8ntIr9Lw9u7Vtm+K5O2iwCTuzXC53vucJaN+vMae9vV2giHpnaBXTGzvZbFkHWXkZwtQnaBFP28HXBambF1ZlZ3ZBdI8d4fV9i2y44/5jy2mYMZTs3sVupi7BM6u+PHU1GwNdVH24ZWFdJ/UjMVvViXVSBFao7orTIa88UyNkPcScsFO12+7t8cw9u5YOSma5gT2IxT55MQUjtQUIqQOmz+AC+NZe62iuF7ycqipcWRylU1pTQPRPUEfByZrpm6X5toywDLzJMgOiUHe24oCpF/uPk6AEVmk6Ge7qCUfpFtfT+4Jed+e3dr3FrYF/dfZqJnM7tiD+55PF6xASkAGNmhITztzdBIR4Fye7OiQSmq60FITaVrlrmiRFJF/buQR4mYd+g+Vo9ohV7N3q4eXHhcOoatv1Jsm9034qosKBWVkM25v2VCe3ZYY12waWw7fLIjHADQp7k9mqpNZNHezQq34rjDJV+k5WPJkYdYV0zGbGkxDIPkbMVv/uIjD7H4yEMAgIO5ATyVw/tjVwXBfd5xzuOcLAwxvJ0Lxvq7lWl2QGN9PcSuCip3v0nNZ6wlg/yvSzEwNdCDq7Ux/BvZlDqwqpoEQMDnlfmz38jOFDe/6VumxxBCao6682tPCGE5WRjiTWaB1uEBFkaKYIdYKkeBRFbsDEJiqe7he3WBtoOpy9EpWofIGAsFxc7kor6qib2p1qF+tqYG6FWBBcXbuem+At3AkjsVslCPZqEhpLbo6mmLHR93xLOkHOSIpDj/JBm/nnkKAPCYf4Jtt+TIQ/Sa83bfKb+fe6pz3er3W+GrA3eRkFk5Q8m0uRFTWHMvZuXAMgVBaoMuatlSw9u5oJlyVkFrE32YGwrRedU5jcccv/8GY5+nolM5is7HpOSi189hWtd19OBuVz2jFwDe8XXCVwHN3nrfpO7Tdny4PixaY9n9JQHFXmwTSWUYq7wIaGEkrHOff0JI8SgoRUgdpD5rXlGmBnoQ8HmQyRlk5kuKDUqpMqXq6pTOPB4PjexM8Dw5lw3kxaflaa0tZVzCVTv12hq/ftC6ortaZkb6AoTO7smejIiUNVoIITXP6S+749czTzC2kzusTfTRTFmkt4kym6ZNQyuEx6Xj4tMUzuNUk1G8DVXtKBV9PT58GliAYRh09lQEK1JyxCVevKgoqiGMLRuY18kTUhMDPfz9UUe8yshH/5aKod2dGxcGqo5O7wozQ0V2yc5rcWw20webruHBd4FvlTUWlZCNwF8v6Fw/uiM3C669uzX+mdqZzaCbpyXbmpCizn3VA3liGe6/ysT8Q/e1tvn1zFN4O5ljoI8TjPQFkMrkiE3NRWM7U/B4PFx+lsKWUDCiGRsJqXcoKEVIHSSW6h52x+PxYGEkRFquGBl5Eo2C2OqkxRQ6ryv2Tu6EVxn5CI1Mwv/OPcMqtdmIVME7ADAppsg5oDjhiF0VBIZhaswJlYetCYJ8nPA8JbdMRUMJIVWrqYMZ/hjTrtg26pMbqKTlli1o9CQxGwsPP8Cwtg3wRpkFZSQUIF8iw7fveGNsJzcAhRc2AOCP0GeYVQXZMqm5YgBAM4e6+13VvamdznU+apnNQ9o0wJqQJ+xwpiMRr0s1jPJleh5CI5Mwxs8NL9PzsfCw9gCBSkcPzRnO2rlZ4cysHnCxMuJMBkKILo3sFBPouNua6AxKbb4UAwD4MTgSZ2b1gM+S0wCA5e+1xBg/N06AvWjAnBBS91FQipA6qLhZ8wCwQanMEqZqLpDIit1OXWBvbgh7c0NEJ2sO2ftmoBe+P/YIQOG0xyWpKQEplXVj2taoQBkh5O2IpIWBomFtXRDyKAFZBVKcfZyEIF+nUm1j3OYbSMgq4MwSunNSR0Qn5XKKA6t/5//vXNUEpdKVQSlrk+Lr6dUHFkZC3F0cgC6rzuFVRj6yC4r/rQYUM8V2/SEUAPDtfw811u+e7IfRfyqGR91dHMAO5dfG0970LXtO6jNTAz08XzEQe2++gLmRHt7xdYZEJof/ynNIUdYxTcwSYcTGwoL+3/z7ADYm+pzvtxHtqVA5IfVN3T3TJKQeU13lVg2HKMpceTBaUlBKVXg1qxQHxLVdIztuwfDTX3aHo9rsL8XNvFfTUUCKkNqvg3thVsvqEa3Qx8sBADBt9+1SPV4slSMhS7NGVDs3a4zo4KqRFaPKzCkpS7SipOUqfmestGSE1Vd9vBT1wnJF0hLbRifrLpZ/bX4fdHS3RoC3AyZ0di82IEVIefD5PIz2a4h3fJ0BKALc7jbcGpeP32Rx7n+68za+2BsBQFETddGgFlXSV0JIzUGZUoTUMXI5A6m85EwpoOSglEp8Wl7FdK4G821ggcAWDnC2NMKid7zB4/GQpfb6GJUyU4oQQirDWH83CPg8dFHWe+rd3B7/3nkFAOwQvivRKTDQE2idBOHa81SNZd2a2GosU+nqaYvd1+PRwlkxrKw8GZcxKbnYf+sFJnX10DlV/JNExex79malnwq+rjNR1pHKLkVQ6mZsutbln/VszF5g2TSufcV1jpBSKjqzJKCY0djSSIj0PO5xqIWRsE7NukkIKR361BNSx0jkhSnQ2mpKAYCZofJAt5QZUMPb1f1Uaj0BHxvHcg/Y1acxNqbCm4SQaiQU8DG+szt7/x1fJ3y+5w4A4N7LTNyKS8OPpxSTNDxfMVBjtlBtmTSr32+lc3+qh8sYBifvv8EX+yKwbnRb9PN2KHPfB/9+CVkFUjxNzMFf47UHRlSznrZ21Zw1tr5SnZyXJlPqVqxiSOakrh5o7mSOwBYOxc52RkhVmdarMdaFcmfkG9HOFSuG+uDkgzeYvvsOu7xo1johpH6g4XuE1DEStWKRujKlzNmgVPEHuqpZ90zqaZaQrY4r+oQQUt14PB4G+ihmcZuw9QYbkAKA7VdjNdqfeZwIAPBRmynUvpiJLvjKrCiZnMHUXbchlsox+e9bb9XXLOVvze147dk8DMMgV6xoY05Dy1iqoFROaYJSymyUbk3tMLydCwWkSI0xJ7A5dk3yg59aYf2PunpAwOfhHV9nxK4KQtjsnpjQ2R3fvuNdjT0lhFSX+nmmSUgdJpGqZ0ppD0qpDlaLy5TiDgOsnzWJTNRSyFUnTIQQUlP083bAifsJyBPLOMu/O/oIE7t4AADmH7qPPTfi2XX/G9UG6XliNHUwK3bbqhpTcoYptl1Z6JrNrUAih2o39fUiiDaFQSlZse3Sc8XsMPs2DS0ru1uElFkXT1tYGetj4P8uAgCaOnCL6bvbmmDJu1RLipD6ijKlCKljCqSqGfN4Ok8AVJlSWfm6Ay2cYYA6CqbXJ+ozwxBCSE0w0Kf4Wfc2no/mBKQAwN3GGG0bWpVYt0U1/O/ey0zO8sgEbpHif++8xOZLMRBJZXiZXnz9weRsERYevg9GLdD1Mj0PXotOsfeNaKg0SzXBRn4JF0Vm7otgb5tThhSpobydzXFpbi9ELu1PE7AQQjjochQhdUy+8oq5YTEH9hbGitmN0vPEOtvI5GrDAPkUlJLKKChFCKlZVEXNw+PS8UWfJjDSF2DVyUh0bmyDNt+f1igi3NzRrNQng3wd7cKiktHc0RyAItv2y313AQD7b75AVGI2unjaYOuEjuzsr8nZIs7jd16Lx85r8VgY5IV3WztjTcgT7n51XEypj1S/4+pFzFWz66oyoXdei8P5J8lV3zlC3oKLlXHJjQgh9Q4FpQipY/IliqBUcVebrYwVV1Iz8nQP35OqBaV0ZVzVJ+qvByGE1BR7JndCvkQGCyMhQh4p6kZdiebOtPdVv6aITc3Dpz0alXq7Ah1BKfULFn4rzrK3o5Sz511+loqmC0+WuP1lxx9j2fHHpe5PfaQ+hPxpYjaik3Pwxd4IiKRyfPduC7zOyMfGC8+rsYeEEEJI+VFQipBaIKtAgsw8CVytS77CVKAKSukXF5QqOVNKqlYwXa8eB6W6N7XDhSfJGNvJrbq7QgghGvT1+GxWkpeTZp2oI9O7wNfFsszb1ZUgm5hVwN4uWsuqPH4Y5oNOjWwqbHt1QWtXS/Z2v18ucNYtPvKwintDCCGEVA4ak0NILdDzpzB0+zEUL9KKr9cBAPliRWp/cZlSlspMqaJDO9RJlTWl+Lz6PZxi09h2ODq9K4a3c6nurhBCSLHszbiz6W2d2OGtAlLajOroCgBIyCzQ2ebz3p7FbqOLpw1ufNNHY/nc/s0xskNDuNnQdPDqdE1WosunPRpXUk8IIYSQykOZUoTUAmm5ioymK9EpGGndsNi2quF7xdWUUmVKZeSJwTCM1hojqiEaevW8npShUAAfF4uSGxJCSDXTLzIpRa9m9m+9LQ9bE+gL+HCxMsK+Kf64E5+OPTde4PSjRHRZdQ6vMvI1HjOrX1N8FdCMvX8lOgWj/7wOAFj+XkuM8VNknD5bPgBvMguQmS8Bw4C+Y9+SkVCAi3N7wcpYH3KGKXMQixBCCKkJKChFSA2nXr9DIiu5rlHpakopglJSOYMckRRmWmbrUQ3fo3pShBBSe7RyscDdl5n4c1z7cm3HycII1xb0gZmhHoQCPhzMC7OwigakVIGrohc4Oje2RczKgZAz3N8SPQEfrtbGcC1XD+uHZg5mbL2um9/0BQMGabliHLj1EvMHNIeeMhAlAP1WE0IIqZ0oKEVIDZerNhW0WFryDHAF4pJrShnpC2Cgx4dIKkdGnkR7UIrNlKIDXUIIqS3++LAd4lJy0dnTttzbsjbRZ2+rB6XUXZrbq9gZtXg8HgT0M/LW/p3WGV/sjcA4fzfYmRkAUAzT/PYd72ruGSGEEFIxKChFSA2XXVAYlMrM110DSqU0mVKA4mTjTWYB0nLFWguoy5Q1pfTobIIQQmqNBpZGaGBpVOHbtTXVh74en704MqClI9Z/2K7C90O4jPX1yp31RgghhNRkFJQipIZLyymcIS8pW3eBWZXS1JQCAEtjRVBK1wx8Enb4HtWoIISQ+k5PwMeeyZ1QIJGhSwVkYRFCCCGEABSUIqTGS8kVsbffFDPrkUo+O3yv+GCSlXIGPl3ZVzIavkcIIURNOzer6u4CIYQQQuoYSoEgpIZLyS4MSkUlZJfYvqCUw/eMlTWn8pRBrKLYmlI0fI8QQgghhBBCSCWgoBQhNVwKZ/ieiDMbnzalrSlloFyvCmIVxdaUokwpQgghhBBCCCGVgIJSpF7JKpBg57U4pOVqr6NUE71Wm3pbJmeQkiMqpnXh8D3DYmbfAwBDPVVQSvuMfoU1pSgoRQghhBBCCCGk4pWpplRGRgb+/fdfXLx4EXFxccjLy4OdnR3atGmDwMBAdO7cubL6SUiF2HE1Dj8FR+HArRf4b3rX6u5OqagHpQAgOVukc2puoPSZUoZCRUxad6aUIiglFFDsmhBCCCGEEEJIxSvV2ebr168xadIkODk5YdmyZcjPz0fr1q3Rp08fuLi4IDQ0FP369YO3tzf27dtX2X0m5K39efE5AODuy8xq7knpvSoSlNJVA0qltDWlVLPzFUiLrylFmVKEEEIIIYQQQipDqTKl2rRpg/HjxyM8PBze3t5a2+Tn5+Pw4cP49ddf8eLFC8yePbtCO0pIRcjI0z7TXE2WmKWYcU8o4EEiY5Anlhbbns2UKmn4nipTSi3IJZHJ2cwoqYxqShFCCCGEEEIIqTylCko9evQINjY2xbYxMjLCqFGjMGrUKKSmplZI5wip7+RyBpn5ikCai5UxYlJyS8yUYmtKlZAppRoCGJ+WBwA4/yQZE7bewNz+zfFpj8aUKUUIIYQQQgghpFKVavheSQGp8rYnpCrkiIrPMKqJsgokUE2252ShCCKVGJRSFi4vafheYztTAIVBqa8P3gXDAKtORgIorCmlRzWlCCGEEEIIIYRUgnKfbT5+/Bhbt25FREREmR+7cuVKdOjQAWZmZrC3t8eQIUMQFRXFadOzZ0/weDzO36effsppEx8fj6CgIBgbG8Pe3h5z5syBVMoNQISFhaFt27YwMDCAp6cntm3bptGfdevWwd3dHYaGhvDz88ONGzfK/JxIzZWcXThrXSM7k2rsSemlK4cbmhrowdxQCACYfeAuLjxJ1vmYglIO33O1MgYARCfnQi5nYKzPTZyU0PA9QgghhBBCCCGVqExBqe+//x4//fQTez80NBStW7fGnDlz0KFDB+zatatMOz9//jymTZuGa9euISQkBBKJBAEBAcjNzeW0mzx5Mt68ecP+/fjjj+w6mUyGoKAgiMViXLlyBdu3b8e2bduwaNEitk1MTAyCgoLQq1cvREREYObMmZg0aRKCg4PZNvv27cOsWbOwePFi3L59G61atUJgYCCSkpLK9JxIzZWWWxiUUgVcarq0XDEAwNJYCGO1INO4LboDpqrheyVlSjlZFs7gd/JBAhzVZvQ7du811p55CoAypQghhBBCCCGEVI4ynW0ePHiQU+h8+fLlmDFjBlJSUvD7779jxYoVZdr5qVOnMGHCBLRo0QKtWrXCtm3bEB8fj/DwcE47Y2NjODo6sn/m5ubsutOnT+PRo0fYuXMnWrdujQEDBmDp0qVYt24dxGLFCf2GDRvg4eGB1atXw8vLC9OnT8fw4cPxyy+/sNtZs2YNJk+ejIkTJ8Lb2xsbNmyAsbExtmzZUqbnRGquVxkF7G2RpHYEpTLyFO9hK2N9xKbmltBaQVXovKSaUkK1YFN0cg6ndtT03XfwPEWxP30KShFCCCGEEEIIqQSlOtv8+++/sX37dsTGxiIiIoK9f/nyZZiamuLvv/+GXC7H8+fP8ffff+Pvv/9+q85kZmYCAKytrTnLd+3aBVtbW7Rs2RLz589HXl4eu+7q1avw8fGBg4MDuywwMBBZWVl4+PAh26Zv376cbQYGBuLq1asAALFYjPDwcE4bPp+Pvn37sm1I7fcqPZ+9LZLWjqCUaviepbEQt+MzOOvORSZqfUxpZ98DgPfbuQAA1p59iuwC7TMTGuhRUIoQQgghhBBCSMUr1ex7bm5uAAB9fX04ODjAzc0NERERMDc3R69evcAwDEQiEXg8Htzd3cEwTJk7IpfLMXPmTHTp0gUtW7Zkl48ePRpubm5wdnbGvXv3MHfuXERFReHQoUMAgISEBE5ACgB7PyEhodg2WVlZyM/PR3p6OmQymdY2kZGRWvsrEokgEhUOB8vKygIASCQSSCTaT+5rA1Xfa/Nz0CUxszCYKZLKasVzTM1WBNIsDPXw6whfzNx/j1330bZbeLo0gNNeJmcgVgbc9CAv8TmaGyoCVyb6AmTkaW+rx6+b74eapi5/9gipyeizR0j1oM8eIdWDPnukqpT2PVaqoFSPHj0AAG3btsWxY8cwd+5cnDp1CgMHDkT37t0BAPfv34erqyt7v6ymTZuGBw8e4NKlS5zln3zyCXvbx8cH/2/vzuOjKu/+/79nJrNkIQkEkoAEZFFARERQiLigIGFpKdVatWhBqf60cCugWPFrcavFqtiiot7WCu1dqEsXVKBARAHRsIhEZBUFBYWENYQkJJnl/P6YzEkmG1kmMwm8no8HD2fOuebMNdxzWed9f67Pad++vYYOHapvvvlG3bp1a9B7hcKsWbP0+OOPVzm+YsUKxcTERGBGoZWZmRnpKYTcF19ZFSgOLHF7tWTJUlka2cO7yCO99Y1Vl7Q11Dep/mHs6Xy2zz/nE4cPqNj1vSov2aVLlwY9L/HKHLPmww90umKphAL/eKvPrcP5bklV/0KO5fygpUv3N/AToL7OxLUHtASsPSAyWHtAZLD20NQq7nCrTZ1CqYBnn31WP/nJTzR48GD17NlTr732mnlu/vz5GjFiRP1mWWby5MlavHix1qxZo44dO9Y6duDAgZKkr7/+Wt26dVNqamqVu+Tl5vq3NaWmppr/DByrOCY+Pl7R0dGy2Wyy2WzVjglco7IZM2Zo2rRp5vP8/HylpaVp+PDhQT2vWhq3263MzExdd911stvtkZ5OSP3thw3S0TxJkiGLho8YEdRXqSHmrtqj7GNfK/uYqlQthULWe9ulH77Xxb266/pruumhjcH/43HplUPVrpXTfH60oETasFqSNGb0SFlPc+e8nPxiPf/lGp30WGuscDy3y7kaNapnIz8JTudMXntAc8baAyKDtQdEBmsP4RLYTXY69Qql+vbtq2+//VZHjx5VUlJS0LkHHnig3mGMYRj6n//5H/3nP//RqlWr1KVLl9O+Jjs7W5LUvn17SVJ6erqeeuopHTp0SMnJyZL8qW98fLzZlD09Pb1KRUlmZqbS09Ml+bcl9u/fXytXrtTYsWMl+bcTrly5UpMnT652Hk6nU06ns8pxu91+RizuM+VzVPTdseCk1mexyW6v1xKo4kSxx3zcFH9f+WXXT4pzyeFwVDl/qNCjDm3izOcFbv+WUpvVIqez6vjK2ifaZLX4t/0FtIl1qGdqK336zVFJUts41xn3XWjOzsS1B7QErD0gMlh7QGSw9tDU6vr9atAv8sqBlFQeEtXHpEmTtHDhQr377rtq1aqV2QMqISFB0dHR+uabb7Rw4UKNGjVKSUlJ2rJli6ZOnaqrrrpKF110kSRp+PDhuuCCC3TbbbfpmWeeUU5Ojh555BFNmjTJDI3uvvtuvfTSS3rwwQd1xx136MMPP9Tbb7+tJUuWmHOZNm2axo8frwEDBuiyyy7Tn/70JxUWFur2229vyF8RmpnCEo+OFJQGHStxexXnbFwoFV3hDncni91q5Qrtv9iPF/r34baO9QdM9w09T29t3C9DhnLzS3Qw75QuTks0x9/8mr8xf8WQqTZRNqvaxjl16KQ/zHJEWbXh4aGyWCz6x4Z9WrLloCYMPjd0HwgAAAAAgDJ12rv05ptv1vmC+/fv1yeffFKnsa+88opOnDihIUOGqH379uaft956S5K/gumDDz7Q8OHD1bNnT91///264YYb9P7775vXsNlsWrx4sWw2m9LT03Xrrbfql7/8pZ544glzTJcuXbRkyRJlZmaqb9++mj17tl5//XVlZGSYY2666SY999xzmjlzpi6++GJlZ2dr2bJlVZqfo2U6eKJYkj9EcpRt2QvFHfjc3vJrbD9Qt/LE+sjJ98+7bZw/YJ163fnKmnGtBnT236Hy4IliFZV65PMZWr/naJXgrS5SE1zm48Rou6JsVtmsFt06qLP+cdcgJUTz/0EBAAAAAIRencpEXnnlFT3++OO6/fbb9eMf/1i9evUKOn/ixAl98skn+vvf/67MzEz95S9/qdObn+4ufWlpaVq9evVpr9O5c+cq2/MqGzJkiDZv3lzrmMmTJ9e4XQ8t27Dn/d+jU26vWjmjVOr1mXepa4wTp8rvKHDn3z7TlscyahldP6dKvfr2aKEk6byU8i16FovFDJK+/OGEnn/qKw3q2kbJ8eXh0r3Xdq/z+yS3ckk6IUkEUAAAAACAsKlTKLV69Wq99957evHFFzVjxgzFxsYqJSVFLpdLx48fV05Ojtq2basJEyZo69atVBehWXNEWaWS0FRKbfn+hPm4T8eERl+voh/yTskwpFbOKLWLC+5f1iExWpL0n80/SJI+2HFI6V3922qf/dlFunFAWp3fJzWh/NqEUgAAAACAcKlzQ50xY8ZozJgxOnLkiNauXavvvvtOp06dUtu2bdWvXz/169dPVmvj7mQGNJU2sQ4dKyzVsilX6o55GyVJJR5vo65pGIZ25pw0n1cOdLL352nFthzdO/Q8uSr0nqrJ3iOFWrkjV7cO6iyX3aa8Iv9WvNaxDlkswXfR61tNAJa1x9+YvHNSbL0+R0qr8gorQikAAAAAQLjUu8tz27ZtzTvUAS2BYRjKL9tmlxBtl7MsIGpspVTl1+cVuYOej53r763m9RmaMSp4y2t1fvTCxyos9epIQakeGtlTx8uu1zqmalB04TkJctisKvVW/Qxd29UzlIonlAIAAAAAhB+lTTjjFbt98pTdjS7eZZczqqzRubtxodSp0uBKq+MVQqlid/m5T745UqfrFZZd78OduZJkVkolxjiqjHXZbeqcFFPleLwrSkmxVcfXJqVCo/N4QikAAAAAQJjUu1IKaGmKSj3m42i7zQylSr2N275XWOG6knSiqPzOd3fM32g+9nhrb+hfWf4pj36/dIdeW7NHkhTjqH7r3+5DBVWOdU+Oq7LV73RS4st7SiVWU5UFAAAAAEBToFIKZ7xAlZTNapHVavE3OlfoK6XyyrYIen2GPv3mqHm8cnh1OvnFbjOQkqT/bs2pdlxqhW13Ad2T46oZWbtUtu8BAAAAACKAUApnPHdZ36Uoq7+CyBkVmp5Sge12rZz+gsOiUq9KPF59f7woaNz+Y6d0rLC0yutrUlQp7Jpw+bnVjnt38mAN7p6k527sax5rSCiVEG03gzpCKQAAAABAuDQ4lCotLdWuXbvk8dSvCgQIN3fZ9jmHzf91N3tKNfLue0Ul/u9+SoJLZXmXTpxy66tc/7a6Xu3jzbGb9x2XJG07cEI/mfuJ/rP5+zq9x7zbL9XDNTRJT4l3acGvBml0n/bmsXatnNWOrY3FYjGrpQilAAAAAADhUu9QqqioSBMnTlRMTIx69+6tffv2SZL+53/+R08//XTIJwg0lidQKWUrq5SyB0KpxlVKBSqaYp1RZphzosit/249KEk6PyVO119yjiRpy/cnJPl7TX2xP09T3/qiyvUClVwB3drF6poeyWYVU02iHTZd3i1JsQ6bLu/WtkGf5aZL09Srfbz6d27doNcDAAAAAFBf9Q6lZsyYoS+++EKrVq2Sy1Xei2bYsGF66623Qjo5IBQClVJ2s1LKv32vtNHb9/yVUrEOm1qX3fHucEGJck4US5LSWseob8dESdKW7/P0t6xvlZtfYr7e6wtugF75LnsVK61O540Jl+rTGUOVUk2fqbqYdE13/fe+K6u90x8AAAAAAE2h3nffW7Rokd566y0NGjQo6C5fvXv31jfffBPSyQGhEOgpFQilAtv4GlspFWh0HuOIUvsEl/YcLlRufrG+Oezfvndtr2QZZbnT9oP5+mjX4aDXH8g7pbQ2MeZznxEcUvVIaVXnubjsNrns1d+lDwAAAACA5qjelVKHDx9WcnJyleOFhYX1vhU9EA4eXw3b99yN6ylVaIZSNnVIiJYkffbtcbMaqlu7OJ2T6D9esUIqYM+RwqDnle/m16VdbKPmBwAAAABAc1bvUGrAgAFasmSJ+TwQRL3++utKT08P3cyAECn1VN6+F5pKqZPFbklSK1eU2fdpwXp/j7V2rZxKiLYrKa7qdrhhvfyh7t6yiirJv5XvVKWQLKN3aqPmBwAAAABAc1bv7Xu///3vNXLkSG3fvl0ej0dz5szR9u3b9emnn2r16tVNMUegUcxKqbJG4oGeUo0Jpb7Yn6c/fbBbkhTnilKPlFZmICVJF52TIMkfhCXG2JVX5DbPdUuO0wc7Dunbo0XmsaLS8rtYpsQ7NfNHvc0QDQAAAACAM1G9f/VeccUVys7OlsfjUZ8+fbRixQolJycrKytL/fv3b4o5Ao3iqdLovHGVUj6foZ/M/cR8nnuiWKP6tA8a0z05znzcNs5pPn5v8mC1K3t+vKjUPF5Y4q+SslktWjdjqEZfFHw9AAAAAADONPWulJKkbt266c9//nOo5wI0idKyRueBLXYOM5RqWE+pzfvzgp6fLPZUaTJ+82WdzMdfHyrfppfWOkZf5fqfV6ye+mBHriR/fyp6swEAAAAAzgb1DqX27dtX6/lOnTrVeh4It1JP4O57ge17jauU+vfn3wc9f/qGi6qM6dK2+ibliTF2JUbbJUl5p8pDqUcWbZXkD7gAAAAAADgb1DuUOvfcc2ut5PB6G3dHMyDU3N5AKFW2fa+sqqnE3bBQKr8sOBrQubX+eNPFatfKvx3vjsFd9MYne/V/Ey8LGv/MDRfpwX9tUXrXJFksFiXGlIVSFbbvAQAAAABwtql3KLV58+ag5263W5s3b9bzzz+vp556KmQTA0IlEEoFKqQC/wxs66uvPWV3zbvrqq5KaxNjHv/tj3pp2vDzFecMXlY/vzRNP+vf0XyeGOO/I9+xAn8oNfWtbPNc7w7xDZoTAAAAAAAtTb1Dqb59+1Y5NmDAAHXo0EHPPvusrr/++pBMDAiV0iqNzgOVUvWv6jMMQ3uPFEry30WvIovFUiWQCrBay6sL2ye4JEknSzx6asl2/WfzD+a5/72NmwUAAAAAAM4OIbvnfI8ePbRx48ZQXQ4ImfKeUpUbnde/Uionv1hFpV5FWS3qVKFKqj5iKwRXf/54r/l43MBOOicxukHXBAAAAACgpal3pVR+fn7Qc8MwdPDgQT322GM677zzQjYxIFSq9JRqRCj1zSF/lVSnNjHm9Rqia7tY7TlcaD5/ZHQv/erKrg2+HgAAAAAALU29Q6nExMQqjc4Nw1BaWprefPPNkE0MCBV3WfjkiKocStV/+96eI/5+Ul3bVX93vbqa+4tLNHLOx5KkNyYM0LU9Uxp1PQAAAAAAWpp6h1IfffRR0HOr1ap27dqpe/fuioqq9+WAJhdoaO6w+cPUwN33ShtQKRWoburWLu40I2vXq328vn16dKOuAQAAAABAS1bvFOnqq69uinkATaY0lNv3DoemUgoAAAAAgLNdnUKp9957r84XHDNmTIMnAzQFt6fs7ntRlRqdN+Due4FKqa6NrJQCAAAAAOBsV6dQauzYsXW6mMVikddb/x/6QFNym9v3GlcpdbywVD/knZLU+O17AAAAAACc7eoUSvl89d/mBDQXpVUanft7SpV4fDIMo0rj/prsPuTfutexdbTaxDqaYKYAAAAAAJw9Gn5Pe6CFcJs9pQKNzq0Vzhl1vs7mfcclST1SWoVwdgAAAAAAnJ0adLu8wsJCrV69Wvv27VNpaWnQuXvvvTckEwNCpbSG7XuSVOLxmhVUpxOolLqkc+sQzxAAAAAAgLNPvUOpzZs3a9SoUSoqKlJhYaHatGmjI0eOKCYmRsnJyYRSaHYWbzkoSSoqa2weCKck/xa+utY95eYXS5JS4l0hnR8AAAAAAGejem/fmzp1qn784x/r+PHjio6O1rp16/Tdd9+pf//+eu6555pijkBIvL1xvyR/Q35HPZudG4ahj3cfkSSlxDubZoIAAAAAAJxF6h1KZWdn6/7775fVapXNZlNJSYnS0tL0zDPP6OGHH26KOQIhkRBtNx+bd+Bz1+1ukVt/yDcfd2oTE9qJAQAAAABwFqp3KGW322W1+l+WnJysffv2SZISEhK0f//+0M4OCKHpGT3Nx4E78AX6TZ3OX7O+NR93TooN6bwAAAAAADgb1bunVL9+/bRx40add955uvrqqzVz5kwdOXJE//d//6cLL7ywKeYINEpijF15RW6lJpRvuyuvlCoPpXbnntSK7bm6Y3AXRTtsQdfYc9jf5PymAWlhmDEAAAAAAGe+OldKeb3+bU6///3v1b59e0nSU089pdatW+uee+7R4cOH9dprrzXNLIFG8HgNSVKUtfzrHgilvj1aaB4b/cJaPbt8l/70wVdVrvHlDyckSbcM7NSUUwUAAAAA4KxR50qpc845RxMmTNAdd9yhAQMGSPJv31u2bFmTTQ4IBXfZFj17VHko5bL7K6GOFpSaxwJb+dbsPqIZFV6/72iR3GXBVsfW0U08WwAAAAAAzg51rpSaNGmS/vnPf6pXr1668sorNX/+fBUVFTXl3ICQMEMpq8U8dtX57SRJe44UVBlfXKn5+T83lfdKaxPjaIopAgAAAABw1qlzKPXb3/5WX3/9tVauXKmuXbtq8uTJat++ve68806tX7++KecINJjXZ8jnL3JSlK38635+Spwk6etDVUOpolJP0HNXhf5S1grBFgAAAAAAaLh6331vyJAh+utf/6qcnBzNnj1bO3bsUHp6unr37q3nn3++KeYINJi7wt317LbyQCk1wSVJOnSypMprTpUGV0rtPHhSkvTgiB5NMUUAAAAAAM5K9Q6lAuLi4vSrX/1Ka9eu1fvvv6+cnBxNnz49lHMDGs0TKJOSZK9QKZUS7w+lDuf7QylvhXHFFe7IJ0nfHfNvU+3aNrbJ5gkAAAAAwNmmwaFUUVGR5s+fr6uvvlpjxoxRUlKSnnrqqVDODWg0T1ClVNVQ6mSJR4UlHhUUl2/ZK/X6VOrxmb2l9pXdoa9TG0IpAAAAAABCpc533wv49NNP9cYbb+idd96Rx+PRz372Mz355JO66qqrmmJ+QKME7qhnsUi2Cv2g4pxRinXYVFjq1aGTJYqq1Cvq8qc/VIzDpn/dc7mOF7klSWltuPMeAAAAAAChUudQ6plnntG8efP01VdfacCAAXr22Wd1yy23qFWrVk05P6BRPF7/tjy7tWpRYEq8S3uOFCo3v1jxLnvQuSMF/m19q786LElq5YpSq0pjAAAAAABAw9U5lHr22Wd166236p133tGFF17YlHMCQibQ6Lxik/OAdq2cZihVk8ztOZIkh63BO10BAAAAAEA16hxKHThwQHY7lSJoWdxllVJR1YRK8dH+73NhiVcnK/SUqmj5tlxJ0tHC0iaaIQAAAAAAZ6c6l380RSA1a9YsXXrppWrVqpWSk5M1duxY7dq1K2hMcXGxJk2apKSkJMXFxemGG25Qbm5u0Jh9+/Zp9OjRiomJUXJysqZPny6PJzhkWLVqlS655BI5nU51795d8+fPrzKfuXPn6txzz5XL5dLAgQO1YcOGkH9mhJfHF6iUqvpVd9ltkqRit1cni921XueGSzqGfnIAAAAAAJzFIronafXq1Zo0aZLWrVunzMxMud1uDR8+XIWFheaYqVOn6v3339c777yj1atX68CBA7r++uvN816vV6NHj1Zpaak+/fRT/fWvf9X8+fM1c+ZMc8zevXs1evRoXXPNNcrOztaUKVP0q1/9SsuXLzfHvPXWW5o2bZoeffRRff755+rbt68yMjJ06NCh8PxloEm4PWU9parZvhdt93/9T7lrrpQKuP6Sc0I/OQAAAAAAzmL1vvteKC1btizo+fz585WcnKxNmzbpqquu0okTJ/SXv/xFCxcu1LXXXitJmjdvnnr16qV169Zp0KBBWrFihbZv364PPvhAKSkpuvjii/Xkk0/qN7/5jR577DE5HA69+uqr6tKli2bPni1J6tWrl9auXas//vGPysjIkCQ9//zzuvPOO3X77bdLkl599VUtWbJEb7zxhh566KEw/q0glNxllVJR1YZS5ZVSPp9R63XObRsb+skBAAAAAHAWi2goVdmJEyckSW3atJEkbdq0SW63W8OGDTPH9OzZU506dVJWVpYGDRqkrKws9enTRykpKeaYjIwM3XPPPdq2bZv69eunrKysoGsExkyZMkWSVFpaqk2bNmnGjBnmeavVqmHDhikrK6vauZaUlKikpMR8np+fL0lyu91yu2vfCtacBebekj9DRadK/L2g7FZLlc8UqJ4qKnGr6DTXaRttO2P+TtA8nWlrD2gpWHtAZLD2gMhg7SFc6voda1Ao5fV6tWjRIu3YsUOS1Lt3b40ZM0Y2m60hl5Mk+Xw+TZkyRYMHDzbv7peTkyOHw6HExMSgsSkpKcrJyTHHVAykAucD52obk5+fr1OnTun48ePyer3Vjtm5c2e18501a5Yef/zxKsdXrFihmJiYOn7q5iszMzPSUwiJXScskmw6VViopUuXBp37fr9VklU7v94rf6FUzbtZly37b1NOEzCdKWsPaGlYe0BksPaAyGDtoakVFZ2u9MOv3qHU119/rdGjR+v7779Xjx49JPkDmrS0NC1ZskTdunWr7yUlSZMmTdLWrVu1du3aBr0+3GbMmKFp06aZz/Pz85WWlqbhw4crPj4+gjNrHLfbrczMTF133XVnxN0W43YfkbZ/rjat4zVqVHrQue8/3qtl3+9WcoeOKnF7pUO5inXaVFjiDRqX3MqpUaOGh3PaOAudaWsPaClYe0BksPaAyGDtIVwCu8lOp96h1L333quuXbsqKyvL3GZ39OhR3Xrrrbr33nu1ZMmS+l5SkydP1uLFi7VmzRp17Fh+l7PU1FSVlpYqLy8vqFoqNzdXqamp5pjKd8kL3J2v4pjKd+zLzc1VfHy8oqOjZbPZZLPZqh0TuEZlTqdTTqezynG73X5GLO4z5XP4yqqf7DZblc8T6/Q/L/UaOlkWRE28oqsWrv9OE6/oqj8s81fJxbmizoi/C7QMZ8raA1oa1h4QGaw9IDJYe2hqdf1+1fvue6tXr9YzzzxjBlKSlJSUpKefflqrV6+u17UMw9DkyZP1n//8Rx9++KG6dOkSdL5///6y2+1auXKleWzXrl3at2+f0tP9VS/p6en68ssvg+6Sl5mZqfj4eF1wwQXmmIrXCIwJXMPhcKh///5BY3w+n1auXGmOQcvk8fobnVd79z1HWaPz0vK7713YIV6fPXKd7hlSXvHnsEX0JpUAAAAAAJyR6v1r2+l06uTJk1WOFxQUyOFw1OtakyZN0t///nctXLhQrVq1Uk5OjnJycnTq1ClJUkJCgiZOnKhp06bpo48+0qZNm3T77bcrPT1dgwYNkiQNHz5cF1xwgW677TZ98cUXWr58uR555BFNmjTJrGS6++67tWfPHj344IPauXOnXn75Zb399tuaOnWqOZdp06bpz3/+s/76179qx44duueee1RYWGjejQ8tU6kZSlX9qrvK7r53yu3VyWJ/E7ZWrvI095bL0iRJDwzv0dTTBAAAAADgrFPv7Xs/+tGPdNddd+kvf/mLLrvsMknS+vXrdffdd2vMmDH1utYrr7wiSRoyZEjQ8Xnz5mnChAmSpD/+8Y+yWq264YYbVFJSooyMDL388svmWJvNpsWLF+uee+5Renq6YmNjNX78eD3xxBPmmC5dumjJkiWaOnWq5syZo44dO+r1119XRkaGOeamm27S4cOHNXPmTOXk5Ojiiy/WsmXLqjQ/R8vi8RqSpKhaQqlid3mlVHx0+ZJ4amwf3Tf0fKUmuMIwUwAAAAAAzi71DqVeeOEFjR8/Xunp6eYeQY/HozFjxmjOnDn1upZhGKcd43K5NHfuXM2dO7fGMZ07d65yZ7XKhgwZos2bN9c6ZvLkyZo8efJp54SWw+PzV0o5qtu+Z1ZK+ZRfVikVX6FSymq1EEgBAAAAANBE6h1KJSYm6t1339Xu3bu1c6e/EXSvXr3UvXv3kE8OaKzSQKWUtWqlVKCn1Mlit4rd/vCqlaveSwIAAAAAADRAg3+Bn3feeTrvvPNCORcg5AKNzqOqqZRyRflDqcMnS8xjcU5CKQAAAAAAwqFOv8CnTZumJ598UrGxsZo2bVqtY59//vmQTAwIBbc3sH2vukop/7ESj39MrMNWbe8pAAAAAAAQenUKpTZv3iy3220+ronFUrUaBYgkt9novJpKqbKeUgEV77wHAAAAAACaVp1CqY8++qjax0BzF7j7nr2Wu+8F0E8KAAAAAIDwYa8SzmiB7XvVhVLRhFIAAAAAAERMnX6FX3/99XW+4L///e8GTwYINbevrNG5le17AAAAAAA0J3UKpRISEpp6HkCTcHvKtu9FVa2UslktctisKi2rpoqPJpQCAAAAACBc6hRKzZs3r6nnATQJT1mllL2aSilJctnLQym27wEAAAAAED4N/hV++PBh7dq1S5LUo0cPtWvXLmSTAkKl/O571bdPi3bYlF/skUQoBQAAAABAONW70XlhYaHuuOMOtW/fXldddZWuuuoqdejQQRMnTlRRUVFTzBFosNoanUvBfaXi6SkFAAAAAEDY1DuUmjZtmlavXq33339feXl5ysvL07vvvqvVq1fr/vvvb4o5Ag3mMUOp6rfvVbwDX1KsIyxzAgAAAAAADdi+969//Uv//Oc/NWTIEPPYqFGjFB0drZ///Od65ZVXQjk/oFEC2/fqUinVmlAKAAAAAICwqXelVFFRkVJSUqocT05OZvsemp3A9r2oGiqlXPbyJZDI3fcAAAAAAAibeodS6enpevTRR1VcXGweO3XqlB5//HGlp6eHdHJAY3l8ZZVS1hoanVeolGpFTykAAAAAAMKm3tv3/vSnP2nEiBHq2LGj+vbtK0n64osv5HK5tHz58pBPEGgMs9F5VA09pRwVQynuvgcAAAAAQLjU+1d4nz59tHv3bi1YsEA7d+6UJN1yyy0aN26coqOjQz5BoDHM7Xs1VErZKhwnlAIAAAAAIHzq9Cv8kksu0cqVK9W6dWs98cQTeuCBB3TnnXc29dyARjtdo/PA3fkkKc5JKAUAAAAAQLjUqafUjh07VFhYKEl6/PHHVVBQ0KSTAkIlEDrZa2h0Hug5JUlRNQRXAAAAAAAg9OpUGnLxxRfr9ttv1xVXXCHDMPTcc88pLi6u2rEzZ84M6QSBxghUStUUOFWslAIAAAAAAOFTp1Bq/vz5evTRR7V48WJZLBb997//VVRU1ZdaLBZCKTQr7tNUSgVCKwAAAAAAEF51CqV69OihN998U5JktVq1cuVKJScnN+nEgFAIbM+rqaeU10coBQAAAABAJNS7ic5HH32kNm3aVDnu8Xi0Zs2akEwKCJVST6BSqoZQyiCUAgAAAAAgEuodSl177bU6duxYleMnTpzQNddcE5JJAaHi8flDqShr9dv37hnSTZI0+qL2YZsTAAAAAACo4/a9igzDkMVS9Qf+0aNHFRsbG5JJ4ezk8fp04pRbSXHOEF6z9u171/RI1qcPXauUeFfI3hMAAAAAAJxenUOp66+/XpK/mfmECRPkdJYHB16vV1u2bNHll18e+hnirPH//d8mrdx5SB/ef7W6tqv+7o71VXqaRueS1CExOiTvBQAAAAAA6q7OoVRCQoIkf6VUq1atFB1d/kPe4XBo0KBBuvPOO0M/Q5wVvD5DK3cekiS99dl+zRjZKyTXPV2lFAAAAAAAiIw6h1Lz5s2TUdYU+sUXX1RcXGgqWQBJ+vSbI+ZjZwgDJLe39kbnAAAAAAAgMur1S90wDC1YsEAHDx5sqvngLPVVboH5uNQbmjviGYYhj89/rahatu8BAAAAAIDwq1coZbVadd555+no0aNNNR+cpQ7mnTIfHz5ZEpJrBgIpSbJbqZQCAAAAAKA5qfcv9aefflrTp0/X1q1bm2I+OEsdKSgPog6dLA7JNQNb9yTJHkWlFAAAAAAAzUmde0oF/PKXv1RRUZH69u0rh8MR1PBcko4dOxayyeHscbSw1Hwcqkopd4VtgFFUSgEAAAAA0KzUO5T605/+1ATTwNmuYhAVsu17FSul6CkFAAAAAECzUu9Qavz48U0xD5zlKlZKHS0sldvra/Qd8wKVUlFWiywWQikAAAAAAJqTeodSkuT1erVo0SLt2LFDktS7d2+NGTNGNpstpJPD2cHnM3SsQiglSUcLSpWa4GrUdQM9pbjzHgAAAAAAzU+9Q6mvv/5ao0aN0g8//KAePXpIkmbNmqW0tDQtWbJE3bp1C/kkcWYrLPXIW3anvMQYu/KK3Dp0sjhkoVRjK64AAAAAAEDo1fvX+r333qtu3bpp//79+vzzz/X5559r37596tKli+69996mmCPOcKWe8t5P5yT6G+dXvBtfQ3nKgi5CKQAAAAAAmp96V0qtXr1a69atU5s2bcxjSUlJevrppzV48OCQTg5nh1KzosmiNrEOSdKJU+5GX9dd4boAAAAAAKB5qXcJidPp1MmTJ6scLygokMPhCMmkcHYJVEo5bFbFR9slSXlFoQilAo3OqZQCAAAAAKC5qfev9R/96Ee66667tH79ehmGIcMwtG7dOt19990aM2ZMU8wRZ7iSQCgVZVViWSgVikopD5VSAAAAAAA0W/UOpV544QV169ZN6enpcrlccrlcGjx4sLp37645c+Y0xRxxhgtUSjmjbEoIYaVUKY3OAQAAAABoturdUyoxMVHvvvuuvv76a+3YsUOS1KtXL3Xv3j3kk8PZIahSKiaUlVJl2/cIpQAAAAAAaHbqHEr5fD49++yzeu+991RaWqqhQ4fq0UcfVXR0dFPOD2eB0gqhVLwrhKGUL9Criu17AAAAAAA0N3UuIXnqqaf08MMPKy4uTuecc47mzJmjSZMmNeXccJYIbLNz2Kzm9r38EIRSpR4qpQAAAAAAaK7q/Gv9b3/7m15++WUtX75cixYt0vvvv68FCxbIV1aNAjRUidsrSXLay0OpUFZKRVmplAIAAAAAoLmpcyi1b98+jRo1ynw+bNgwWSwWHThwoMFvvmbNGv34xz9Whw4dZLFYtGjRoqDzEyZMkMViCfozYsSIoDHHjh3TuHHjFB8fr8TERE2cOFEFBQVBY7Zs2aIrr7xSLpdLaWlpeuaZZ6rM5Z133lHPnj3lcrnUp08fLV26tMGfC/VTsVIqPoShlNtbvi0QAAAAAAA0L3X+te7xeORyuYKO2e12ud0NDw8KCwvVt29fzZ07t8YxI0aM0MGDB80///jHP4LOjxs3Ttu2bVNmZqYWL16sNWvW6K677jLP5+fna/jw4ercubM2bdqkZ599Vo899phee+01c8ynn36qW265RRMnTtTmzZs1duxYjR07Vlu3bm3wZ0PdVewpVblSyjAM7TtaJJ/PqPd13YFG51RKAQAAAADQ7NS50blhGJowYYKcTqd5rLi4WHfffbdiY2PNY//+97/r/OYjR47UyJEjax3jdDqVmppa7bkdO3Zo2bJl2rhxowYMGCBJevHFFzVq1Cg999xz6tChgxYsWKDS0lK98cYbcjgc6t27t7Kzs/X888+b4dWcOXM0YsQITZ8+XZL05JNPKjMzUy+99JJeffXVOn8eNEwggIp32c1KqRKPT8Vur97LPqAH/7VFvx7STQ+O6Fmv6wbuvmenpxQAAAAAAM1OnUOp8ePHVzl26623hnQy1Vm1apWSk5PVunVrXXvttfrd736npKQkSVJWVpYSExPNQErybyu0Wq1av369fvrTnyorK0tXXXWVHA6HOSYjI0N/+MMfdPz4cbVu3VpZWVmaNm1a0PtmZGRU2U5YUUlJiUpKSszn+fn5kiS3292o6rFIC8w9nJ9h0eYfJEkxDqtcVkNWi+QzpGMnT+nh/3wpSXp51TeaOrRbva5bXOr/DDZLeD8P0BCRWHsAWHtApLD2gMhg7SFc6vodq3MoNW/evAZPpqFGjBih66+/Xl26dNE333yjhx9+WCNHjlRWVpZsNptycnKUnJwc9JqoqCi1adNGOTk5kqScnBx16dIlaExKSop5rnXr1srJyTGPVRwTuEZ1Zs2apccff7zK8RUrVigmJqZBn7c5yczMDNt77c21SbJoz3f7tWzZd3LZbCryWPT+8pXy+Mq/ovXt87XlgEWSTYdyD2rp0h9CO2mgiYRz7QEox9oDIoO1B0QGaw9NraioqE7j6hxKRcLNN99sPu7Tp48uuugidevWTatWrdLQoUMjODNpxowZQdVV+fn5SktL0/DhwxUfHx/BmTWO2+1WZmamrrvuOtnt9rC85+xdHyv/2Cnddu3FGtUnVc/vWqvvjhXpokvTpS82muMqNtqvi/1r9krf7VbntI4aNerCUE8bCKlIrD0ArD0gUlh7QGSw9hAugd1kp9OsQ6nKunbtqrZt2+rrr7/W0KFDlZqaqkOHDgWN8Xg8OnbsmNmHKjU1Vbm5uUFjAs9PN6amXlaSv9dVxf5aAXa7/YxY3OH8HBaLvxH5OW1iZbfblRjr0HfHilRQGtzcvL7zMeS/rtNuOyP+b4Kzw5ny7xCgpWHtAZHB2gMig7WHplbX71eL6gD9/fff6+jRo2rfvr0kKT09XXl5edq0aZM55sMPP5TP59PAgQPNMWvWrAnaz5iZmakePXqodevW5piVK1cGvVdmZqbS09Ob+iNBUn6FRueSzDvwfX2owBzTkBvouX00OgcAAAAAoLmK6K/1goICZWdnKzs7W5K0d+9eZWdna9++fSooKND06dO1bt06ffvtt1q5cqV+8pOfqHv37srIyJAk9erVSyNGjNCdd96pDRs26JNPPtHkyZN18803q0OHDpKkX/ziF3I4HJo4caK2bdumt956S3PmzAnaenffffdp2bJlmj17tnbu3KnHHntMn332mSZPnhz2v5OzjWEYOlnskSTFR/sL9xLLQqkv9ueZ43yGdKrUW69ru70+SVKUlVAKAAAAAIDmJqK/1j/77DP169dP/fr1kyRNmzZN/fr108yZM2Wz2bRlyxaNGTNG559/viZOnKj+/fvr448/Dto2t2DBAvXs2VNDhw7VqFGjdMUVV+i1114zzyckJGjFihXau3ev+vfvr/vvv18zZ87UXXfdZY65/PLLtXDhQr322mvq27ev/vnPf2rRokW68EL6EDW1Eo9PnrKKpjhnWSgV4w+lPvvueNDY744V1uvanrJQym5rQJkVAAAAAABoUhHtKTVkyBAZhlHj+eXLl5/2Gm3atNHChQtrHXPRRRfp448/rnXMjTfeqBtvvPG074fQ+iHvlPk41uH/Oga27x0pKAkauyvnpHqm1r2JvNvL9j0AAAAAAJorfq0jop54f7v52FrWOCoQSgVU12OqLszte1RKAQAAAADQ7BBKIaK+yj1Z5VjlUGpEb/9dEA/kFQcdf3nV17rqmY+09YcT1V7bQ6UUAAAAAADNFr/WEVE3DkirciwxxhH0/LIubSRJufnBodQzy3Zp37Ei/ejFtVq29WCV67jpKQUAAAAAQLNFKIWIctn9X8Eb+3c0j1WulGrl8veaKijx1Hidu//+eZVj7rIG6tx9DwAAAACA5odf64iowrKgKdphM49VrGyantFDsWV35TtV6g16bac2Mebjfp0Sq1zb7SmrlIriaw4AAAAAQHPDr3VE1JGTpZKkdnFO81ifcxLUpW2s2ie49Osh3czAqsgdXClV7C4PqYpK/I9z84v13PJdOnjilDy+slDKyvY9AAAAAACam6hITwBnt0Mn/X2ikuPLQ6kom1UfPTDEfB7r8H9NA8FTwKkKodSxIn+4dc/fN+nzfXnK3J6rlASXJBqdAwAAAADQHBFKIaIOF5RIktq1ctY4JiZQKVVp+16J22c+zisqlWEY+nxfniRpV+5JHS30B1VRNDoHAAAAAKDZoYQEEXUo3x9KJbdy1TgmEEqdcnvlK2te7vH6VOotD6XcXqNKI/RAv6q0Cr2nAAAAAABA80AohYjxeH06UlYpVXH7XmUxjvKCvqKyLXtFFbbu2cp6Rh06WaJzEqPN46fcXjlsVl10TkJI5w0AAAAAABqPUAoRc7SwVD5DslqkpNiaQymXvfxrWhIIpcr6S0VZLUqMtkuSvvz+hAac2zrote1aORVFTykAAAAAAJodfq0jIjxen7l1r22c06x2qo7FYpG9rC9UYMteYal/a16Mw6bUsobmxwpL5fEaQa/9xcBOIZ87AAAAAABoPBqdI+zyiko1/I9rdOhkeSh1OnabVW6vV26PP3QKVErFOqOU3jVJ2w7kKye/OKjPlCT96souIZ49AAAAAAAIBUIphN07n31vBlKSlBTnOO1rHFFWFZV6Veot275XoVIqJd5fKbX4iwM6cKJYkjRjZE+Nv/xcOaNsoZ4+AAAAAAAIAbbvIew++eZI0PP2CTXfeS/AXtYXqjRQKVVaXikV5/Jnq4FASpJSE1xy2QmkAAAAAABorqiUQticOOXW8yt2adWuw0HHW8fUoVIqEEpV01MqxlE1fKJCCgAAAACA5o1QCmHz9H936h8b9lU53sp1+q+hI8ofSrnLQqlAT6kYR5Siq6mIckTV3DgdAAAAAABEHtv3EDZZFbbtOaPKv3pxzjqEUub2veoqpaq+/pzEmEbNFQAAAAAANC1CKUTE9Iwe5uMit/e04+1llU/m9r0SfygV54xSdKXte+cmxahHaqtQTRUAAAAAADQBQimEhc9n6ECevxH5Mz+7SHcM7mKe69U+/rSvr1wpdbJCKFW5p9Rt6eeGYsoAAAAAAKAJ0VMKYXGkoESlXp+sFumn/c6R1WrR8ilX6csfTmjI+e1O+/rA3fcCPaUKistCKVeUYitt36uuxxQAAAAAAGheCKUQFvuPn5Ikpca7zICpR2qrOm+zCzQ6D1RKFVSolGoTF3z3PkNGSOYMAAAAAACaDtv3EBY/5PlDqXNaRzfo9Y4aKqVauaIU54zSDZd0NMe2ctkbM1UAAAAAABAGVEohLLYdOCFJ6tYurkGvr1wpFegpFVt2577ZP++ri9MS9P3xU/rxRe0bO10AAAAAANDECKXQpLYdOKEJ8zbq8MkSSdIlnVs36DqBLX+lXv/WvOKyO/ZV7CdFg3MAAAAAAFoOtu+hSU176wszkJKk85JDUylV4vb/0xnFVxgAAAAAgJaIX/RoUh6fL+h556TYBl0nEEoFekqVePyVUk47X2EAAAAAAFoiftHjtEo8Xj27fKc+3Jlb79fGVWo63jqmYU3IA43OzUopT6BSytag6wEAAAAAgMiipxRO6w//3aU3PtkrSfr26dH1em0rZ/BXzGKxNGgOVSul2L4HAAAAAEBLxi96nFYgkJIkwzDq9dpWrvJQ6rEfX9DgOdht/jCrxOwpVbZ9j0opAAAAAABaJEIp1KqwxBP0vKDS89NpHeswH4+//NwGz8Nh84dPVSql6CkFAAAAAECLxC961Orbo4VBz48WlNbr9T6fv7LqgeHnN3jrniTZo/yvLfX45PH65Cm7Ltv3AAAAAABomfhFj1qt/upw0PMjBSX1en0gPLJZG/dVCzQ6d3t9KizxmsfZvgcAAAAAQMtEKIVa/XnNnqDnRwpK5fUZ+t3i7Vr65cHTvt5nhlKNm0eg0Xmp16eXPtpd5TgAAAAAAGhZ+EWPWvkq9TX/7mihFq7/Tq+v3atfL/j8tK8PdaXUzpyT+vPH5Y3XbdaGbwkEAAAAAACRQyiFWp2fEidJ6to2VpL0Q94pvf/F6SukArxloVRUI8Mje1kotedw4WlGAgAAAACAloBQCjX6Ie+UNn57XJJ0TutoSdLeI4Xa8O2xOl/Da1ZKNS6UYpseAAAAAABnFn7po0a/W7zdfNy7Q4Ik6ePdR8xjCdH2017DE6JQyl5NU6rpGT0adU0AAAAAABA5hFKoUYnHZz4e1LVNlfN1yZm8Pv81GhtKOStVSvVqH69fD+nWqGsCAAAAAIDIIZRCjT7ceUiS9NRPL1RSrLPKeU/lLujV8JYNCVVPqYAxfTvIYqHJOQAAAAAALRWhFE6rQ0K0WseWb9VrG+eQVN4vqjahqpSq3FMq1mlr1PUAAAAAAEBkEUqhRoEcqWf7VmobV14pdeE5/v5SdamU8nhD1VMq+PWxjqhGXQ8AAAAAAEQWoRSq5fb6FMicou02uezllUmXdfH3l/LVIZTyGf4xjd2+R6UUAAAAAABnFkIpVLH1uEUz/rPNfB7t8AdAs2/sq4lXdNHPLukoyV8pZRi1B1OBaiprI/s/OSr1lIqhUgoAAAAAgBaNX/ao4s87bZIOSvJv4QsEQjf076gbJB0vLDXH+gzJVkveFOg7FVXboDqoWinFVxcAAAAAgJYsopVSa9as0Y9//GN16OC/k9qiRYuCzhuGoZkzZ6p9+/aKjo7WsGHDtHv37qAxx44d07hx4xQfH6/ExERNnDhRBQUFQWO2bNmiK6+8Ui6XS2lpaXrmmWeqzOWdd95Rz5495XK51KdPHy1dujTkn7clyN6fF/Q8xhFV5S53tgoBk6eskXlNAqGUzdq4r1rlu++xfQ8AAAAAgJYtoqFUYWGh+vbtq7lz51Z7/plnntELL7ygV199VevXr1dsbKwyMjJUXFxsjhk3bpy2bdumzMxMLV68WGvWrNFdd91lns/Pz9fw4cPVuXNnbdq0Sc8++6wee+wxvfbaa+aYTz/9VLfccosmTpyozZs3a+zYsRo7dqy2bt3adB++mbrxtQ1Bz5PK7rRXUcX+UKe7A58ZSjVy+17lSisanQMAAAAA0LJF9Jf9yJEjNXLkyGrPGYahP/3pT3rkkUf0k5/8RJL0t7/9TSkpKVq0aJFuvvlm7dixQ8uWLdPGjRs1YMAASdKLL76oUaNG6bnnnlOHDh20YMEClZaW6o033pDD4VDv3r2VnZ2t559/3gyv5syZoxEjRmj69OmSpCeffFKZmZl66aWX9Oqrr4bhb6L56t+pdZVjtnqEUh5fiO6+Z2X7HgAAAAAAZ5Jm+8t+7969ysnJ0bBhw8xjCQkJGjhwoLKysnTzzTcrKytLiYmJZiAlScOGDZPVatX69ev105/+VFlZWbrqqqvkcJRX/GRkZOgPf/iDjh8/rtatWysrK0vTpk0Lev+MjIwq2wkrKikpUUlJifk8Pz9fkuR2u+V2uxv78SOixOOTw2ZVqbd8S94lnRKqfB5fhfPFJW65atlJ5ykba/i8jfp7MXzeoOfRNqPF/j0D1Ql8n/leA+HF2gMig7UHRAZrD+FS1+9Ysw2lcnJyJEkpKSlBx1NSUsxzOTk5Sk5ODjofFRWlNm3aBI3p0qVLlWsEzrVu3Vo5OTm1vk91Zs2apccff7zK8RUrVigmJqYuH7HZySuRzomxKadIOuX1VzbZDmzR0qVbgsb5b7jn/+osz8xUK3vN18zJs0my6MvPsnR4e8PnVuotf0+LDK1YvqzhFwOasczMzEhPATgrsfaAyGDtAZHB2kNTKyoqqtO4ZhtKNXczZswIqq7Kz89XWlqahg8frvj4+AjOrHFudLu1fEWmMoZfJ7u95rTp/g2Z8voMDbnmWqXEu2oc98CGTEmGRg2/Vqm1jDsdt9en6Rs+kCTFOu0aNSqjwdcCmiO3263MzExdd13taw9AaLH2gMhg7QGRwdpDuAR2k51Osw2lUlNTJUm5ublq3769eTw3N1cXX3yxOebQoUNBr/N4PDp27Jj5+tTUVOXm5gaNCTw/3ZjA+eo4nU45nc4qx+12e4tf3FbL6T+HzWqR12fIaouqcZxhGHJ7/T2lXA5Ho/5eoqLKe1fFOWt+T6ClOxP+HQK0RKw9IDJYe0BksPbQ1Or6/Yro3fdq06VLF6WmpmrlypXmsfz8fK1fv17p6emSpPT0dOXl5WnTpk3mmA8//FA+n08DBw40x6xZsyZoP2NmZqZ69Oih1q1bm2Mqvk9gTOB9UFXgbnq1NTqveCqqkY3OLRXu3hfjrKWJFQAAAAAAaBEiGkoVFBQoOztb2dnZkvzNzbOzs7Vv3z5ZLBZNmTJFv/vd7/Tee+/pyy+/1C9/+Ut16NBBY8eOlST16tVLI0aM0J133qkNGzbok08+0eTJk3XzzTerQ4cOkqRf/OIXcjgcmjhxorZt26a33npLc+bMCdp6d99992nZsmWaPXu2du7cqccee0yfffaZJk+eHO6/khYjEDJ5agmlPL7yhug2W+NCqYoctmabpQIAAAAAgDqK6Pa9zz77TNdcc435PBAUjR8/XvPnz9eDDz6owsJC3XXXXcrLy9MVV1yhZcuWyeUq7020YMECTZ48WUOHDpXVatUNN9ygF154wTyfkJCgFStWaNKkSerfv7/atm2rmTNn6q677jLHXH755Vq4cKEeeeQRPfzwwzrvvPO0aNEiXXjhhWH4W2iZAiGTt0LwVFnFKiq7NXRBkjOKUAoAAAAAgJYuoqHUkCFDZBg1V9pYLBY98cQTeuKJJ2oc06ZNGy1cuLDW97nooov08ccf1zrmxhtv1I033lj7hGGqS6VUoJ+U5O9BFSp2KqUAAAAAAGjx+HWPBrHWoadUxXON7SlVkYNKKQAAAAAAWjx+3aNBAiFTbaFUoKeU1SJZqZQCAAAAAAAV8OseDRLoKVVro/Oy7XtRIewnJVEpBQAAAADAmYBf92iQQNBUl+17oewnJXH3PQAAAAAAzgT8ukeDBHKm2rfvBSqlQhtK2W2hvR4AAAAAAAg/Qik0SF0qpTxef0+pqBCHSGzfAwAAAACg5ePXPRoksCWv1p5S5va90HzNeneIlyT9rH9aSK4HAAAAAAAiJyrSE0DLFKh+8pbdYa86BSUeSVKs0xaS9/zXPZfr4IlidWkbG5LrAQAAAACAyKFSCg1itQRCqZrHHC0okSQlxTpC8p4uu41ACgAAAACAMwShFBok0Ly8tkqpY4VuSVKbEIVSAAAAAADgzEEohQapS08pd1kZlTMqNNv3AAAAAADAmYNQCg1S3lOq5lAqcM5qDe3d9wAAAAAAQMtHKIUGCfSU8nhPH0rZyKQAAAAAAEAlhFJokA17j0mSsvYcrXGM1ygLpax8zQAAAAAAQDDSAjRIicffL+qfm76vcYxZKcW3DAAAAAAAVEJcgCZTHkqxfw8AAAAAAAQjlEKjOKJq/gqZjc4thFIAAAAAACAYoRQa5N5ru0uSbrikY41jfGU9paKolAIAAAAAAJUQSqFBnHabJMnr89U4xqyUIpQCAAAAAACVEEqhQew2f9Dk8Ro1jjF7SrF9DwAAAAAAVEIohQaJsvq/Om5fHUIpKqUAAAAAAEAlhFJokPJKqVq27xmEUgAAAAAAoHqEUmiQKFtZpVRdtu8RSgEAAAAAgEoIpdAggTvqeerS6JyeUgAAAAAAoBJCKTSIvaxSqrZG576y7XtRVEoBAAAAAIBKCKXQIFFlPaXctfSUCgRWVkIpAAAAAABQCaEUGqR8+14tPaVodA4AAAAAAGpAKIUGibKWbd+rJZQKVEqxfQ8AAAAAAFRGKIUGCWzf89Syfa/E45Ukuey2sMwJAAAAAAC0HIRSaJC6NDov8fgDK2cUXzMAAAAAABCMtAANEtiS5/bVUinlLgulqJQCAAAAAACVEEqhQaLqVCnl375HpRQAAAAAAKiMtAANYq9TTym27wEAAAAAgOqRFqBBAnffc9dy971tB/Il0egcAAAAAABURSiFBjnd3fdy84vNx9GEUgAAAAAAoBJCKTRIoNG5p4ZKqe0H883HF3SID8ucAAAAAABAy0EohQax19Lo/FhhqW6ft1GSdMtlncyxAAAAAAAAAaQFaBBz+56v6va9P3+8x3x866BOYZsTAAAAAABoOQil0CBmo3OvIcMIrpb6/Lvj5uPeHRLCOi8AAAAAANAyEEqhQexllVKS5K3QV6rU49P6vcckSX8ZPyDs8wIAAAAAAC0DoRQaJKpCn6iKzc73Hik0Hw/u3jascwIAAAAAAC0HoRQaJHD3PUlye8v7Sn171B9K9e2YIJfdFvZ5AQAAAACAloFQCg1SMZSqeAe+bQfyJUld28WFfU4AAAAAAKDlIJRCg9isFgVyqYqVUv/YsE+SNKhrm0hMCwAAAAAAtBCEUmgQi8Wi6LLteSdLPJKkDXuP6fDJEknSwC5JEZsbAAAAAABo/pp1KPXYY4/JYrEE/enZs6d5vri4WJMmTVJSUpLi4uJ0ww03KDc3N+ga+/bt0+jRoxUTE6Pk5GRNnz5dHo8naMyqVat0ySWXyOl0qnv37po/f344Pl6LF+OMkiQNnb1ay7Ye1Jsb95nnOifFRGpaAAAAAACgBWjWoZQk9e7dWwcPHjT/rF271jw3depUvf/++3rnnXe0evVqHThwQNdff7153uv1avTo0SotLdWnn36qv/71r5o/f75mzpxpjtm7d69Gjx6ta665RtnZ2ZoyZYp+9atfafny5WH9nC1RjKO8kfnD/9mqNjEOSVJ61yRZLJaaXgYAAAAAAKCoSE/gdKKiopSamlrl+IkTJ/SXv/xFCxcu1LXXXitJmjdvnnr16qV169Zp0KBBWrFihbZv364PPvhAKSkpuvjii/Xkk0/qN7/5jR577DE5HA69+uqr6tKli2bPni1J6tWrl9auXas//vGPysjICOtnbWmOF5aaj48Vliq3bOve0F7JkZoSAAAAAABoIZp9KLV792516NBBLpdL6enpmjVrljp16qRNmzbJ7XZr2LBh5tiePXuqU6dOysrK0qBBg5SVlaU+ffooJSXFHJORkaF77rlH27ZtU79+/ZSVlRV0jcCYKVOm1DqvkpISlZSUmM/z8/13nXO73XK73SH45JERmHtdPkN+cfA2yH1HCyVJ7WLtLfrvAIiE+qw9AKHD2gMig7UHRAZrD+FS1+9Ysw6lBg4cqPnz56tHjx46ePCgHn/8cV155ZXaunWrcnJy5HA4lJiYGPSalJQU5eTkSJJycnKCAqnA+cC52sbk5+fr1KlTio6OrnZus2bN0uOPP17l+IoVKxQT0/L7KWVmZp52TLLLpkPF/m16Vhn68oc8SRYd2f25lu5v2vkBZ6q6rD0AocfaAyKDtQdEBmsPTa2oqKhO45p1KDVy5Ejz8UUXXaSBAweqc+fOevvtt2sMi8JlxowZmjZtmvk8Pz9faWlpGj58uOLj4yM4s8Zxu93KzMzUddddJ7vdXutYIy1HU97eIknyySIZkt1m0a1jR8pqpacUUB/1WXsAQoe1B0QGaw+IDNYewiWwm+x0mnUoVVliYqLOP/98ff3117ruuutUWlqqvLy8oGqp3NxcswdVamqqNmzYEHSNwN35Ko6pfMe+3NxcxcfH1xp8OZ1OOZ3OKsftdvsZsbjr8jl+0q+j0pJidcMrWeaxjq1j5HQ6mnp6wBnrTPl3CNDSsPaAyGDtAZHB2kNTq+v3q9nffa+igoICffPNN2rfvr369+8vu92ulStXmud37dqlffv2KT09XZKUnp6uL7/8UocOHTLHZGZmKj4+XhdccIE5puI1AmMC10DNLBaL+nduE3SsY+vIVrABAAAAAICWoVmHUg888IBWr16tb7/9Vp9++ql++tOfymaz6ZZbblFCQoImTpyoadOm6aOPPtKmTZt0++23Kz09XYMGDZIkDR8+XBdccIFuu+02ffHFF1q+fLkeeeQRTZo0yaxyuvvuu7Vnzx49+OCD2rlzp15++WW9/fbbmjp1aiQ/eotyTY925mNCKQAAAAAAUBfNevve999/r1tuuUVHjx5Vu3btdMUVV2jdunVq184fgvzxj3+U1WrVDTfcoJKSEmVkZOjll182X2+z2bR48WLdc889Sk9PV2xsrMaPH68nnnjCHNOlSxctWbJEU6dO1Zw5c9SxY0e9/vrrysjICPvnbamS4sq3MV7UMTFyEwEAAAAAAC1Gsw6l3nzzzVrPu1wuzZ07V3Pnzq1xTOfOnbV06dJarzNkyBBt3ry5QXOE1K5VeSjVM7VVBGcCAAAAAABaima9fQ8tQ7sKlVLnJLJ9DwAAAAAAnB6hFBqtqNRjPm4bV/WOhAAAAAAAAJURSqHRLunUWpK/SspqtUR4NgAAAAAAoCVo1j2l0DKkd0vS/028TN3axUV6KgAAAAAAoIUglEKjWSwWXXleu0hPAwAAAAAAtCBs3wMAAAAAAEDYEUoBAAAAAAAg7AilAAAAAAAAEHaEUgAAAAAAAAg7QikAAAAAAACEHaEUAAAAAAAAwo5QCgAAAAAAAGFHKAUAAAAAAICwI5QCAAAAAABA2BFKAQAAAAAAIOwIpQAAAAAAABB2hFIAAAAAAAAIO0IpAAAAAAAAhB2hFAAAAAAAAMKOUAoAAAAAAABhFxXpCZwpDMOQJOXn50d4Jo3jdrtVVFSk/Px82e32SE8HOGuw9oDIYO0BkcHaAyKDtYdwCWQjgaykJoRSIXLy5ElJUlpaWoRnAgAAAAAAEHknT55UQkJCjectxuliK9SJz+fTgQMH1KpVK1kslkhPp8Hy8/OVlpam/fv3Kz4+PtLTAc4arD0gMlh7QGSw9oDIYO0hXAzD0MmTJ9WhQwdZrTV3jqJSKkSsVqs6duwY6WmETHx8PP+SAiKAtQdEBmsPiAzWHhAZrD2EQ20VUgE0OgcAAAAAAEDYEUoBAAAAAAAg7AilEMTpdOrRRx+V0+mM9FSAswprD4gM1h4QGaw9IDJYe2huaHQOAAAAAACAsKNSCgAAAAAAAGFHKAUAAAAAAICwI5QCAAAAAABA2BFKIcjcuXN17rnnyuVyaeDAgdqwYUOkpwS0GLNmzdKll16qVq1aKTk5WWPHjtWuXbuCxhQXF2vSpElKSkpSXFycbrjhBuXm5gaN2bdvn0aPHq2YmBglJydr+vTp8ng8QWNWrVqlSy65RE6nU927d9f8+fOb+uMBLcLTTz8ti8WiKVOmmMdYd0DT+OGHH3TrrbcqKSlJ0dHR6tOnjz777DPzvGEYmjlzptq3b6/o6GgNGzZMu3fvDrrGsWPHNG7cOMXHxysxMVETJ05UQUFB0JgtW7boyiuvlMvlUlpamp555pmwfD6gOfJ6vfrtb3+rLl26KDo6Wt26ddOTTz6piq2iWXtoUQygzJtvvmk4HA7jjTfeMLZt22bceeedRmJiopGbmxvpqQEtQkZGhjFv3jxj69atRnZ2tjFq1CijU6dORkFBgTnm7rvvNtLS0oyVK1can332mTFo0CDj8ssvN897PB7jwgsvNIYNG2Zs3rzZWLp0qdG2bVtjxowZ5pg9e/YYMTExxrRp04zt27cbL774omGz2Yxly5aF9fMCzc2GDRuMc88917jooouM++67zzzOugNC79ixY0bnzp2NCRMmGOvXrzf27NljLF++3Pj666/NMU8//bSRkJBgLFq0yPjiiy+MMWPGGF26dDFOnTpljhkxYoTRt29fY926dcbHH39sdO/e3bjlllvM8ydOnDBSUlKMcePGGVu3bjX+8Y9/GNHR0cb//u//hvXzAs3FU089ZSQlJRmLFy829u7da7zzzjtGXFycMWfOHHMMaw8tCaEUTJdddpkxadIk87nX6zU6dOhgzJo1K4KzAlquQ4cOGZKM1atXG4ZhGHl5eYbdbjfeeecdc8yOHTsMSUZWVpZhGIaxdOlSw2q1Gjk5OeaYV155xYiPjzdKSkoMwzCMBx980Ojdu3fQe910001GRkZGU38koNk6efKkcd555xmZmZnG1VdfbYZSrDugafzmN78xrrjiihrP+3w+IzU11Xj22WfNY3l5eYbT6TT+8Y9/GIZhGNu3bzckGRs3bjTH/Pe//zUsFovxww8/GIZhGC+//LLRunVrcy0G3rtHjx6h/khAizB69GjjjjvuCDp2/fXXG+PGjTMMg7WHlofte5AklZaWatOmTRo2bJh5zGq1atiwYcrKyorgzICW68SJE5KkNm3aSJI2bdokt9sdtM569uypTp06messKytLffr0UUpKijkmIyND+fn52rZtmzmm4jUCY1irOJtNmjRJo0ePrrI2WHdA03jvvfc0YMAA3XjjjUpOTla/fv305z//2Ty/d+9e5eTkBK2bhIQEDRw4MGjtJSYmasCAAeaYYcOGyWq1av369eaYq666Sg6HwxyTkZGhXbt26fjx4039MYFm5/LLL9fKlSv11VdfSZK++OILrV27ViNHjpTE2kPLExXpCaB5OHLkiLxeb9B/kEtSSkqKdu7cGaFZAS2Xz+fTlClTNHjwYF144YWSpJycHDkcDiUmJgaNTUlJUU5OjjmmunUYOFfbmPz8fJ06dUrR0dFN8ZGAZuvNN9/U559/ro0bN1Y5x7oDmsaePXv0yiuvaNq0aXr44Ye1ceNG3XvvvXI4HBo/fry5dqpbNxXXVXJyctD5qKgotWnTJmhMly5dqlwjcK5169ZN8vmA5uqhhx5Sfn6+evbsKZvNJq/Xq6eeekrjxo2TJNYeWhxCKQBoApMmTdLWrVu1du3aSE8FOKPt379f9913nzIzM+VyuSI9HeCs4fP5NGDAAP3+97+XJPXr109bt27Vq6++qvHjx0d4dsCZ6+2339aCBQu0cOFC9e7dW9nZ2ZoyZYo6dOjA2kOLxPY9SJLatm0rm81W5W5Eubm5Sk1NjdCsgJZp8uTJWrx4sT766CN17NjRPJ6amqrS0lLl5eUFja+4zlJTU6tdh4FztY2Jj4+nWgNnnU2bNunQoUO65JJLFBUVpaioKK1evVovvPCCoqKilJKSwroDmkD79u11wQUXBB3r1auX9u3bJ6l87dT235apqak6dOhQ0HmPx6Njx47Va30CZ5Pp06froYce0s0336w+ffrotttu09SpUzVr1ixJrD20PIRSkCQ5HA71799fK1euNI/5fD6tXLlS6enpEZwZ0HIYhqHJkyfrP//5jz788MMqJc/9+/eX3W4PWme7du3Svn37zHWWnp6uL7/8Mug/FDIzMxUfH2/+x396enrQNQJjWKs4Gw0dOlRffvmlsrOzzT8DBgzQuHHjzMesOyD0Bg8erF27dgUd++qrr9S5c2dJUpcuXZSamhq0bvLz87V+/fqgtZeXl6dNmzaZYz788EP5fD4NHDjQHLNmzRq53W5zTGZmpnr06MH2IZyVioqKZLUG/4y32Wzy+XySWHtogSLdaR3Nx5tvvmk4nU5j/vz5xvbt24277rrLSExMDLobEYCa3XPPPUZCQoKxatUq4+DBg+afoqIic8zdd99tdOrUyfjwww+Nzz77zEhPTzfS09PN84Fb0w8fPtzIzs42li1bZrRr167aW9NPnz7d2LFjhzF37lxuTQ9UUPHue4bBugOawoYNG4yoqCjjqaeeMnbv3m0sWLDAiImJMf7+97+bY55++mkjMTHRePfdd40tW7YYP/nJT6q9LX2/fv2M9evXG2vXrjXOO++8oNvS5+XlGSkpKcZtt91mbN261XjzzTeNmJgYbkuPs9b48eONc845x1i8eLGxd+9e49///rfRtm1b48EHHzTHsPbQkhBKIciLL75odOrUyXA4HMZll11mrFu3LtJTAloMSdX+mTdvnjnm1KlTxq9//WujdevWRkxMjPHTn/7UOHjwYNB1vv32W2PkyJFGdHS00bZtW+P+++833G530JiPPvrIuPjiiw2Hw2F07do16D2As13lUIp1BzSN999/37jwwgsNp9Np9OzZ03jttdeCzvt8PuO3v/2tkZKSYjidTmPo0KHGrl27gsYcPXrUuOWWW4y4uDgjPj7euP32242TJ08Gjfniiy+MK664wnA6ncY555xjPP30003+2YDmKj8/37jvvvuMTp06GS6Xy+jatavx//7f/zNKSkrMMaw9tCQWwzCMSFZqAQAAAAAA4OxDTykAAAAAAACEHaEUAAAAAAAAwo5QCgAAAAAAAGFHKAUAAAAAAICwI5QCAAAAAABA2BFKAQAAAAAAIOwIpQAAAAAAABB2hFIAAAAAAAAIO0IpAAAAAAAAhB2hFAAAQDMzYcIEjR07tsrxVatWyWKxKC8vL+xzAgAACDVCKQAAAJjcbnekpwAAAM4ShFIAAAAt1L/+9S/17t1bTqdT5557rmbPnh103mKxaNGiRUHHEhMTNX/+fEnSt99+K4vForfeektXX321XC6XFixYEKbZAwCAs11UpCcAAACA+tu0aZN+/vOf67HHHtNNN92kTz/9VL/+9a+VlJSkCRMm1OtaDz30kGbPnq1+/frJ5XI1zYQBAAAqIZQCAABohhYvXqy4uLigY16v13z8/PPPa+jQofrtb38rSTr//PO1fft2Pfvss/UOpaZMmaLrr7++0XMGAACoD7bvAQAANEPXXHONsrOzg/68/vrr5vkdO3Zo8ODBQa8ZPHiwdu/eHRRe1cWAAQNCMmcAAID6oFIKAACgGYqNjVX37t2Djn3//ff1uobFYpFhGEHHqmtkHhsbW/8JAgAANBKVUgAAAC1Qr1699MknnwQd++STT3T++efLZrNJktq1a6eDBw+a53fv3q2ioqKwzhMAAKAmVEoBAAC0QPfff78uvfRSPfnkk7rpppuUlZWll156SS+//LI55tprr9VLL72k9PR0eb1e/eY3v5Hdbo/grAEAAMpRKQUAANACXXLJJXr77bf15ptv6sILL9TMmTP1xBNPBDU5nz17ttLS0nTllVfqF7/4hR544AHFxMREbtIAAAAVWIzKjQYAAAAAAACAJkalFAAAAAAAAMKOUAoAAAAAAABhRygFAAAAAACAsCOUAgAAAAAAQNgRSgEAAAAAACDsCKUAAAAAAAAQdoRSAAAAAAAACDtCKQAAAAAAAIQdoRQAAAAAAADCjlAKAAAAAAAAYUcoBQAAAAAAgLAjlAIAAAAAAEDY/f+GlbJjWafrdQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}